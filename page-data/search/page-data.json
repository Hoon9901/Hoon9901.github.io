{"componentChunkName":"component---src-pages-search-tsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"rawMarkdownBody":"[23년도 하반기 회고](https://seonghoon.xyz/23-second-half/) 에 이어서.\n\n작년 8월부터 시작한 취준이 끝났다. 이제는 주니어 개발자로 일하고 있다.\n\n개발자는 서울에 가야한다는 생각으로 서울권이나 수도권 회사 지원을 예전 부터 했었는데 취준 기간이 점점 길어지며 이제는 아무데나 당장 취직을 하고 싶다는 생각이 들었고 내 자신에 대해 후회와 회의감이 들면서 나를 갉아먹고 있었다.\n\n밤에 잠에 들려고 누워있으면 불안감과 잡생각, 그리고 언제까지 해야할까라는 생각이 들며 잠이 오지 않고 새벽 늦게 눈꺼풀이 강제로 닫혀있을 때 까지 핸드폰을 봤다.\n\n밤낮이 바뀌고 마음이 계속 꺾이니 이러면 안될것같아 책이라도 읽을려고 이것저것 찾다가  [기분이 태도가 되지 말자](https://product.kyobobook.co.kr/detail/S000200329012) 라는 책을 보게되었다. 이 책을 읽고 나름 생각 정리가 되었다 현명한 삶을 살기 위해서는 내 감정을 조절할 줄 알아야 하고 더 나아가 '나'를 다스릴 수 있다고 한다 라는 내용이고 가볍게 읽기 편해서 심적으로 힘들때가 오면 이 책을 읽고 감정을 조절하고 잡생각들을 잊기 위해 노력했다.\n\n이러한 노력덕인지 내 자신에 대한 회의감에서 벗어나 자신감을 기르게 되었고 내 자신에게 '조금만 더 노력해보자' 라는 말을 계속 건냈다. 내가 이 시기를 계속 이겨낼 수 있는 버팀목이 된것같다.\n\n작년에 이어 올해는 약 10% 정도의 확률로 서류 전형을 합격하고 이후 채용 과정을 진행했다. 그동안 여러 회사들의 면접을 보며 나만의 데이터베이스도 구축했고 이력서와 포폴도 꾸준하게 튜닝 파인을 하면서 이번에 합격 하지 않아도 다음에 합격할 수 있는 성장기를 지낸 것 같다.\n\n그런 성장할 수 있다는 생각이 면접 시 많은 긴장을 하지 않게하도록 해준것 같다. 예전에는 면접장 들어가면 내가 잘못 대답해서 떨어지면 어떡하지? 잘 할 수 있을까 라며 긴장했었는데 이제는 적절한 긴장과 여유를 통해 면접관들과 티키타카 대화하게 되었다. 이때 내가 '성장했구나' 라는 생각과 '이렇게 계속 하면 될거같다' 라는 생각이 들었다.\n\n그렇게 매일매일 코테 준비와 기업 조사, 이력서와 포폴 기반으로 예상 질문을 정리하며 이러한 반복적인 일상이 점차 쌓여 1개의 질문에서 300개에 달하는 예상 질문을 정리하고 코테 1문제에서 200개가 넘는 문제를 풀었다 그렇게 계속 달리다보니 목적지에 도달하게 되었다.\n\n### 이제는 주니어 개발자\n\n![왓챠 웰컴기프트](1.jpeg)\n![Alt text](2.jpeg)\n\n고2때 왓챠플레이를 알게되었고 영화를 좋아하다 보니 평점을 매기고 기록하는 용도로 왓챠피디아를 애용했는데 이제는 왓챠에서 주니어 서버 개발자로 일하게 되었다.\n\n이제 정말 내가 회사를 다니는 직장인이라는게 실감이 안나면서 왓챠의 문화와 분위기에 놀라며 매일 출근할 때 마다 한배에 탄 기분에 스며들고 기쁘게 강남 출퇴근을 하고 있다.\n\nJava와 스프링을 여태까지 공부하고 주로 개발했는데 새로운 언어와 기술 스택을 배워야한다는 컨텍스트 스위칭 비용이 나름 있지만 이때까지 학교에서 공부할때도 그렇고 기본기와 언어와 도구에 매몰되지 않는 서버 개발자가 되기 위해 노력해왔기에 성장 비용으로 하루하루 출근할 때 마다 새로운것들과 내가 배우고 축적한 기반들에 차곡차곡 쌓아 올리고 있다.\n\n왓챠의 서비스들을 구성하는 기술들을 하루하루 접하고 알아가니 너무 재밌다 진짜 서버 개발자를 꿈꿔왔을때 부터 지금까지 많은 분들이 이용하는 서비스의 개발자로 일하고 싶었는데 그렇게 되어서 너무 좋다 또한 제일 좋은 복지는 동료라고 생각하는데 대단한 분들과 함께 일을하고 매일 얘기하면서 많은 것을 물어보고 있다.\n\n왓챠를 이용해주시는 분들에게 더 좋은 서비스를 제공할 수 있도록 주니어 개발자로써 정진할 것이다.\n","excerpt":"23년도 하반기 회고 에 이어서. 작년 8월부터 시작한 취준이 끝났다. 이제는 주니어 개발자로 일하고 있다. 개발자는 서울에 가야한다는 생각으로 서울권이나 수도권 회사 지원을 예전 부터 했었는데 취준 기간이 점점 길어지며 이제는 아무데나 당장 취직을…","fields":{"slug":"/24-first-story/"},"frontmatter":{"date":"Jun 22, 2024","title":"이제는 주니어 개발자","tags":["회고"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n기존에는 SoftDelete를 구현할려면 @Where 와 @SQLDelete 를 사용했어야했다.\n\n```java\n@Entity\n@Where(clause = \"deleted = false\")\n@SQLDelete(sql = \"UPDATE member SET deleted = true WHERE id = ?\")\npublic class Member {\n    @Id\n    @GeneratedValue\n    private Long id;\n\n    private String name;\n\n    private boolean deleted;\n}\n```\n`@SQLDelete`는 Repository의 `delete()` 메서드를 호출했을 때, 대신 호출되는 SQL을 지정해주는 어노테이션인데 이를 통해 UPDATE 방식으로 삭제 처리를 하고 `@Where`를 통해 삭제되지 않은 데이터만 조회할 수 있다.\n\n이렇게 해서 SoftDelete를 구현할 수 있었지만, Hibernate 6.4 버전부터는 JPA에서 공식적으로 이를 SoftDelete를 지원하도록 하는 `@SoftDelete` 어노테이션을 제공한다.\n\n## 1. @SoftDelete\n\nSpring Data JPA 경우 3.2.1 이상, Hibernate 6.4 이상부터 지원한다.\n\n```java\nimport org.hibernate.annotations.SoftDelete;\n\n@Entity\n@SoftDelete(columnName = \"deleted\")\npublic class Member {\n    @Id\n    @GeneratedValue\n    private Long id;\n\n    private String name;\n}\n```\n\n`@SoftDelete` 어노테이션을 사용하면 JPA가 자동으로 bool 타입의 `deleted` 컬럼을 추가하고 delete() 메소드 호출 시 `deleted` 컬럼을 true로 변경해주는 쿼리를 자동으로 생성해준다.\n`@SoftDelete` 어노테이션을 사용하면 `@Where` 와 `@SQLDelete` 어노테이션을 사용하지 않아도 되기 때문에 코드가 간결해지고 유지보수하기 좋게 된다.\n\n`@SoftDelete`는 다음 3가지 주요 기능을 제공한다\n- `strategy` : 삭제 방식을 지정할 수 있다. (기본값은 `SoftDeleteType.DELETED`)\n- `columnName` : 삭제 컬럼의 이름을 지정할 수 있다. (기본값은 `deleted` 컬럼명)\n- `converter` : 삭제 컬럼의 데이터 타입을 지정할 수 있다. (기본값은 Bool 타입의 `TrueFalseConverter`)\n\n### 1.1 @SoftDelete 컬럼 이름 변경하기\n\n```java\nimport org.hibernate.annotations.SoftDelete;\n\n@Entity\n@SoftDelete(columnName = \"is_deleted\")\npublic class Member {\n    @Id\n    @GeneratedValue\n    private Long id;\n\n    private String name;\n}\n```\n만약에 `deleted` 컬럼의 이름을 변경하고 싶다면 `columnName` 속성을 사용하면 된다.\n\n\n### 1.2 @SoftDelete 삭제 방식 변경하기\n\n`@SoftDelete` 는 삭제 방식도 변경할 수 있다.\n\n```java\nimport org.hibernate.annotations.SoftDelete;\nimport org.hibernate.annotations.SoftDeleteType;\n\n@Entity\n@SoftDelete(strategy = SoftDeleteType.ACTIVE)\npublic class Member {\n    @Id\n    @GeneratedValue\n    private Long id;\n\n    private String name;\n}\n```\n\n`SoftDeleteType.ACTIVE` 는 `true`이면 삭제되지 않는 것 즉 활성화된 것을 의미한다.\n`SoftDeleteType.DELETED`는 기본 전략인데 `true`이면 삭제된 것을 의미하고 `false`이면 삭제되지 않은 것을 의미한다.\n\n\n### 1.3 @SoftDelete Converter를 이용해 BOOL이 아닌 다른 데이터 타입으로 삭제 표시하기\n\n`@SoftDelete`는 `Converter`를 통해 `Bool` 타입이 아닌 다른 데이터 타입으로 삭제 표시 할 수 있다.\n\n```java\nimport org.hibernate.annotations.SoftDelete;\nimport org.hibernate.annotations.SoftDeleteType;\nimport org.hibernate.type.YesNoConverter;\n\n@Entity\n@SoftDelete(strategy = SoftDeleteType.ACTIVE, converter = YesNoConverter.class)\npublic class Member {\n    @Id\n    @GeneratedValue\n    private Long id;\n\n    private String name;\n}\n```\n`YesNoConverter`를 사용하면 `Y`와 `N` 문자로 삭제 표시를 할 수 있다.\n\n그리고 여러 Convert를 사용해 다르게 삭제 표시를 할 수 있다.\n\n`NumericBooleanConverter` : `1`과 `0`으로 삭제 표시를 할 수 있다.\n\n`TrueFalseConverter` : `true`와 `false`로 삭제 표시를 할 수 있다.\n\n## 2. 기존 @Where 와 @SQLDelete 방식에서 @SoftDelete 방식으로 변경하기\n\n기존 `@Where` 와 `@SQLDelete` 방식에서 `@SoftDelete` 방식으로 변경하고 싶다면 \n\n```java\n\n@Entity\n@SoftDelete // 추가\n// @Where(clause = \"deleted = false\") // 제거\n// @SQLDelete(sql = \"UPDATE member SET deleted = true WHERE id = ?\") // 제거\npublic class Member {\n    @Id\n    @GeneratedValue\n    private Long id;\n\n    private String name;\n\n    // private boolean deleted; // @SoftDelete 어노테이션을 사용하면 deleted 컬럼을 추가하지 않아도 된다.\n}\n```\n`@SoftDelete` 어노테이션을 추가하고 `@Where` 와 `@SQLDelete` 어노테이션을 제거하면 간단하게 된다.\n\n## 3. ManyToOne 관계에서 SoftDelete 사용하기 위해선\n\nManyToOne 관계에서 `@SoftDelete`를 사용하려면 즉시 전략으로 연관 관계를 조회해야한다.\n\n```java\n@Entity\n@SoftDelete\npublic class Member { \n    ...\n}\n\n@Entity\npublic class Post {\n    @Id\n    @GeneratedValue\n    private Long id;\n\n    private String content;\n\n    @ManyToOne(fetch = FetchType.EAGER)\n    private Member member; // 즉시 로딩 (SoftDelete)\n}\n```\n\n만약에 지연 로딩 전략을 사용하면 `@SoftDelete`를 사용할 수 없다. 컴파일 시 다음과 같은 `UnsupportedMappingException` 예외가 발생한다.\n```\nUnsupportedMappingException: To-one attribute cannot be mapped as LAZY as its associated entity is defined with @SoftDelete\n```\n\n\n일반적으로 @ManyToOne에서 가리키는 엔티티(One쪽)가 삭제되면 지연 로딩 시 `EntityNotFoundException`이 발생하는데\n`FetchType.EAGER`로 변경하면 초기화 시 엔티티를 가져오고 프록시가 호출되지 않으므로 작동하게 된다.\n그리고 해당 엔티티를 사용하게 되면 삭제되었기 때문에 DB에 조회되지 않고 `null`을 반환하게 된다.\n\n따라서 `@ManyToOne` 관계에서 `@SoftDelete`를 사용하려면 **즉시 로딩 전략**을 사용해야한다.\n\n![alt text](image.png)\n조회 시 JOIN ON 절에 `is_deleted=false` 조건이 추가되어 삭제되지 않은 데이터만 조회되는 모습이다.\n\n즉시 전략으로 N+1 문제를 방지할 수 있으나, Many 쪽에서 연관객체 조회 시 별도의 `null` 체크를 해야하고 `@SoftDelete`를 적용한 엔티티는 연관 관계 조회 시 성능적으로 잘 고려해서 사용해야한다.\n\n## 4. Flyway를 사용하고 있다면\n\n만약에 Flyway를 사용하고 있어 JPA가 자동으로 DDL(ddl-auto)을 생성하지 않는다면\nFlyway가 자동으로 `deleted` 컬럼을 추가하지 않으므로 **`@SoftDelete`를 사용하려면 `deleted` 컬럼을 직접 추가해야한다.**\n\n```sql\nALTER TABLE member ADD COLUMN deleted BOOLEAN DEFAULT FALSE;\n```\n\n만약 기존에 `is_deleted` 컬럼으로 SoftDelete를 직접하고 있고 `@SoftDelete`를 적용하게 된다면\n\n```java\nimport org.hibernate.annotations.SoftDelete;\n\n@Entity\n@SoftDelete(columnName = \"is_deleted\")\npublic class Member {\n    @Id\n    @GeneratedValue\n    private Long id;\n\n    private String name;\n\n    // private boolean is_deleted; // @SoftDelete 어노테이션을 사용하면 is_deleted 컬럼을 추가하지 않아도 된다.\n}\n```\n\ncolumnName 속성을 사용해 컬럼 이름을 변경하면 지정된 `is_deleted` 컬럼으로 JPA는 삭제 처리를 한다.\n\n## 레퍼런스\n- [Hibernate 6.4 Release Note](https://hibernate.org/orm/releases/6.4/)\n- [Hibernate 6.4 SoftDelete API](https://docs.jboss.org/hibernate/orm/6.4/javadocs/org/hibernate/annotations/SoftDelete.html)\n- [Hibernate 6.4 UserGuide](https://docs.jboss.org/hibernate/orm/6.4/userguide/html_single/Hibernate_User_Guide.html)\n- [https://www.baeldung.com/java-hibernate-softdelete-annotation](https://www.baeldung.com/java-hibernate-softdelete-annotation)","excerpt":"기존에는 SoftDelete를 구현할려면 @Where 와 @SQLDelete 를 사용했어야했다. 는 Repository의  메서드를 호출했을 때, 대신 호출되는 SQL을 지정해주는 어노테이션인데 이를 통해 UPDATE 방식으로 삭제 처리를 하고 를 …","fields":{"slug":"/jpa-softdelete-annotation/"},"frontmatter":{"date":"Mar 28, 2024","title":"Hibernate 6.4 부터 SoftDelete를 공식적으로 지원한다","tags":["Spring","JPA","Hibernate"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"![alt text](image-1.png)\n\n매번 개발 서버나 프로덕션 서버에 배포 한 후 따로 팀원들에게 \"서버 방금 올렸습니다~\" 라고 전하는게 귀찮을 수 있다. \n우아하고 개발자스럽게 불필요한 행위없이 서버가 정상적으로 배포되면 자동으로 디스코드에 알림을 보내는 서비스를 만들어보자.\n\n일단 배포 알리미에 대한 기능 요구사항은 다음과 같다.\n- 서버가 정상적으로 작동하는지 판별할 수 있어야 한다.\n- 서버가 정상 작동하면 Webhook을 이용해 메시지를 보낼 수 있다.\n- 여러 환경에 따라 알리미가 작동할 수 있으면 한다.\n\nWebhook 전송 방식은 필자가 예전에 작성한 [[SpringBoot] 디스코드 WebHook으로 알림 보내기](https://seonghoon.xyz/springboot-disord-webhook/)를 참고하면 더 좋다.\n\n## Prerequisite\n- 디스코드 채널 웹훅 URL\n- Spring 기반의 서버\n\n추가적인 라이브러리를 사용하지 않고 스프링이 제공하는 기능만으로 기능을 구현할 것 이다.\n\n## 서버 정상 작동 판별하기\n\n우선 서버 작동에 이상이 없는지 알 수 있는 방법을 알아보자.\n\n### 헬스체크 API\n일반적으로 서버를 배포하면 데이터베이스나 여러 서버와 통합적으로 연결이 끝난 후 API가 정상 호출이 되는지 확인한다. \n여러 API가 있겠지만 아주 간단하게 헬스체크 용도의 GET 방식 API를 만들어보자.\n\n\n```java\n@RestController  \n@RequestMapping(\"/api/test\")  \npublic class TestController {  \n  \n    @GetMapping  \n    public String test() {  \n        return \"Good\";  \n    }  \n}\n```\n\n`/api/test` URL로 GET 요청을 보내면 서버에서 `Good` 이라는 문자열을 반환하는 아주 간단한 API 이다.\n\n서버가 잘 동작하고 해당 URL로 요청을 보내면 언제든지 `Good` 이라는 메시지를 통해 잘 돌아가는구나 라고 안심할 수 있는 API 이다.\n\n그러면 이 API를 언제 호출해야할까?\n개발자가 직접 서버가 작동되면 주기적으로 API 요청을 보내는 것은 매우 효율적이지 못하다\n따라서 스프링에서 제공하는 기능을 이용해 자동으로 API 요청을 보내도록 해보자.\n\n### API 자동 호출\nJava를 이용해 코드를 작성해본 분들은 잘 알다시피 main() 메소드가 프로그램의 진입점이다.\n\n```java\n@SpringBootApplication  \npublic class WebApplication {  \n  \n    public static void main(String[] args) {  \n\t    SpringApplication.run(WebApplication.class, args);  \n    }\n}\n```\n\n위 코드는 스프링 부트 프로젝트 생성 시 기본적으로 생성되는 코드이다.\n\n서버를 실행하면 main 함수의 `SpringApplication.run()` 메소드를 통해 스프링 컨테이너가 생성되어 Bean을 등록하고 의존성을 주입하는 여러 작업들이 수행된다.\n\n혹시 `run()` 메소드 다음 라인을 디버깅 해본적 있는가?\n당장 IDE를 켜서 `run()` 다음으로 아무 로그를 출력해보자. 스프링이 정상적으로 실행된 후 제일 마지막에 로그가 출력 될 것이다.\n스프링을 이용해 개발하다보면 main 함수를 건드리는 일이 대부분 없고 스프링 컨테이너 덕분에 직접 인스턴스를 main에서 생성하고 의존성을 주입하는 일이 없다 (DI 와 Bean 덕분에) \n\n하지만 main 함수에서 스프링 컨테이너가 생성되고 Bean이 등록된 후에 특정 작업을 수행하게 할 수 있다.\n우선 배포 알림을 전송하는 서비스를 만들어보자.\n\n## 배포 알림 서비스 구현하기\n\n### DeployAlertService 클래스\n\n```java\n@Slf4j  \npublic class DeployAlertService {  \n  \n    @Value(\"${webhook.url}\")  \n    private String webhookUrl;  \n  \n    @Value(\"${spring.profiles.active}\")  \n    private String activeProfile;  \n  \n    public void deployAlert() {  \n        try {  \n            RestTemplate restTemplate = new RestTemplate();  \n            healthCheck(restTemplate);  \n            webHook(restTemplate, makeMessage());  \n        } catch (Exception e) {  \n            log.warn(e.getMessage());  \n        }  \n    }  \n  \n    private void healthCheck(RestTemplate restTemplate) {  \n        String url = \"http://localhost:8080/api/test\";  \n        String result = restTemplate.getForObject(url, String.class);  \n  \n        assert result != null;  \n        if (!result.equals(\"Good\")) {  \n            throw new RuntimeException(\"서버가 정상적으로 배포되지 않았습니다.\");  \n        }  \n    }  \n  \n    private String makeMessage() {  \n        String json = \"\"\"\n\t        {\n\t\t        \"content\": \"%s 환경 서버가 정상적으로 배포되었습니다.\"\n\t        }\n        \"\"\";\n        String message = String.format(json, activeProfile);\n        return message;  \n    }\n  \n    private void webHook(RestTemplate restTemplate, String message) {  \n        HttpHeaders headers = new HttpHeaders();  \n        headers.setContentType(MediaType.APPLICATION_JSON);  \n  \n        HttpEntity<String> entity = new HttpEntity<>(message, headers);  \n        String string = restTemplate.postForObject(webhookUrl, entity, String.class);  \n        if (string != null) {  \n            throw new RuntimeException(\"웹훅 전송에 실패하였습니다.\");  \n        }  \n    }  \n}\n```\n\n`deployAlert()` 메소드를 이용해 테스트 API 호출하고 API 응답이 정상이면 서버가 정상작동하는 것이므로 \njson 형식의 메시지를 만들고 프로필을 담아 Webhook을 전송하게 된다.\n\n테스트 API 호출과 WebHook시  Spring 에서 제공하는 `RestTemplate`을 이용하여 HTTP 요청을 보내게된다.\n\n해당 클래스는 스프링 컨테이너에 등록되어야 하므로 Bean으로 등록해야 한다.\n\n### Bean 등록\n\n스프링에서 어떤 객체를 Bean으로 등록하기 위해선 `@Configuration`가 달린 설정 클래스에서 `@Bean`을 이용하거나 `@Component`를 클래스에 부착한다. 별도의 설정 클래스를 만들어야 하는데 `@SpringBootApplication` 어노테이션 내부를 살펴보면 `@Configuration` 어노테이션이 내장되어있고 그 말은 메인 함수가 위치한 WebApplication 클래스에서 `@Bean` 어노테이션을 이용해 Bean을 등록할 수 있다.\n\n```java\n@SpringBootApplication  \npublic class WebApplication {  \n  \n    public static void main(String[] args) {  \n        SpringApplication.run(WebApplication.class, args);    \n    }\n  \n    @Bean  \n    public DeployAlertService deployAlertService() {  \n        return new DeployAlertService();  \n    }\n}\n```\n\n그러면 `DeployAlertService` 클래스는 Bean으로 등록되어 스프링 컨테이너가 관리하게 되는데 해당 Bean을 사용할려면 스프링 컨테이너에게 요청을 해야한다.\n\n### 스프링 컨테이너에게 요청하기\n```java\npublic static void main(String[] args) {  \n    var context = SpringApplication.run(ArtBackendApplication.class, args);  \n  \n    if (context.containsBean(\"deployAlertService\")) {  \n        context.getBean(DeployAlertService.class).deployAlert();  \n    }  \n}\n```\n\n`run()` 메소드의 반환은 스프링 컨테이너 이므로 bean을 사용할 수 있도록 로직을 작성할 수 있다 컨테이너으로 부터 Bean을 가져와 배포 알림 메소드를 호출한다.\n\n이렇게 하여 스프링 서버 실행 시 여러 작업 이후에 `DeployAlertService` 클래스의 `deployAlert()` 메소드가 호출되어 Webhook을 통해 알림을 전송하게 된다.\n\n### 배포 환경에 따라 알림 전송하기\n\n개발환경이나 프로덕션 환경에서 서버 배포 시 호출하게 할려면 Spring 에서 제공하는 Profile 설정을 이용해야 한다.\n\n```java\n@Bean  \n@Profile({\"dev\", \"prod\"})  // dev, prod 환경에서 Bean을 생성한다.\npublic DeployAlertService deployAlertService() {  \n    return new DeployAlertService();  \n}\n```\n\n위와 같이 `@Profile` 어노테이션을 이용해 `spring.profiles.active` 옵션에 따라 Bean이 생성되게 할 수 있다.\n\n자 그러면 이제 `application.properties` 파일에 Webhook URL 등록하고 프로필을 설정해보자.\n\n```properties\nspring.profiles.active=dev\nwebhook.url=...\n```\n\n이제 서버가 정상적으로 배포되면 디스코드에 알림이 전송된다.\n\n## 실행 결과\n![alt text](image.png)\n\n기본적으로 위와 같은 형식으로 알림 메시지가 전송되는데\n\n![alt text](image-2.png)\n\n[디스코드 공식 Webhook 문서](https://discord.com/developers/docs/resources/webhook) 참고하면 여러 형식으로 메시지를 전송할 수 있다.\n\n# 마치며\n\n이번 포스트를 통해 스프링 컨테이너가 생성된 후에 특정 작업을 수행하는 방법과 스프링 프로파일을 이용해 Bean을 생성하는 방법을 알아보았다.\n또한 이러한 방식을 이용해 서버가 정상적으로 배포되면 Webhook 알림을 전송하는 서비스를 구현해보았다.\n\n해당 방식은 간단하게 스프링 컨테이너가 정상적으로 생성 된 후 알림을 전송하는 것이라 어떤 이유로 스프링 배포가 실패한다면 알람을 전송할 수 없다.\n실제 운영 환경을 모니터링하는것은 매우 안정적으로 동작해야하므로 여러 모니터링 서비스가 다양하게 있으므로 이러한 서비스를 이용하는게 더 좋을 수 있다.\n","excerpt":"매번 개발 서버나 프로덕션 서버에 배포 한 후 따로 팀원들에게 \"서버 방금 올렸습니다~\" 라고 전하는게 귀찮을 수 있다. \n우아하고 개발자스럽게 불필요한 행위없이 서버가 정상적으로 배포되면 자동으로 디스코드에 알림을 보내는 서비스를 만들어보자. 일단…","fields":{"slug":"/spring-deploy-alert/"},"frontmatter":{"date":"Mar 07, 2024","title":"[Spring] 서버가 정상적으로 배포되면 알림을 보낼 수 있는 서비스 구현하기","tags":["Spring","Webhook"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\nSpring에서는 `@Component`, `@Autowired`를 이용하여 Bean을 등록하고 의존성을 주입하는 방법을 사용한다. 하지만 해당 어노테이션을 이용하지 않고 스프링 컨테이너에 Bean을 등록하고 의존성을 주입하는 방법이 있다.\n\n## 1. Context and Dependency Injection (CDI)란?\n![alt text](image.png)\nContext and Dependency Injection (CDI)를 이용하면 `@Component`, `@Autowired`를 이용하지 않고 Bean을 등록하고 의존성을 주입할 수 있다.\n\nCDI는 자바 엔터프라이즈 애플리케이션(EE)개발을 위한 스펙이며, Java EE (현재는 Jakarta EE)에서 사용되는 기술 중 하나이다. CDI는 컨텍스트와 의존성 주입을 통해 관리되는 Component-Based Application을 지원하고,\n여러 Java EE 컴포넌트간에 통합적으로 사용할 수 있는 컨텍스트와 의존성 주입을 지원한다.\n\n즉 `의존성 주입`을 수행하는데 사용할 수 있는 표준 스펙(인터페이스)이다\n\n- CDI에는 Injection 관련 API 어노테이션이 정의되어 있다.\n\t- @**Inject** (스프링의 @Autworired )\n\t- @**Named** (스프링의 @Component)\n\t- @Qualifier \n\t- @Scope\n\t- @Singleton\n\n\n## 2. CDI를 이용한 Bean 등록 및 의존성 주입\nSpring Framework에서는 Bean으로 등록하기 위해선 @Component 어노테이션을 사용한다. 또한 의존성 주입을 위해 @Autowired 어노테이션을 사용한다.\n\nCDI를 이용하면 해당 어노테이션을 사용하지 않고 Bean을 등록하고 의존성을 주입할 수 있다.\n\n### 2.1 의존성 추가\nCDI를 사용하기 위해서는 jakarta.inject-api 의존성을 추가해야 한다.\n\nMaven을 사용한다면\n```xml\n        <dependency>\n            <groupId>jakarta.inject</groupId>\n            <artifactId>jakarta.inject-api</artifactId>\n            <version>2.0.1</version>\n        </dependency>\n```\n\nGradle을 사용한다면\n```groovy\nimplementation 'jakarta.inject:jakarta.inject-api:2.0.1'\n```\n\n### 2.2 Component 등록\nCDI를 이용하여 Bean을 등록하기 위해서는 `@Named` 어노테이션을 사용한다.\n\n```java\nimport jakarta.inject.Named;\n\n@Named\npublic class MyBean {\n    public String sayHello() {\n        return \"Hello\";\n    }\n}\n``` \n\n### 2.3 의존성 주입\nCDI를 이용하여 의존성을 주입하기 위해서는 `@Inject` 어노테이션을 사용한다.\n\n```java\nimport jakarta.inject.Inject;\n\n@Named\npublic class MyService {\n    @Inject\n    private MyBean myBean;\n\n    public String sayHello() {\n        return myBean.sayHello();\n    }\n}\n```\n\n### 2.4 Main Application\n\n스프링 컨테이너를 생성하고 `@Named`로 선언한 클래스들을 Bean으로 가져와 사용할 수 있다.\n또한 `@Inject`로 선언한 필드에 의존성이 주입된다.\n\n```java\n@Configuration\n@ComponentScan\npublic class CdiContextApplication {\n\n    public static void main(String[] args) {\n        try (var context = new AnnotationConfigApplicationContext(CdiContextApplication.class)) {\n            Arrays.stream(context.getBeanDefinitionNames())\n                    .forEach(System.out::println); // MyBean, MyService\n\n            System.out.println(context.getBean(MyService.class).sayHello()); // Hello\n        }\n    }\n}\n```\n\n### 2.5 실행결과\n```sh\norg.springframework.context.annotation.internalConfigurationAnnotationProcessor\norg.springframework.context.annotation.internalAutowiredAnnotationProcessor\norg.springframework.context.annotation.internalCommonAnnotationProcessor\norg.springframework.context.event.internalEventListenerProcessor\norg.springframework.context.event.internalEventListenerFactory\ncdiContextApplication\nmyBean\nmyService\nHello # MyService.sayHello() 메소드 실행결과\n```\n스프링 컨테이너에 MyBean, MyService가 Bean으로 등록되어 있고 `myService.sayHello()` 메소드를 실행하면 `myBean.sayHello()` 메소드가 실행되어 \"Hello\"가 출력된다. 정상적으로 Bean이 등록되고 의존성이 주입된 것을 확인할 수 있다.\n\n## 3. 스프링에선 어떻게 CDI 어노테이션이 부착된 클래스를 Bean으로 인식하는 걸까? (@ComponentScan 동작원리)\n\n스프링 컨테이너를 생성할 때 `@ComponentScan` 어노테이션을 사용하여 스캔할 패키지를 지정한다. 일반적으로 스프링 컨테이너는 해당 패키지를 스캔하여 `@Component` 어노테이션이 붙은 클래스를 찾아 Bean으로 등록한다.\n\n하지만 `@Named` 어노테이션은 스프링에서 제공하는 어노테이션이 아니기 때문에 컴포넌트 스캔 시 어떻게 인식하는지 코드를 확인해보자.\n\n우선 스프링 컨테이너 내부를 살펴보자 (`AnnotationConfigApplicationContext`)\n\n```java\n// AnnotationConfigApplicationContext (스프링 컨테이너) 내부에 멤버 변수를 보면 ClassPathBeanDefinitionScanner가 있다.\npublic class AnnotationConfigApplicationContext extends GenericApplicationContext implements AnnotationConfigRegistry {\n\n\tprivate final AnnotatedBeanDefinitionReader reader;\n\n\tprivate final ClassPathBeanDefinitionScanner scanner; // scanner.doScan() 메소드를 통해 컴포넌트 후보를 찾는다.\n\n    // ...\n\n}\n```\nComponentScan 시 Component 어노테이션이 붙은 클래스를 찾아 Bean으로 등록하는데 해당 기능을 수행하는 클래스는 \n스프링 프레임워크에서 제공하는 `ClassPathBeanDefinitionScanner` 클래스이다. \n\n`scanner.doScan()` 메소드를 통해 컴포넌트 후보를 찾는다.\n\n해당 클래스의 `doScan()` 메소드는 스프링 컨테이너의 생성방식에 따라 호출되는 경로가 다르지만 \n```java\n@Configuration\n@ComponentScan\npublic CdiContextApplication {\n    public static void main(String[] args) {\n        var context = new AnnotationConfigApplicationContext(CdiContextApplication.class);\n        // ...\n    }\n}\n```\n\n`@Configuration` 어노테이션을 기반으로 스프링 컨테이너를 생성했다면 `AnnotationConfigApplicationContext(Class<?>... componentClasses)` 생성자에 의해 `refresh()` 메소드 내부에서 `doScan()` 이 호출된다.\n\n\n`doScan()` 메소드 내부를 살펴보자.\n```java\npublic class ClassPathBeanDefinitionScanner extends ClassPathScanningCandidateComponentProvider {\n\n    // ...\n\n    // doScan() 메소드를 통해 컴포넌트를 찾는다.\n    protected Set<BeanDefinitionHolder> doScan(String... basePackages) {\n        // ...\n        Set<BeanDefinitionHolder> beanDefinitions = new LinkedHashSet<>();\n        for (String basePackage : basePackages) {\n            Set<BeanDefinition> candidates = findCandidateComponents(basePackage); // 컴포넌트 후보를 찾는다. \n            // (이때 어노테이션을 기반으로 클래스를 Bean 후보로 등록함)\n            for (BeanDefinition candidate : candidates) {\n                // ...\n                beanDefinitions.add(beanDefinitionHolder);\n            }\n        }\n        return beanDefinitions;\n    }\n}\n```\n`doScan()` 메소드 내부에서는 `findCandidateComponents()` 메소드를 통해 컴포넌트 후보를 찾는다.\n해당 메소드는 상속받은 `ClassPathScanningCandidateComponentProvider` 클래스의 메소드이다.\n\n해당 클래스를 살펴보자.\n\n```java\npublic class ClassPathScanningCandidateComponentProvider implements EnvironmentCapable, ResourceLoaderAware {\n\n    // includeFilters에 등록된 어노테이션을 기반으로 클래스를 찾는다.\n    private final List<TypeFilter> includeFilters = new ArrayList<>(); \n\n    // ...\n\n    // 해당 메소드를 통해 includeFilters에 기본적으로 인식할 어노테이션을 등록하는데 살펴보면 @Component 어노테이션, @ManagedBean 어노테이션, @Named 어노테이션을 필터로 등록되있다.\n\tprotected void registerDefaultFilters() {\n\t\tthis.includeFilters.add(new AnnotationTypeFilter(Component.class));\n\t\tClassLoader cl = ClassPathScanningCandidateComponentProvider.class.getClassLoader();\n\t\ttry {\n\t\t\tthis.includeFilters.add(new AnnotationTypeFilter(\n\t\t\t\t\t((Class<? extends Annotation>) ClassUtils.forName(\"jakarta.annotation.ManagedBean\", cl)), false));\n\t\t\tlogger.trace(\"JSR-250 'jakarta.annotation.ManagedBean' found and supported for component scanning\");\n\t\t}\n\t\tcatch (ClassNotFoundException ex) {\n\t\t\t// JSR-250 1.1 API (as included in Jakarta EE) not available - simply skip.\n\t\t}\n\t\ttry {\n\t\t\tthis.includeFilters.add(new AnnotationTypeFilter(\n\t\t\t\t\t((Class<? extends Annotation>) ClassUtils.forName(\"jakarta.inject.Named\", cl)), false));\n\t\t\tlogger.trace(\"JSR-330 'jakarta.inject.Named' annotation found and supported for component scanning\");\n\t\t}\n\t\tcatch (ClassNotFoundException ex) {\n\t\t\t// JSR-330 API not available - simply skip.\n\t\t}\n\t}\n\n    // ...\n\n\n    // 해당 메소드를 통해 includeFilters에 등록된 어노테이션을 기반으로 클래스가 컴포넌트 인지 판별한다\n\tprotected boolean isCandidateComponent(MetadataReader metadataReader) throws IOException {\n\t\tfor (TypeFilter tf : this.excludeFilters) {\n\t\t\tif (tf.match(metadataReader, getMetadataReaderFactory())) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tfor (TypeFilter tf : this.includeFilters) {\n\t\t\tif (tf.match(metadataReader, getMetadataReaderFactory())) { // @Component,@ManagedBean, @Named 어노테이션이 등록된 클래스인지 확인한다.\n\t\t\t\treturn isConditionMatch(metadataReader);\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n}\n\n```\n\nisCandidateComponent() 메소드를 통해 includeFilters에 등록된 어노테이션을 이용하여 metadataReader (패키지에 있는 클래스 정보) 와 filter를 하나씩 match 하면서 컴포넌트 후보 판별을 수행한다, 즉 스캔된 클래스가 Component 후보 인지 판별하게 된다.\n\nincludeFilters는 List<TypeFilter> 타입으로 기본적으로 `@Component`, `@ManagedBean`, `@Named` 어노테이션을 필터로 등록되어 있다.\n\n즉 `@Named` 어노테이션이 스프링 컨테이너에 Bean으로 등록되는 이유는 `ClassPathBeanDefinitionScanner` 클래스 내부에서 `ClassPathScanningCandidateComponentProvider` 클래스를 통해 `@Named` 어노테이션이 등록된 클래스를 찾아 Bean으로 등록하기 때문이다.\n\n## 4. 마무리\n\nJava 표준 스펙인 CDI를 이용해 여러 Java EE 컴포넌트간에 통합적으로 사용할 수 있는 컨텍스트와 의존성 주입을 지원하는 방법을 알 수 있다.\n\n해당 방법을 꼭 알고 사용할 필요는 없지만 Java 진영에서 예전부터 이러한 기술을 표준 스펙으로 제공하고 있었음을 알 수 있다.\n따라서 Spring Framework가 아닌 Java 진영의 여러 IoC 컨테이너를 사용할 때 해당 기술을 사용할 수 있다.\n\n","excerpt":"Spring에서는 , 를 이용하여 Bean을 등록하고 의존성을 주입하는 방법을 사용한다. 하지만 해당 어노테이션을 이용하지 않고 스프링 컨테이너에 Bean을 등록하고 의존성을 주입하는 방법이 있다. 1. Context and Dependency In…","fields":{"slug":"/jakarta-injection-api/"},"frontmatter":{"date":"Feb 22, 2024","title":"@Component, @Autowired를 이용하지않고 CDI API를 이용해 @Bean 등록 및 의존성 주입하는법 그리고 @ComponentScan 동작원리","tags":["Spring"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n벌써 12월 상반기 회고를 작성한게 얼마안된거 같은데 이제 하반기 회고를 작성할 시기가 되었다.\n이전 회고와 달리 미루지 않고 글을 올리려고 마음을 먹어서.. 올 한해 내가 무엇을 얻고 깨닫게 되었는지 얘기해볼려고 한다.\n\n## 본격 취준생\n\n여름방학 8월달 부터 취준을 시작했다.\n`개발자는 무조건 서울이다` 라는 생각을 가지고 서울권에 있는 여러 회사에 지원해보고 이 중 몇 군데 면접과 좋은 결과를 받았다. 그 중 좋은 결과를 받거나 영향을 받은 회사에 대해 얘기 해볼려고 한다.\n\n이 중 AI 스타트업은 개인적으로 고민도 많이하고 결정을 내렸다.\n서울 중심에서 근무를 하게되는데 준비 과정에서 회사에 대한 얘기를 많이 찾아보고 보게되었는데 금전적인 보상이 많이 아쉽다는 말이 나왔다. 월급이 밀린다는게 큰 문제점이라 입사 프로세스를 포기했다.\n\n서울에서 취직을 하는 목표를 달성 하겠지만 금전적 보상이 밀린다는 것은 나에겐 하이 리스크이다. 스타트업이라 역량을 키우기에는 좋겠지만 서울 스타트업이나 지방 스타트업이나 좋은 아이템으로 회사를 운영한다면 차이가 없다고 생각한다. 그리고 나는 지방에 있는 대학교에서 생활하고 지방에서 생활하는 사람이다. 즉 서울에 집이 없다 이게 큰 문제점이다.\n\n불확실한 미래에 투자하기에는 내가 금전적으로 가진게 많이 없다. 그래서 포기하게 되었다\n\n이후 인프랩 서류 전형을 합격했고 과제 전형을 진행했다.\n과제는 인프런의 기술 스택을 적용해 요구조건에 맞는 프로젝트를 구현하게 되었다.\n이때까지 스프링에 대한 역량을 키우고 있었지만 백엔드 개발자가 지녀야할 기본적인 원리를 이해한다면 NodeJs 라도 충분히 할 수 있겠다고 생각해서 전형을 진행했다.\n\n올해 3월에는 NestJs로 졸업작품을 진행했었고, 에트리 인턴때도 NodeJs로 백엔드 서버를 개발했었으니 기본적인 구현은 가능했다.\n\n그렇게 과제를 제출하게 되었고 결과를 기다리니 합격 했고 면접을 보라고 메일이 왔다.\n\n![Alt text](1.png)\n\n그렇게 백엔드 개발을 공부하는 학생이라면 대부분 알고 있을 이동욱([기억보단 기록을 블로그](https://jojoldu.tistory.com/))님을 만나 뵙게되었다.\n\n처음으로 개발자 도시 판교에 가게 되었고 두근두근 하는 마음으로 면접에 임하게 되었다 3분이 참석하셨고 이력서와 내가 제출한 과제를 기반으로 여러 질문이 오갔다. \n\n좋은 영향을 주시는 분들과 얘기를 하게 되어서 매우 좋은 경험과 기회였고 개인적으로 취준을 위한 역량이 아직 안올라왔다고 생각해 많이 아쉬웠지만 다음에도 기회가 있다면 가고싶은 회사라 생각이 든다.\n\n그렇게 해서 바쁜 여름방학이 흘러가게되었다.\n\n## 아트스코프는 꾸준히 성장 중\n10월달 부터 아트스코프에 새로운 백엔드 개발자가 합류하게 되었다.\n백엔드 길을 걷게된 시기가 6개월도 안된 후배인데 인턴 느낌으로 참여하게 되었다.\n개인적으로 아트스코프 백엔드를 혼자 하다보니 피로감이 매우 컸었는데 덕분에 많이 부담을 덜게 되었다.\n\n온보딩을 시작했고 프로젝트에서 사용하는 기술스택에 대해 개념을 설명해 드렸다. 그리고 전체적인 서버 구성과 데이터베이스 모델에 대해서도 알려드렸다. \n그리고 본격적으로 Task를 배정했다.\n\n백엔드 개발 시작이 얼마 안되셨지만 잘 따라오셨고 좋은 성과를 내셨다.\n덕분에 기능 구현이 우선이였던게 이제는 설계와 리팩터링을 더욱더 집중해서 할 수 있게 되었다.\n\n그렇게 해서 아트스코프는 더욱 더 예술 플랫폼을 확장하고 정체성을 가꾸게 되었다.'\n\n![Alt text](<2.png>)\n\n\nElasticsearch를 이용한 통합검색과 도메인 별 `검색 기능`이 추가되었다.\n기존에 검색 기능은 있었다. MySQL RDB 상에서 LIKE 절을 사용해 검색어를 포함하는 게시글과 작품을 검색하는 기능이였다. 향후 많은 글과 작품이 여러개 추가될 것을 고려했고 또한 `LIKE '%...'` 인덱스를 사용하지 못하므로 더 나은 검색을 도입해야한다고 생각했다. \n\n그렇게 해서 Elasticsearch를 도입했다.\n그냥 도입만 해서 검색 API를 개선해서 사용하는게 아닌 기존에 가지고 있던 게시글과 작품 여러 도메인 문서들을 검색엔진에 추가하는 과정이 필요했다.\n\n그렇게 해서 Logstash를 이용해서 주기적으로 SQL문을 이용해 MySQL 데이터를 스크랩해 ES에 저장해주는 데이터 파이프라인을 구축했고 현재 잘 사용하고 있다.\n\n이 관련 내용은 메가콘(학술동아리 기술 컨퍼런스)에서 발표도 했고 관련 영상도 있다.\n추후에 블로그에 검색 관련 게시글을 작성할 예정이다.\n\n![Alt text](<3.png>)\n그리고 이벤트가 추가되었다.\n여러 전시와 행사들을 모아서 보여주는 기능인데 간단해 보이지만 생각보다 많은 시간을 쏟았다.  \n\n![Alt text](<4.png>)\n\n이벤트에는 장소도 포함이 되어야하고 여러 일정을 하루 단위로 작성할 수 있도록 했어야 했다. 이렇게 해서 완성된 모습은 위 사진처럼 나오게 되는데 현재는 일부 요구사항이 변경되어 바뀔 예정이다.\n\n전시에 관심이 있거나 여러 예술 이벤트를 쉽게 접할 수 있도록 관람 일정을 하루 단위로 뿌리도록 하였고 원하는 일정을 캘린더에 추가해서 참가를 유도할 수 있도록 하였다.\n\n해당 도메인은 새로 참가한 인턴 후배가 구현했다. 과정 속에는 여러 기술적인 얘기를 많이 했었고 최선의 방향으로 백엔드 개발을 진행할 수 있도록 이끌었다.\n\n마지막으로 `아고라`가 추가되었다.\n아트스코프 참가하시는 분들과 오프라인 미팅에서 이런 저런 아이디어를 얘기를 하다가 학교에서 트렌드 코리아 공저자의 강연을 참석했었는데 발표 중 일부 내용이 생각이 났었다.\n\n최근 AI 미술 작품이 미국 미술 경연에서 1등을 했다고 한다.\n많이 화두가 되었는데 예술계에서는 AI 로 인해 많은 변화가 일어나고 있다. 미팅때 관련 발표 내용과 AI 얘기를 하다가 문득 작가분들, 예술을 좋아하시는 분들의 생각이 궁금해졌다. 이런 주제로 얘기할 수 있는 공간이 있었으면 좋겠다고 얘기했었다. \n\n![Alt text](<Pasted image 20231206155525.png>)\n\n그렇게 해서 익명, 실명으로 한 주제에 대해 토론할 수 있고 투표할 수 있는 아고라를 개발하고 출시하게 되었다.\n\n현재 아트스코프는 예술가들을 위해 여러 경험을 얘기하고 영향을 줄 수 있도록 오늘 보다 내일 더 나은 사이트로 거듭나게 위해 여러 시도를 하고 있다. 개발과 기획하시는 분들이 열정페이로 일을 하고 계시는데 많은 분들이 편하게 작품을 보고 얘기할 수 있는 공간이 되었으면 한다.\n\n## 우리끼리 우아한 백엔드\n채성이([푸르고 개발 블로그](https://puleugo.tistory.com/))와 동현이(아트스코프 인턴 후배)와 함께 우아한 백엔드라는 그룹을 만들었다.\n어느 배달 플랫폼이 생각날 수 있긴한데 비슷한 느낌이다.\n\n매번 1시간 이상 우아하게 이것저것 얘기하는 모임이라 그룹명을 이렇게 짓게 되었는데 만족스럽다. \n이 모임은 조금이라도 우아하게 객체지향적인 코드를 작성할 수 있게 오브젝트 책을 함께 스터디하고 우아하게 데이터베이스의 동작 원리를 이해하고 싶어서 Real MySQL 책을 함께 읽고 얘기하는 우리끼리하는 모임이다.\n\n책을 읽고 스터디를 하는데 그냥? 하진 않는다. \n필기도 노트북이나 공책에 하지 않는다 바로 책 에다가 하고 있다.\n매번 필기를 노트나 외부 매체에 기록하다보면 책 따로 보고 필기 따로 보는 경향이 있어서 이렇게 하고 있다. 책을 보면 어떤 생각으로 적었는지 볼 수 있어서 좋은 것 같다.\n\n스터디 진행도 어떤 체계가 있지는 않다 저번 스터디때 읽었던 부분을 다시 복습하며 한명 씩 읽고 읽은 사람이 정리하고 그거에 대해서 바로 얘기하고 토론한다.\n그 후 진도를 나가는데 새로운 페이지들을 읽으며 서로의 견해를 나누고 얘기하며 또 토론하게 된다. 이해가 안되는 부분이 있다면 종이를 꺼내서 그림을 그리며 이렇게 코드가 될 것 같다, 협력이 이렇게 구성되지 않을까? 얘기하게 된다.\n\n우리는 그렇게해서 1달간 오브젝트를 3장까지 밖에 못 읽었다.\n스터디를 하면 1시간 이상은 기본적으로 얘기하게 된다. 그런데 이 스터디가 책을 다읽는게 목표가 아닌 평소의 생각과 코드를 작성할 때 바로 적용할 수 있도록 여러 얘기를 하고 있어서 책 진도와 트레이드 오프 했다.\n\n우리는 항상 왜?를 말하며 깊게 파면서 얘기하는 모임이다.\n\n사람이 적어서 이렇게 체계없이 스터디해도 많이 배우고 있고 아직까지는 어떤 템플릿이 필요하지 않고 서로 좋은 영향을 주고 있어서 우리끼리 우아하게 진행하고 있다.\n\n## 지방 컨퍼런스 참가\n지방에서는 컨퍼런스의 기회가 많이 없다 대부분 서울에서 진행한다.\n그래서 평소에 많이 아쉽다고 생각했지만 찾아보면은 좋은 컨퍼런스가 있다는 것을 깨달았다. 왜 이런곳을 미리 가지 않았을까? 라는 생각을 가지게 되었다. 내 자신이 너무 서울 서울 거리지 않는지 반성하게 되었는데 부산에도 좋은 컨퍼런스가 있다는 것을 알게되었다. (미리 좀 찾아볼걸)\n\n그래서 [센텀 디지털 위크](http://m.centumdigitalweek.com/)와 [GDG 부산 Devfest 2023](https://festa.io/events/4248) 에 참가하게 되었다.\n\n![Alt text](IMG_7630.jpeg)\n\n센텀 디지털 위크는 올해 처음으로 열리는 컨퍼런스인데 카카오페이 백엔드 개발자, LINE PM, 토스 개발자, 디자이너 등 유명한 회사에 계시는 분들이 발표를 하셨고 행사 퀄리티도 좋고 좋은 영향을 받을 수 있어 좋았다.\n\nGDG 부산은 대학교 1학년때 부터 알고있던 그룹인데 이번에 Devfest에 참가하게 되었다. 발표는 개인적으로 센텀 디지털 위크에서 인상 깊게 봐서 꽤 비교되긴 했다. 기술적으로 깊거나 내용이 인상 깊었던 것은 센텀이였고 DevFest는 발표 대부분 커뮤니티 관련 얘기였다 그래도 나름 괜찮았다 다음에도 가보고 싶다.\n\n이런 컨퍼런스가 앞으로도 많이 기획되고 열렸으면 좋겠다고 생각했다. 그리고 후배 학생 개발자분들이 이런곳을 앞으로 많이 가서 네트워킹하면서 작은 우물에서 큰 바다로 갔으면 한다.\n\n## 올해 마무리는 메가콘\n\n작년에 이어 올해도 교내 학술동아리 메가브레인에서 메가콘 기술 컨퍼런스를 열었다. 작년에는 동아리의 과거, 현재, 미래 시스템에 대해서 그리고 Spring Security 인증과 인가 동작에 대해서 발표를 했었고 올해는 Elasticsearch를 이용한 검색 개발을 발표하게 되었다. 발표 영상도 있다.\n\n[![](https://img.youtube.com/vi/1SX-sG26jIk/0.jpg)](https://youtu.be/1SX-sG26jIk)\n([유튜브 링크](https://youtu.be/1SX-sG26jIk))\n\n외부 컨퍼런스에 참가하면서 좋은 영향을 받았어서 나도 내 발표가 누군가에게 좋은 영향을 줬으면 하는 생각으로 진행하고 준비했다.\n\n기술적인 발표는 듣는 분들의 관심도와 집중도, 그리고 개인 역량에 따라 반응이 갈리는데 최대한 어려운 내용을 쉽게 풀어 말할려고 노력 했다. 그래서 총 50장의 슬라이드의 대부분을 예시를 들며 설명하고 코드는 적게 풀어냈다.\n\n지방대에서 학술 동아리 활동을 하며 기술적으로 많은 성장을 이뤄내고 싶고 우물 안 개구리를 벗어나고 싶어서 2학년때 부터 여러 활동을 했었는데 메가콘이라는 교내 기술 컨퍼런스을 통해서 후배 학생 개발자분들이 더욱 더 참가하고 관심을 가졌으면 좋겠다고 생각이 든다.\n\n## 우물 안 개구리\n\n예전엔 우물 안 개구리 처럼 나 정도면은 4학년 때 당연히 취직하겠지? 라는 안일한 생각을 했었다. 개발자의 취직 시장이 많이 힘들고 얼어있는데 주변에도 취직을 못하고 있는 상황이고 정작 나도 못하는 거를 보면 우울하기도 하고 기분도 안좋고 하는데 내 현재 위치를 파악하고 당장 해야할 것을 정리하며 꾸준하게 공부를 할려고 한다. 언젠간 취직 하겠지 라는 생각으로 앞으로는 근거없는 자신감으로 여러 회사에 지원도 하고 개발도 하고 이것 저것 좋은 영향을 받고 주는 그런 개발자가 되고 싶다고 생각이 든다.\n\n이렇게 언젠가 나도 그들 처럼 되고 싶어서 더욱 더 열심히 공부하고 개발해 우물을 떠날려고 한다.\n\n내년에는 어떤 일이 개인적으로 일어날지 기대가 되며 회고를 읽어주시는 분들에게 감사의 말을 전한다.","excerpt":"벌써 12월 상반기 회고를 작성한게 얼마안된거 같은데 이제 하반기 회고를 작성할 시기가 되었다.\n이전 회고와 달리 미루지 않고 글을 올리려고 마음을 먹어서.. 올 한해 내가 무엇을 얻고 깨닫게 되었는지 얘기해볼려고 한다. 본격 취준생 여름방학 8월달…","fields":{"slug":"/23-second-half/"},"frontmatter":{"date":"Dec 06, 2023","title":"23년도 하반기 회고 - 우물 안 개구리","tags":["회고"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n[Artscope](http://artscope.kr) 서비스를 AWS에 배포하기 위해 CI/CD를 구축하였는데 구축 과정과 시행착오를 기록했습니다.\n\n기존에는 개발 환경에서 깃허브로 커밋을 하게 되면 (develop 브랜치) GitAction을 통해서 Build와 Test과정을 진행하게 되는데 \nDocker 이미지를 저장소에 업로드 하게 되고 온프레미스로 운영중인 개발 서버의 ArgoCD가 해당 이미지를 감지하여 Kubernetes 오브젝트로 배포를 (CD) 진행하게 됩니다. 개발 환경까지는 배포가 자동으로 진행되지만 배포 환경 (main 브랜치)에서는 업로드된 도커 이미지를 직접 가져와 AWS EC2로 배포해야하는 번거로움이 있었습니다.\n\n그래서 이번에 AWS CodeDeploy를 이용해 배포 환경까지 자동으로 배포를 진행하고자 합니다.\nCI/CD 과정은 다음과 같습니다.\n1. github 저장소로 commit\n2. git action을 통해 build, test 진행 (CI)\n    1. spring boot 프로젝트를 docker 이미지로 빌드\n    2. 빌드된 이미지를 docker hub에 업로드\n    3. AWS S3에 새로운 이미지 버전에 대한 정보를 저장\n    4. AWS CodeDeploy에 배포 요청\n3. AWS CodeDeploy를 통해 AWS EC2에 배포 (CD)\n\n### 고민한 부분\n#### AWS 인스턴스는 도커 이미지를 Pull하고 Run만 하도록 고안\n위 과정을 구성하며 고민한 부분은 AWS CodeDeploy 이용한 배포 레퍼런스를 찾아보니 S3에 애플리케이션 빌드 파일을 업로드 후 EC2 상에서 Docker 이미지를 빌드하고 실행하거나 곧 바로 Java 애플리케이션을 실행하는데 이런 과정으로 진행하지 않고싶었습니다. 이유는 AWS 인스턴스는 한정된 자원으로 운영중인 서비스가 있어서 S3로 부터 무거운 빌드 파일을 받아오거나 Docker 이미지 빌드 과정으로 운영중인 서비스에 조금이라도 영향이 없도록 하고 싶었습니다. \n\n그래서 고안한 방법으로 GitAction의 Task 중 새롭게 갱신된 도커 이미지명을 파일로 저장해 S3 저장소에 이미지명이 담긴 파일을 업로드하고 CodeDeploy Script상에서 해당 파일 내용을 환경변수로 저장해 컨테이너로 실행하는 방법으로 진행하였습니다.\n\n위 방법을 적용하니 스프링 빌드 파일(jar, 약 75MB)을 S3에 업로드하지 않아도 되고 도커 이미지 빌드를 EC2가 진행하지 않고 GitAction이 담당하게 되니 최종적으로 EC2 인스턴스에서는 해당 이미지를 Pull 하고 Run하는 과정만 진행하면 되어서 효율적인 방법이라고 생각해 적용했습니다.\n\n--- \n## 1. IAM 설정\n### 1.1 Github Action IAM 사용자 생성\nGithub Action에서 사용할 IAM 사용자를 생성합니다. (IAM - 사용자 - 사용자 추가)\n- 사용자 이름 : artscope-deploy\n- 액세스 유형 : 프로그래밍 방식 액세스\n- 권한 정책\n    - 인라인 정책 생성\n        ```json\n        {\n            \"Version\": \"2012-10-17\",\n            \"Statement\": [\n                {\n                    \"Effect\": \"Allow\",\n                    \"Action\": [\n                        \"autoscaling:*\",\n                        \"codedeploy:*\",\n                        \"ec2:*\",\n                        \"lambda:*\",\n                        \"elasticloadbalancing:*\",\n                        \"s3:*\",\n                        \"cloudwatch:*\",\n                        \"logs:*\",\n                        \"sns:*\"\n                    ],\n                    \"Resource\": \"*\"\n                }\n            ]\n        }\n        ```\n- 생성 후 보안 자격 증명 - 액세스 키 발급 (Access Key ID, Secret Access Key)\n\n발급받은 Key를 Github 저장소의 Secrets에 등록합니다.\n\n\n### 1.2 EC2 IAM 역활 생성\nEC2에서 사용할 IAM 역활을 생성합니다. (IAM - 역활 - 역활 생성)\n\n- 역활 이름 : ec2-deploy\n- 역활 유형 : AWS 서비스\n- 권한 정책\n    - AmazonEC2RoleforAWSCodeDeploy\n\nEC2에서 CodeDeploy Agent가 S3에 접근할 수 있도록 권한을 추가합니다.\n\n### 1.3 CodeDeploy IAM 역활 생성\n그리고 CodeDeploy에서 사용할 IAM 역활을 생성합니다.\n\n\n- 역활 이름: artscope-codedeploy\n- 역활 유형: AWS 서비스\n- 권한 정책\n    - AWSCodeDeployRole\n\nCodeDeploy가 EC2에 접근할 수 있도록 권한을 추가합니다.\n\n### 1.4 EC2에 IAM 역활 연결\nEC2에 IAM 역활을 연결합니다.\n저는 사용중인 EC2가 있어서 IAM 역활 수정을 했습니다 (EC2 - 인스턴스 - 인스턴스 선택 - IAM 역활 수정)\n- IAM 역활 : ec2-deploy\n\n만약에 EC2를 새로 생성한다면 인스턴스 생성 시 생성한 IAM 역활을 선택하면 됩니다.\n\n--- \n## 2. EC2 설정\n### 2.1 AWS CLI 설치\n저는 Ubuntu 22.04.2 LTS를 사용하고 있습니다.\n\n```bash \nsudo apt update\nsudo apt-get install awscli\n```\n\n설치 후 `aws configure` 명령어를 통해 AWS 계정 정보를 입력합니다.\n저는 EC2에 IAM 역활을 연결했기 때문에 Access Key ID, Secret Access Key는 입력하지 않습니다.\n\n```bash\n> aws configure\nAWS Access Key ID [None]: \nAWS Secret Access Key [None]: \nDefault region name [None]: ap-northeast-2\nDefault output format [None]:     \n```\n\n그리고 다음 명령어를 통해 iam-role을 확인합니다.\n\n```bash\n> aws configure list\n      Name                    Value             Type    Location\n      ----                    -----             ----    --------\n   profile                <not set>             None    None\naccess_key     ****************24FZ         iam-role    \nsecret_key     ****************xJAl         iam-role    \n    region           ap-northeast-2      config-file    ~/.aws/config\n```\n\n위 처럼 나오면 정상적으로 설정이 된 것입니다.\n만약에 iam-role 관련 access\\_key, secret\\_key 가 안나온다면 `~/.aws` 폴더에 credentials 파일을 확인하거나\nEC2 역활을 다시 확인하면 됩니다.\n\n이렇게 하면 EC2에서 AWS CLI, CodeDeploy Agent에 필요한 설정이 완료됩니다.\n\n### 2.2 CodeDeploy Agent 설치\n\n다음 명령어를 실행해 CodeDeploy Agent를 설치합니다. (Ubuntu 22.04.2 LTS 기준)\n```bash\nsudo apt install ruby-full\ncd ~ && wget https://aws-codedeploy-ap-northeast-2.s3.ap-northeast-2.amazonaws.com/latest/install\nsudo chmod +x ./install\nsudo ./install auto\n```\n\n설치가 완료되면 다음 명령어를 통해 CodeDeploy Agent가 정상적으로 실행되는지 확인합니다.\n```bash\nsudo service codedeploy-agent status\n```\n\nEC2 재시작되면 CodeDeploy Agent가 자동으로 실행되도록 설정합니다.\n```bash\n# 다음 명령어를 실행합니다\nsudo vim /etc/init.d/codedeploy-startup.sh\n\n# 다음 내용으로 작성합니다\n#!/bin/bash \necho 'Starting codedeploy-agent' \nsudo service codedeploy-agent restart\n\n\n# 실행 권한을 추가합니다\nsudo chmod +x /etc/init.d/codedeploy-startup.sh\n```\n\n이제 EC2에 CodeDeploy Agent가 정상적으로 설치되었습니다.\n\n\n--- \n## 3. CodeDeploy 설정\n### 3.1 CodeDeploy 생성\n\nCodeDeploy 애플리케이션을 생성합니다.\n\n- CodeDeploy - 애플리케이션 - 애플리케이션 생성\n    - 애플리케이션 이름 : artscope-codedeploy\n\n그리고 배포 그룹을 생성합니다.\n\n- CodeDeploy - 배포 그룹 - 배포 그룹 생성\n    - 배포 그룹 이름 : artscope-codedeploy-group\n    - 서비스 역활 : artscope-codedeploy (이전에 생성한 IAM 역활입니다.)\n    - 배포 유형 : 현재 위치\n    - 환경 구성 \n        - Amazon EC2 인스턴스\n        - 키 : Name\n        - 값 : artscope\n    - 배포 설정 : CodeDeployDefault.OneAtATime\n    - 로드 밸런싱 : 없음\n\n### 3.2 CodeDeploy AppSpec 생성\nCodeDeploy에서 배포할 때 필요한 설정 파일입니다.\n프로젝트에서 다음 파일을 생성했습니다.\n\n- ./appspec.yml\n\n```yaml\nversion: 0.0\nos: linux\nfiles:\n  - source: /\n    destination: /home/ubuntu/deploy/\n    overwrite: yes\n\npermissions:\n  - object: /home/ubuntu/deploy/\n    pattern: \"**\"\n    owner: root\n    group: root\n    mode: 777\n\nhooks:\n  ApplicationStop:\n    - location: scripts/stop.sh\n      timeout: 60\n      runas: root\n\n  ApplicationStart:\n    - location: scripts/start.sh\n      timeout: 60\n      runas: root\n```\nCodeDeploy에는 다음과 같은 단계가 있습니다.\n\n- ApplicationStop\n- DownloadBundle\n- BeforeInstall\n- Install\n- AfterInstall\n- ApplicationStart\n- ValidateService\n\n저는 ApplicationStop, ApplicationStart 단계에서 스크립트를 실행하도록 했습니다.\n\n\n### 3.3 CodeDeploy 배포 스크립트 생성\nCodeDeploy에서 배포할 때 필요한 스크립트 파일입니다.\n프로젝트에서 다음 파일을 생성했습니다.\n\n- ./scripts/stop.sh\n\n```bash\nCONTAINER_NAME=art-backend\n\n# 도커 컨테이너가 있는지 확인 (-a 옵션으로 정지된 컨테이너도 확인)\nRUNNING_CONTAINER_ID=$(docker ps -aq --filter \"name=$CONTAINER_NAME\")\necho \"실행중인 컨테이너 ID: $RUNNING_CONTAINER_ID\"\n\n# 이전 도커 컨테이너 종료\nif [ -n \"$RUNNING_CONTAINER_ID\" ]; then\n  echo \"이전 도커 컨테이너 종료 및 삭제합니다\"\n  docker stop $CONTAINER_NAME && docker rm $CONTAINER_NAME\nfi\n\n```\n\n위 스크립트는 실행 중인 컨테이너가 있다면 종료하고 삭제합니다.\n\n\n- ./scripts/start.sh\n\n```bash\nIMAGE_FILE_PATH=\"/home/ubuntu/deploy/image.txt\"\nIMAGE_NAME=$(cat \"$IMAGE_FILE_PATH\")\nCONTAINER_ENV_PATH=\"/home/ubuntu/env/.env\"\nSERVICE_NAME=art-be\n\n# Docker Compose YAML을 새로운 도커 버전으로 작성해서 저장\necho \"version: '3.8'\n\nservices:\n  art-be:\n    container_name: art-backend\n    image: ${IMAGE_NAME}\n    ports:\n      - 8080:8080\n    env_file:\n      - ${CONTAINER_ENV_PATH}\n    volumes:\n      - logs_data:/logs\n      - /home/ubuntu/art-be/pinpoint/profiles:/pinpoint-agent/profiles:rw\n      - pinpoint-volumes:/pinpoint-agent\n    depends_on:\n      - redis\n      - pinpoint-agent\n      - filebeat\n\n  pinpoint-agent:\n    container_name: art-pinpoint-agent\n    image: pinpointdocker/pinpoint-agent:2.5.2\n    volumes:\n      - pinpoint-volumes:/pinpoint-agent\n\n  redis:\n    image: redis:7.0-alpine\n    command: redis-server --port 6379\n    container_name: art-redis\n    labels:\n      - \"name=redis\"\n      - \"mode=standalone\"\n    ports:\n      - 6379:6379\n\n  filebeat:\n    image: filebeat-custom:0.18\n    container_name: art-filebeat\n    volumes:\n      - logs_data:/logs\n    ports:\n      - 5044:5044\n\nvolumes:\n  logs_data:\n  pinpoint-volumes:\n\nnetworks:\n  default:\n    name: art\n    external: true\" > docker-compose.yaml\n\n# 새로운 도커 컨테이너 실행\necho \"IMAGE_NAME: $IMAGE_NAME 도커 실행\"\ndocker-compose up -d $SERVICE_NAME\n```\n\n새로운 도커 이미지 버전을 알기위해 `/home/ubuntu/deploy/` 경로에 저장된 `image.txt` 파일을 읽어 `IMAGE_NAME` 환경변수에 저장합니다.\n그리고 저는 스프링 애플리케이션 뿐만 아니라 pinpoint, redis, filebeat도 함께 실행하기 때문에 docker-compose를 이용해 실행하고 싶어서 갱신된 스프링 서버의 이미지 버전 (`$IMAGE\\_NAME`)을 이용하는 docker-compose.yaml을 생성합니다. 그리고 `docker-compose up -d {서비스_이름}` 명령어로 컨테이너를 실행합니다.\n\n`image.txt` 파일은 Github Action에서 생성하고 S3에 업로드합니다. 그리고 CodeDeploy 배포 요청이 시작되면 Agent가 EC2 인스턴스에서 S3에서 `image.txt` 파일이 담긴 zip을 다운로드 받아 사용합니다.\n\n---\n## 4. GitHub Action 설정\n### 4.1 Github Action Tasks 작성\n\n프로젝트에서 다음 파일을 생성했습니다.\n\n- .github/workflows/prod-ci.yml\n\n```yaml\nname: Docker Prod CI\n\non:\n  push:\n    branches: [ \"main\" ]\n  pull_request:\n    branches: [ \"main\" ]\n\nenv:\n  REGISTRY: docker.io\n  IMAGE_NAME: repository/image-name\n  DOCKER_REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n  DOCKER_REGISTRY_PASSWORD: ${{ secrets.DOCKERHUB_PASSWORD }}\n  JASYPT_ENCRYPTOR_PASSWORD: ${{ secrets.JASYPT_ENCRYPTOR_PASSWORD }}\n  AWS_S3_BUCKET_NAME: ${{ secrets.AWS_S3_BUCKET_NAME }} # S3 버킷 이름\n  AWS_CODE_DEPLOY_NAME: artscope-codedeploy # CodeDeploy 애플리케이션 이름\n  AWS_CODE_DEPLOY_GROUP: artscope-codedeploy-group # CodeDeploy 배포 그룹 이름\n\njobs:\n    \n  build-dockerized-production:\n    name: Build and push Docker image\n    runs-on: ubuntu-latest\n\n    ...\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up JDK 11\n        uses: actions/setup-java@v3\n        with:\n          java-version: '11'\n          distribution: 'temurin'\n\n      - name: Cache Gradle packages\n        uses: actions/cache@v2\n        with:\n          path: |\n            ~/.gradle/caches\n            ~/.gradle/wrapper\n          key: ${{ runner.os }}-gradle-${{ hashFiles('**/*.gradle*', '**/gradle-wrapper.properties') }}\n          restore-keys: |\n            ${{ runner.os }}-gradle-    \n\n      - name: Grant execute permission for gradlew\n        run: chmod +x ./gradlew\n\n      - name: Build with Gradle\n        uses: gradle/gradle-build-action@v2.4.2\n        with:\n          arguments: |\n            build\n\n      - name: Setup Docker buildx\n        uses: docker/setup-buildx-action@79abd3f86f79a9d68a23c75a09a9a85889262adf\n\n      - name: Build the Docker image\n        run: docker build --tag ${{ env.IMAGE_NAME }}:${{ secrets.MAJOR }}.${{ secrets.MINOR }} -f Dockerfile.prod .\n\n      - name: Login to registry ${{ env.REGISTRY }}\n        run: echo \"$DOCKER_REGISTRY_PASSWORD\" | docker login \"$REGISTRY\" -u \"$DOCKER_REGISTRY_USERNAME\" --password-stdin\n\n      - name: Push to ${{ env.REGISTRY }}\n        run: docker push ${{ env.IMAGE_NAME }}:${{ secrets.MAJOR }}.${{ secrets.MINOR }}\n\n      # Docker 이미지 이름을 image.txt 파일에 쓰기\n      - name: Write Docker image name to file\n        run: echo \"${{ env.IMAGE_NAME }}:${{ secrets.MAJOR }}.${{ secrets.MINOR }}\" > image.txt\n\n      # CodeDeploy 배포를 위한 관련 파일 압축\n      - name: Create zip file for AWS CodeDeploy\n        run: mkdir ${{ env.AWS_CODE_DEPLOY_NAME }} && cp -r appspec.yml image.txt scripts ${{ env.AWS_CODE_DEPLOY_NAME }}\n\n      # AWS 설정\n      - name: AWS Configure\n        uses: aws-actions/configure-aws-credentials@v1\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}\n          aws-region: ap-northeast-2\n\n      # AWS S3로 배포 파일 업로드\n      - name: Upload to AWS S3\n        run: |\n          aws deploy push \\\n            --application-name ${{ env.AWS_CODE_DEPLOY_NAME }} \\\n            --s3-location s3://${{ env.AWS_S3_BUCKET_NAME }}/codedeploy/$GITHUB_SHA.zip \\\n            --ignore-hidden-files \\\n            --source ${{ env.AWS_CODE_DEPLOY_NAME }}\n\n      # AWS EC2 CodeDeploy 배포 요청\n      - name: Delpoy to AWS EC2\n        run: |\n          aws deploy create-deployment \\\n            --application-name ${{ env.AWS_CODE_DEPLOY_NAME }} \\\n            --deployment-config-name CodeDeployDefault.OneAtATime \\\n            --deployment-group-name ${{ env.AWS_CODE_DEPLOY_GROUP }} \\\n            --description \"Deploy artscope\" \\\n            --s3-location bucket=$AWS_S3_BUCKET_NAME,key=codedeploy/$GITHUB_SHA.zip,bundleType=zip\n          \n\n      - name: Autoincrement a new minor version\n        run: |\n          echo \"NEW_MINOR_VERSION=$((${{ secrets.MINOR }}+1))\" >> $GITHUB_ENV\n\n      - name: Update Minor version\n        uses: hmanzur/actions-set-secret@v2.0.0\n        with:\n          name: 'MINOR'\n          value: ${{ env.NEW_MINOR_VERSION }}\n          repository: ${{ secrets.REPO }}\n          token: ${{ secrets.REPO_ACCESS_TOKEN }}\n```\n\n중요한 부분이라면 다음과 같습니다.\n- 빌드된 Docker 이미지 이름을 `image.txt` 파일에 쓰기\n- AWS S3로 배포 파일 업로드\n- AWS EC2 CodeDeploy 배포 요청\n\n업데이트된 이미지명을 기록하고 CodeDeploy의 Script에서 사용하기 위해 `image.txt` 파일을 생성하였고 해당 파일에는 다음 내용으로 쓰여집니다.\n\n```\nrepository/image-name:1.0\n```\n\nCodeDeploy Agent에서 배포 작업들을 실행 하기 위해 `appspec.yml`과 `scripts\\`, `image.txt` 를 함께 압축하여 AWS S3에 업로드합니다 그리고 해당 s3 파일의 경로를 알려주면 CodeDeploy Agent가 압축을 풀고 appspec에 명시된 내용을 토대로 배포를 진행합니다.\n\n---\n## 5. CodeDeploy 실행\n이제 CodeDeploy를 실행해보겠습니다. `main` 브랜치에 푸시를 하면 다음과 같이 Github Actions가 실행됩니다.\n\n![Alt text](image.png)\n\nCodeDeploy 배포 요청이 성공적으로 이뤄지면 다음과 같이 배포 내역을 확인할 수 있습니다.\n![Alt text](image-1.png)\n\n배포가 성공적으로 이뤄지면 EC2에 접속하면 실행된 컨테이너와 배포 파일을 확인할 수 있습니다.\n\n- 배포된 컨테이너\n![Alt text](image-2.png)\n\n- 배포 파일\n![Alt text](image-3.png)\n\n이렇게 AWS CodeDeploy와 Github Action, Docker를 이용해 CI/CD를 구축하였습니다.\n\n---\n# 시행착오\n구축 과정을 진행하며 저는 여러 오류를 겪었습니다. 그 중 몇 가지를 정리해보겠습니다.\n\n## 1. Aws::CodeDeployCommand::Errors::AccessDeniedException\n\n### 문제점\nCodeDeploy로 배포 요청을 보냈지만 다음과 같은 오류가 발생했습니다.\n\n- aws codedeploy agent log\n```bash\n2023-07-22T10:56:39 ERROR [codedeploy-agent(3744996)]: InstanceAgent::Plugins::CodeDeployPlugin::CommandPoller: Error polling for host commands: Aws::CodeDeployCommand::Errors::AccessDeniedException - Aws::CodeDeployCommand::Errors::AccessDeniedException - /opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/seahorse/client/plugins/raise_response_errors.rb:17:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/aws-sdk-core/plugins/jsonvalue_converter.rb:22:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/aws-sdk-core/plugins/idempotency_token.rb:19:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/aws-sdk-core/plugins/param_converter.rb:26:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/seahorse/client/plugins/request_callback.rb:71:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/aws-sdk-core/plugins/response_paging.rb:12:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/seahorse/client/plugins/response_target.rb:24:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/seahorse/client/request.rb:72:in `send_request'\n/opt/codedeploy-agent/vendor/gems/codedeploy-commands-1.0.0/sdks/codedeploy_commands_sdk.rb:856:in `poll_host_command'\n/opt/codedeploy-agent/lib/instance_agent/plugins/codedeploy/command_poller.rb:170:in `next_command'\n/opt/codedeploy-agent/lib/instance_agent/plugins/codedeploy/command_poller.rb:94:in `perform'\n/opt/codedeploy-agent/lib/instance_agent/agent/base.rb:28:in `run'\n/opt/codedeploy-agent/lib/instance_agent/runner/child.rb:44:in `block in run'\n/opt/codedeploy-agent/lib/instance_agent/runner/child.rb:86:in `with_error_handling'\n/opt/codedeploy-agent/lib/instance_agent/runner/child.rb:43:in `run'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/child.rb:70:in `block in run_with_error_handling'\n/opt/codedeploy-agent/lib/instance_agent/runner/child.rb:86:in `with_error_handling'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/child.rb:69:in `run_with_error_handling'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/child.rb:33:in `block in start'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/child.rb:22:in `loop'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/child.rb:22:in `start'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:206:in `block in spawn_child'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:204:in `fork'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:204:in `spawn_child'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:196:in `block in spawn_children'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:195:in `times'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:195:in `spawn_children'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:134:in `start'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:37:in `block in start'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:36:in `fork'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:36:in `start'\n/opt/codedeploy-agent/bin/../lib/codedeploy-agent.rb:43:in `block (2 levels) in <main>'\n/opt/codedeploy-agent/vendor/gems/gli-2.11.0/lib/gli/command_support.rb:126:in `execute'\n/opt/codedeploy-agent/vendor/gems/gli-2.11.0/lib/gli/app_support.rb:284:in `block in call_command'\n/opt/codedeploy-agent/vendor/gems/gli-2.11.0/lib/gli/app_support.rb:297:in `call_command'\n/opt/codedeploy-agent/vendor/gems/gli-2.11.0/lib/gli/app_support.rb:79:in `run'\n/opt/codedeploy-agent/bin/../lib/codedeploy-agent.rb:90:in `<main>'\n2023-07-22T10:56:39 ERROR [codedeploy-agent(3744996)]: InstanceAgent::Plugins::CodeDeployPlugin::CommandPoller: Cannot reach InstanceService: Aws::CodeDeployCommand::Errors::AccessDeniedException - Aws::CodeDeployCommand::Errors::AccessDeniedException\n```\n\n### 해결방안\nAcessDeniedException 에러가 발생했는데 이는 IAM Role에 CodeDeploy에 대한 권한이 없어서 발생한 문제였습니다. 그래서 IAM Role에 CodeDeploy에 대한 권한을 추가해주었습니다.\n\n## 2. Aws::CodeDeployCommand::Errors::UnrecognizedClientException - The security token included in the request is invalid.\n\n### 문제점\n- aws codedeploy agent log\n```bash\n2023-07-25T00:00:00 ERROR [codedeploy-agent(8749)]: InstanceAgent::Plugins::CodeDeployPlugin::CommandPoller: Error polling for host commands: Aws::CodeDeployCommand::Errors::UnrecognizedClientException - The security token included in the request is invalid. - /opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/seahorse/client/plugins/raise_response_errors.rb:17:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/aws-sdk-core/plugins/jsonvalue_converter.rb:22:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/aws-sdk-core/plugins/idempotency_token.rb:19:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/aws-sdk-core/plugins/param_converter.rb:26:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/seahorse/client/plugins/request_callback.rb:71:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/aws-sdk-core/plugins/response_paging.rb:12:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/seahorse/client/plugins/response_target.rb:24:in `call'\n/opt/codedeploy-agent/vendor/gems/aws-sdk-core-3.121.1/lib/seahorse/client/request.rb:72:in `send_request'\n/opt/codedeploy-agent/vendor/gems/codedeploy-commands-1.0.0/sdks/codedeploy_commands_sdk.rb:856:in `poll_host_command'\n/opt/codedeploy-agent/lib/instance_agent/plugins/codedeploy/command_poller.rb:170:in `next_command'\n/opt/codedeploy-agent/lib/instance_agent/plugins/codedeploy/command_poller.rb:94:in `perform'\n/opt/codedeploy-agent/lib/instance_agent/agent/base.rb:28:in `run'\n/opt/codedeploy-agent/lib/instance_agent/runner/child.rb:44:in `block in run'\n/opt/codedeploy-agent/lib/instance_agent/runner/child.rb:86:in `with_error_handling'\n/opt/codedeploy-agent/lib/instance_agent/runner/child.rb:43:in `run'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/child.rb:70:in `block in run_with_error_handling'\n/opt/codedeploy-agent/lib/instance_agent/runner/child.rb:86:in `with_error_handling'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/child.rb:69:in `run_with_error_handling'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/child.rb:33:in `block in start'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/child.rb:22:in `loop'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/child.rb:22:in `start'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:206:in `block in spawn_child'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:204:in `fork'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:204:in `spawn_child'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:196:in `block in spawn_children'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:195:in `times'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:195:in `spawn_children'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:134:in `start'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:37:in `block in start'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:36:in `fork'\n/opt/codedeploy-agent/vendor/gems/process_manager-0.0.13/lib/process_manager/master.rb:36:in `start'\n/opt/codedeploy-agent/bin/../lib/codedeploy-agent.rb:43:in `block (2 levels) in <main>'\n/opt/codedeploy-agent/vendor/gems/gli-2.11.0/lib/gli/command_support.rb:126:in `execute'\n/opt/codedeploy-agent/vendor/gems/gli-2.11.0/lib/gli/app_support.rb:284:in `block in call_command'\n/opt/codedeploy-agent/vendor/gems/gli-2.11.0/lib/gli/app_support.rb:297:in `call_command'\n/opt/codedeploy-agent/vendor/gems/gli-2.11.0/lib/gli/app_support.rb:79:in `run'\n/opt/codedeploy-agent/bin/../lib/codedeploy-agent.rb:90:in `<main>'\n2023-07-25T00:00:00 ERROR [codedeploy-agent(8749)]: InstanceAgent::Plugins::CodeDeployPlugin::CommandPoller: Cannot reach InstanceService: Aws::CodeDeployCommand::Errors::UnrecognizedClientException - The security token included in the request is invalid.\n```\n\n- aws codedeploy agent aws_wire log\n```bash\nopening connection to codedeploy-commands.ap-northeast-2.amazonaws.com:443...\nopened\nstarting SSL for codedeploy-commands.ap-northeast-2.amazonaws.com:443...\nSSL established, protocol: TLSv1.2, cipher: ECDHE-RSA-AES128-GCM-SHA256\n<- \"POST / HTTP/1.1\\r\\nContent-Type: application/x-amz-json-1.1\\r\\nAccept-Encoding: \\r\\nUser-Agent: aws-sdk-ruby3/3.121.1 ruby/3.0.2 x86_64-linux-gnu aws-sdk-codedeploycommand/1.0.0\\r\\nX-Amz-Target: CodeDeployCommandService_v20141006.PollHostCommand\\r\\nX-Amz-Codedeploy-Agent-Version: OFFICIAL_1.6.0-49_deb\\r\\nHost: codedeploy-commands.ap-northeast-2.amazonaws.com\\r\\nX-Amz-Date: 20230726T071557Z\\r\\nX-Amz-Content-Sha256: 43bee01b74391facd1d25...75a441ac49517bfc71ccf565\\r\\nAuthorization: AWS4-HMAC-SHA256 Credential=AKIAX...C26VMCRNUX/20230726/ap-northeast-2/codedeploy-commands/aws4_request, SignedHeaders=content-type;host;x-amz-codedeploy-agent-version;x-amz-content-sha256;x-amz-date;x-amz-target, Signature=2271f959ef...7a6e66b278\\r\\nContent-Length: 89\\r\\nAccept: */*\\r\\n\\r\\n\"\n-> \"HTTP/1.1 400 Bad Request\\r\\n\"\n-> \"x-amzn-RequestId: 897d8a0f-869a-47ef-80d9-c13d0ec189b7\\r\\n\"\n-> \"Date: Wed, 26 Jul 2023 07:15:57 GMT\\r\\n\"\n-> \"Content-Type: application/x-amz-json-1.1\\r\\n\"\n-> \"Content-Length: 107\\r\\n\"\n-> \"connection: keep-alive\\r\\n\"\n-> \"\\r\\n\"\nreading 107 bytes...\n-> \"\"\n-> \"{\\\"__type\\\":\\\"UnrecognizedClientException\\\",\\\"message\\\":\\\"The security token included in the request is invalid.\\\"}\"\nread 107 bytes\nConn keep-alive\nI, [2023-07-26T07:15:57.958765 #25534]  INFO -- : [Aws::CodeDeployCommand::Client 400 0.017194 0 retries] poll_host_command(host_identifier:\"arn:aws:ec2:ap-northeast-2:539239817397:instance/i-0e9fe7b11be081a65\") Aws::CodeDeployCommand::Errors::UnrecognizedClientException The security token included in the request is invalid.\n```\n\n```Aws::CodeDeployCommand::Errors::UnrecognizedClientException - The security token included in the request is invalid.```\nAgent 로그(agent.log, agent_aws_wire.log)에서도 해당 메시지가 보였습니다. \n\nAWS CodeDeploy Server로 Agent가 주기적으로 요청을 보내는데 이때, 요청에 대한 응답이 400 Bad Request로 오고 `The security token included in the request is invalid` 라는 메시지가 포함되어 있었습니다.\n\n이를 통해 Agent가 AWS CodeDeploy Server로 요청을 보낼 때, 요청에 대한 인증이 실패하고 있음을 알 수 있었습니다.\n\n저는 처음에 IAM 사용자나 EC2 역활이 제대로 aws configure에 등록되지 않았나 싶어서 액세스 키를 새롭게 발급해서 등록하거나, EC2 역활을 새롭게 생성해서 다시 등록해봐도 해결이 되지 않았습니다 그리고 Agent도 여러번 삭제했지만 해결이 되지 않았습니다.\n\n로그를 다시 확인하니 `Authorization` 요청 헤더에 포함된 `Credentials`를 확인해보니 제가 발급한 액세스키와 비밀키도 아니였고 EC2 역활의 액세스 키와 비밀키도 아니였습니다. 그래서 `.aws` 경로를 확인해봐도 로그에 나타나는 Credentials와 일치하는 액세스 키와 비밀키가 없었습니다.\n\n### 해결방안\n`.aws` 관련해서 이상한 액세스 키를 이용해 요청하니 해당 경로가 문제가 있다고 생각했습니다. 그래서 `ubuntu` 계정이 아닌 `root` 계정으로 `/.aws` 경로를 확인하니 `credentials` 파일이 존재했습니다. 해당 파일을 확인하니 요청에 담긴 Credentials의 액세스 키가 있었습니다. 이전에 root 계정으로 aws cli를 실행한 적이 있는데 이로 인해 발생한 문제였습니다. 해당 파일을 삭제하니 정상적으로 Agent가 AWS CodeDeploy Server로 요청을 보내고 응답을 받을 수 있었습니다. \n\n혹시나 저와 같은 증상이 발생한다면 `root` 나 aws cli를 사용했던 계정들의 `.aws` 폴더를 확인하면 될것 같습니다.\n\n## 레퍼런스\n- https://jwkim96.tistory.com/272\n- https://jojoldu.tistory.com/281\n","excerpt":"Artscope 서비스를 AWS에 배포하기 위해 CI/CD를 구축하였는데 구축 과정과 시행착오를 기록했습니다. 기존에는 개발 환경에서 깃허브로 커밋을 하게 되면 (develop 브랜치) GitAction을 통해서 Build와 Test과정을 진행하게 …","fields":{"slug":"/aws-codedeploy/"},"frontmatter":{"date":"Jul 28, 2023","title":"[AWS] CodeDeploy, Github action, docker-compose를 이용한 CI/CD 구축 그리고 시행착오","tags":["AWS","CodeDeploy","GitAction","Docker","docker-compose","CI/CD"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n![Alt text](<Pasted image 20230708180132.png>)\n\n23년도의 반이 흘렀다. 올해부터 4학년이 되었고 정신없이 지낸거 같고 깃허브의 잔디를 보면 많이한거 같지만 내가 생각했을땐 유의미한 뭐가 없었던 것 같기도 하다. 그 동안 해왔던 거를 이력서나 포토폴리오로 작성해보기도 하고 몇번 서류 합격을 받았지만 매번 코테에서 좋은 결과를 받지 못해서 그런가 번아웃이 오고 그래서 그동안의 내가 뭘 했는지 되돌아 볼려고 회고를 작성하면서 지금까지를 정리해보려고 한다. 23년도 상반기 회고 이지만 22년도 12월 부터 시작한다.\n\n## CEDC 2022 한중일 캡스톤 디자인\n23년도 2학기엔 캡스톤 디자인이라는 프로그램을 통해 `클라우드 서버를 이용한 스마트팜 관리 플랫폼`이라는 주제를 통해 팀 프로젝트를 진행했는데 나는 팀장으로 수행했고 백엔드 개발도 했었다. 교내 경진대회에서 좋은 평가를 받아 수상까지 하게 되었고 지도 교수님이 한번 12월에 열리는 한중일 글로벌 캡스톤 디자인 대회에서도 참가해서 발표를 해보라고 하셔서 발표날 까지 많은 준비를 했었다. \n\n22년도 CEDC 대회는 코로나로 인해 비대면 ZOOM으로 대회가 진행이 되었는데 코로나 전에는 대회가 열리는 국가에 직접 가서 발표를 했다고 한다.\n\n![Alt text](<Pasted image 20230718172141.png>)\n\n영어로 발표를 해야하기 때문에 참가 문서, 소개 문서, 발표 PPT 등 전부를 한글로 초안을 작성하고 번역을 하는 식으로 해서 필요한 문서를 작성했다. 논문과 같은 학술 문서를 작성해본적이 없어서 팀원들의 도움과 지도교수님의 첨삭을 통해서 문서를 계속 초안에서 최종까지 날밤세면서 작성을 했다.\n\n![Alt text](998AB42A-941D-4225-BC78-972AE1942C64_1_102_o.jpeg)\n\n그렇게 해서 문서를 계속계속 수정하다 보니 발표 당일이 되었고 내 차례가 오기까지 다른 참가 조의 발표를 같이 있던 팀원 들과 모니터링 하면서 기다리고 있었다 영어로 발표를 해야하기 때문에 개인적인 시간에 영어 발음과 작성한 발표 대본을 계속 읽고 다른 사람들한테 들려주면서 연습을 했었고 전날 밤에는 꿈에서 영어로 말하는 지경까지 왔었다 (한동안 영어로 생각까지 했다..)\n\n![Alt text](<Pasted image 20230718172936.png>)\n\n드디어 발표 차례가 왔고 ZOOM의 화면 공유를 누르면서 발표를 시작했다. 발표를 끝나고 다른 나라의 참가하시는 분들의 질문까지 잘 답변해서 성공적으로 마무리를 했다. 발표가 끝나고 손이 벌벌떨렸는데.. 아직까지 생각하면 어떻게 했는지 의문이다. \n\n![Alt text](<Pasted image 20230718173439.png>)\n\n결과는 대상을 수상 했고. 결과를 보자마자 지도해주신 교수님과 팀원 들에게 전화로 감사한 말을 전했다. 프로젝트를 여기까지 준비한 과정이 짧지 않고 2학기 동안 진행 했었고 이 과정 속에는 팀장으로 미흡한 부분도 있었고 발표를 위해 프로젝트를 밤세 준비하며 많은 신경을 쓰다보니 스트레스도 많이 받았었다 하지만 좋은 결과로 보답을 받아 좋았다.\n\n## 한국전자통신연구원 인턴 수행\n![Alt text](IMG_1061.jpeg)\n\n12월달에 한국전자통신연구원 (ETRI)의 동계 연구연수생 지원했었다. 한국전자통신연구원에 지원하게 된 계기는 같은 학부 연구실의 졸업하신 선배가 연구실에 계셨고 이전에 많은 조언과 관심을 주셨는데 백엔드 개발을 처음 시작 했을 때 많은 도움을 받았었다 그래서 선배가 계신 연구실에 인턴으로 같이 근무를 해보고 싶었고 매우 운이 좋게 합격하게 되어 근무하게 되었다.\n\n김해가 아닌 대전에서 2달 자취를 하면서 첫 회사 생활을 하게 되었다. 같은 대학교 형 두분과도 같이 합격하게 되어서 혼자가 아닌 셋이서 함께 출근과 퇴근 그리고 헬스... 하게 되어서 하루하루가 매우 알차고 바쁘게 지냈다.\n\n업무는 첫주 때 부터 연구실에서 적용하던 인증 서비스가 구 버전이라 최신 버전을 조사해서 한번 어떤지 써보고 발표를 해달라고 하셔서 첫날에 맥을 세팅하고 바로 업무를 시작했다.. 그렇게 하루에 업무 시간내내 코딩과 자료 조사를 하게 되었는데 업무의 강도는 연구실과 부서마다 다르겠지만 나에겐 괜찮았다. ETRI 인턴을 하기 전에 관련 분야에 대해 이미 공부를 했었기 때문에 괜찮았다 그래서 하루하루 코딩의 재미를 느끼고 평소에는 공식 문서도 깊게 안읽었지만 진짜 공식문서를 꿈에서 까지 상상할 정도로 읽었다.\n\n같이온 형들은 자기 관련 관심 전공과 다른 업무를 하고 있거나 하루종일 논문을 읽고 분석하고 계셨는데 만약 ETRI 인턴에 대해 관심이 있는 분이라면 논문에 대해서 평소 관심있거나 자주 읽는다면 지원하는 연구실의 진행하는 연구 과제를 잘 보고 지원하기를 바란다 의미있는 2달을 보내고싶다면.\n\n결론은 ETRI 인턴 한번즘은 해보는 것을 추천한다. 나는 좋은 경험과 많은 성장을 했고 대학교에서 쉽게 못 느끼는 박사님들의 지식에 감탄하며 나도 저렇게 지식이 깊었으면 하며 의의를 두었다.\n\n## Artscope 플랫폼 사이트 개발\n\n![Alt text](<1.gif>)\n\n22년도 여름방학때 부산 금정구 금샘미술관에 좋은 기회로 전시에 참가했다. 개발자가 미술관에 전시라니? 나의 작품은 아니고 부산시에서 활동하시는 작가님의 전시 작품을 위해 개발자로 참가했다. 관람하는 관객들의 모습을 카메라로 촬영해 다른 화면에 그 모습은 영상 이펙트를 씌워 실시간으로 화면에 보여주는 것인데. 작품과 관객이 상호작용하는 그런 것을 하자고 전시 전에 얘기를 나눴고 같이 개발자로 참가한 친구와 함께 얼굴 인식 프로그램과 인식한 사진을 서버로 전송해서 파일로 저장하는 프로그램을 개발했다. 위 움짤한 그때 전시한 작품의 모습이다. (오른쪽에는 관람객의 모습이 보이고 왼쪽엔 일정 시간 이후에 인식한 모습을 이펙트를 씌워 보여준다.)\n\n![Alt text](<Pasted image 20230718175726.png>)\n\n올해는 작품 전시에 직접적으로 참가는 안하고 부산시 작가분들이나 예술을 좋아하는 일반인들이 작품을 전시하거나 공모를 할 수 있는 것을 한번 만들어 보자고 얘기를 나눴고 그 결과 Artscope라는 사이트를 만들었고 나는 백엔드 개발을 수행했다. \n\nArtscope의 백엔드 개발자로 개발하면서 사이트 특성상 작가분들의 영상 파일이나 이미지 파일이 대부분 해상도가 높고 용량이 크다는 요구사항이 있어서 AWS의 S3로 정적 파일 저장소를 구성하고 이미지나 영상 파일들을 빠르게 사이트에 뿌릴 수 있도록 AWS Cloudfront과 AWS Lambda를 통해서 이미지를 최적화 처리를 하는 시스템을 적용했다 그 결과 해상도가 높은 2K 이상의 이미지를 기존에 5초 이상 받아온 것을 0.5초 이하로 밀리세컨드 단위로 받아올 수 있도록 성능을 개선했다.\n또한 모니터링과 로그에 대해서도 신경쓰게 되었는데. 로그를 한곳에 모아서 모니터링을 할 수 있도록 ELK 스택을 도입하게 되었고 운영중인 스프링 어플리케이션의 다양한 메트릭 수집과 추적을 위한 Naver의 Pinpoint도 도입해서 운용하고 있다. \n\n처음 사이트를 배포하게 되니 많은 사용자들이 찾아와 주셨는데. Artscope는 실제 미술이나 예술계에 활동하시는 작가분들이 자신의 전시 이력이나 관련 정보를 작성할 수 있는데. 사이트에서 하나하나 작품을 감상하다가 하단에 위치한 작가 프로필을 보다보면 부산시에 있는 작가 뿐만 아니라 해외에 전시를 하신 분들까지 사이트에 찾아 와서 자신의 작품을 올려주시니 감회가 새로웠다. Artscope는 평균적으로 WAU는 250명 정도였고 사이트에 평균 머무는 시간이 4분정도로 많은 관심을 가져주셨다. 사이트에 올라온 작품의 수도 약 150개 이상이 업로드 되었고 작가 정보를 입력해주신 분들은 약 40명 정도로 찾아와서 작가 정보를 기입하신 분들에게 대해 매우 감사하다.\n\n![Alt text](<Pasted image 20230718180941.png>)\n이용자들의 피드백을 수용할 수 있도록 설문조사도 만들었고 8명의 소중한 피드백을 주셨고 사이트를 현재까지 개선하고 있다. 사이트를 몇번 배포해 본적은 있지만 이렇게 오래 운영하고 있는건 처음이다. 좋은 기회로 올해도 이런 프로젝트를 진행하게 되어서 몹시 기쁘다. \n\n![Alt text](IMG_5895.jpeg)\nArtscope는 실제 작가분들의 작품을 전시하거나 공모 받고 있고 (사이트에 작품을 업로드하게 되면 금샘미술관에 공모하겠는지 묻고 있다) 그 결과 7월 한달 동안 부산 금정구 금샘미술관에 실제 작품들이 전시하고 있다. 관심이 있는 분이라면 https://artscope.kr 를 찾아와 주시거나 부산에 거주하고 있다면 금샘미술관으로 가보시길!\n\n## 이제는.\n4학년으로 취업 준비를 하고 있다. 저번주에 진행한 2023 토스 SLASH 코딩 테스트를 봐었는데 알고리즘 문제와 서술형 문제에 생각보다 해맸고 좋은 결과를 받지 못했다. 토스라는 앱을 고등학교 처음 토스앱이 출시할 때 부터 사용하고 있고(그때 당시에 등록할 수 있는 은행이 별로 없던걸로 기억) 내 삶에 매우 편리한 부분을 제공해서 이 회사에 많은 관심을 가지고 있고 꼭 백엔드 개발자로 들어가고 싶다는 생각이 예전부터 있었다. 이번 코테를 통해서 아직 내가 많이 부족하다는 것을 느꼈고 와중에 번아웃 + 감기가 오게 되서 그런지 코테 이후론 개발이나 공부를 안하고 집에서 휴식을 취하고 있었다. 이제는 내 현재를 잘 파악하고 정비해서 천천히라도 내가 꿈꾸는 회사에 도전하고 다시 번아웃을 이기고 달려보려고 한다. 글을 잘 못쓰지만 마지막까지 읽어주신 분들에게 감사하며 글을 마친다.","excerpt":"23년도의 반이 흘렀다. 올해부터 4학년이 되었고 정신없이 지낸거 같고 깃허브의 잔디를 보면 많이한거 같지만 내가 생각했을땐 유의미한 뭐가 없었던 것 같기도 하다. 그 동안 해왔던 거를 이력서나 포토폴리오로 작성해보기도 하고 몇번 서류 합격을 받았지…","fields":{"slug":"/23-first-half/"},"frontmatter":{"date":"Jul 18, 2023","title":"23년도 상반기 회고 - 한중일 캡스톤대회, ETRI 인턴 그리고 Artscope","tags":["회고"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"![](2023-05-24-12-30-01.png)\n# 개요\nArgoCD에서는 알림 기능을 제공하는데 해당 기능을 사용하면 ArgoCD에서 사용되는 Application(예: Argo를 통해 배포한 k8s object)을 지속적으로 모니터링하고 상태의 변경 사항을 알릴 수 있다. ArgoCD에서는 Trigger와 Template이라는 매커니즘을 사용해 알림을 보내야하는 시기를 구성할 수 있다. [공식문서](https://argo-cd.readthedocs.io/en/release-2.6/operator-manual/notifications/catalog/)에서 참고하면 이런 Trigger와 Template을 이용한 예제가 있으니 참고하거나 사용자가 직접 알림 매커니즘을 구성해서 사용할 수 있다.\n\n제공하는 여러 서비스들에 알림을 보낼 수 있는데 자주 쓰는거로는 이메일이나, 깃허브, 그라파나, 프로메테우스의 AlertManager, Slack 그리고 Webhook 이 있다.\n이중에서 Webhook을 이용해서 ArgoCD의 배포 상태 변경에 대해 디스코드로 알림을 보내보자!\n\n# Get Started\n이 글에서 운영환경은 다음과 같다.\n- argocd v2.6.5\n- argo-notifications-controller v2.6.5\n\n\n## ArgoCD Notification 설정\n\n우선 ArgoCD Notification Controller에 알려줘야할 쿠버네티스 시크릿을 다음과 같은 내용을 생성해서 적용한다.\n\n### argo-notifications-secret.yaml\n```yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: argocd-notifications-secret\n  namespace: argocd\ntype: Opaque\nstringData:\n  notifiers.yaml: |\n    webhook:\n    - name: discord-webhook\n      url: <여기에 웹훅 URL 입력>\n      headers:\n      - name: Content-Type\n        value: application/json\n```\n\n`argocd-notifications-secret` 이라는 이름의 Secret 파일을 생성해준다\n그 후 `kubectl apply`로 Object를 적용한다\n\n### argocd-notifications-cm.yaml\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-notifications-cm\n  namespace: argocd\ndata:\n  service.webhook.discord-webhook: |\n    url: <여기에 윕훅 URL 입력>\n    headers:\n    - name: Content-Type\n      value: application/json\n```\n\n그리고 configmap을 작성하는데. `service.webhook.<webhook-name>` 형식으 로 아까 작성한 Secret과 동일하게 작성해준다. 이 부분은 ArgoCD에 Webhook을 등록한다.\n\n그 다음 Notification의 Trigger를 설정해준다.\n```yaml\n  trigger.sync-operation-change: |\n    - when: app.status.operationState.phase in ['Running', 'Succeeded', 'Error', 'Failed']\n      send: [ discord-alert ]\n```\n`sync-operation-change` 트리거에서 조건은 \bApplication의 상태가 `Running, Succeded, Error, Failed` 로 설정했고 위와 같은 상태에 도달했을때 discord-alert라는 template을 통해 알림을 전송한다. \n\n```yaml\n  template.discord-alert: |\n    webhook:\n      discord-webhook:\n        method: POST\n        body: |\n          {\n            \"embeds\": [\n              {\n                \"title:\": \"ArgoCD Notification - {{ .app.metadata.name }}\",\n                \"description\": \" **{{ .app.metadata.name }}** 의 상태가 **{{ .app.status.operationState.phase }}** 로 변경되었습니다.\",\n                \"color\": \"{{ if eq .app.status.operationState.phase \"Running\" }} 1127128 {{end}} {{ if eq .app.status.operationState.phase \"Succeeded\" }} 3066993 {{end}} {{ if eq .app.status.operationState.phase \"Error\" }} 15158332 {{end}} {{ if eq .app.status.operationState.phase \"Failed\" }} 15158332 {{end}}\"\n              }\n            ]\n          }\n```\n그리고 template을 정의하는데 template의 이름은 discord-webhook이고 `webhook: <wehbook-name>` 을 통해서 해당 Template의 service를 정의한다. discord에서 webhook 메시지를 작성하는 방법은 [공식문서](https://discord.com/developers/docs/resources/webhook)를 참고하면 된다.\n\n이렇게 해서 `argocd-notifications-cm` 을 작성했다면 적용해주면 된다.\n그 후 ArgoCD의 대시보드에 접속해서 원하는 애플리케이션을 다음과 같이 따라해서 알림을 적용하면 된다.\n![](2.png)\n이미 생성된 애플리케이션이나 새로 생성할 애플리케이션에 Notification Subscriptions을 적용하면 된다. \n\n`notification.argoproj.io/<trigger-name>.<service-name>= \"\"`\n\n이렇게 하여 디스코드로 웹훅 알림을 전송하는 설정은 끝났다 이제 확인을 해보자\n\n## Notification Result\n![](2023-05-24-12-32-44.png)\nArgoCD로 배포된 애플리케이션 상태가 변경되면 알림이 전송되는데 `Sync`  버튼을 눌러 강제로 상태 변경을 일으키면 위와 같이 알림이 전송된다.\n\n간단하게 Discord로 알림을 전송하는 방법을 알아봤고 ArgoCD의 애플리케이션 상태를 자세히 분기해 알림을 적용하고 싶다면 [공식문서](https://argo-cd.readthedocs.io/en/release-2.6/operator-manual/notifications/catalog/)를 참조하면 좋을 것 같다. 그리고 Template을 작성할때 `{{ ... }}` 로 Kubernetes 애플리케이션에 대한 내부 속성들을 가져왔는데 이러한 속성들을 사용하는 방법에 대해서 궁금하면 \b[K8S JSONPATH](https://kubernetes.io/ko/docs/reference/kubectl/jsonpath/) 를 참고하면 된다.!\n# 레퍼런스\nhttps://argo-cd.readthedocs.io/en/release-2.6/operator-manual/notifications/","excerpt":"개요 ArgoCD에서는 알림 기능을 제공하는데 해당 기능을 사용하면 ArgoCD에서 사용되는 Application(예: Argo를 통해 배포한 k8s object)을 지속적으로 모니터링하고 상태의 변경 사항을 알릴 수 있다. ArgoCD에서는 Tri…","fields":{"slug":"/argocd-notification/"},"frontmatter":{"date":"May 24, 2023","title":"[K8S] ArgoCD Notification을 이용해 Discord Webhook으로 알림을 보내보자","tags":["Kubernetes","ArgoCD"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n필자가 진행하는 토이 프로젝트 냥피스에서는 이미지를 업로드 하는 기능과 이미지 조회 기능을 제공한다.\n해당 기능을 구현하기 위해서 도움이 될만한 내용이 있으므로 이 기능을 구현하기 위한 분들은 읽어보면 좋을 것이다.\n# Get Started\n## 1. 이미지 업로드 구현하기\n만약에 글을 생성할때 이미지 파일과 같이 단일 API로 처리할 수 있다. 이러한 요구사항은 \n이미지 업로드 시에 MultiPartFile 뿐만 아니라 DTO도 함께 처리할 수 있도록 코드를 작성하면된다\n다음 내용들은 이러한 요구사항을 토대로 작성했다.\n\n### 1.1 MultiPart Config 설정\n우선 MultiPartFile에 대해 최대 사이즈 설정을 해준다. \n이미지 파일을 업로드하기 때문에 기본값보다 높은 용량으로 제한해준다.\n다음과 같이 설정을 추가한다. ([MultipartProperties](https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/autoconfigure/web/servlet/MultipartProperties.html))\n```yaml\n  spring:\n\t  servlet:\n\t    multipart:\n\t      max-file-size: 10MB\n\t      max-request-size: 10MB\n```\n- max-file-size: 업로드된 파일에 허용되는 최대 크기를 지정. (기본값은 1MB)\n- max-request-size: multipart/form-data 요청에 허용되는 최대 크기를 지정. (기본값은 10MB)\n\n그외 MultiPart 업로드에 대한 설정이 있다. 기본적으로 Multipart 기능이 활성화 (`spring.servlet.multipart.enabled : true`) 되어있다.\n업로드된 파일의 임시 저장 공간을 설정할 수 있는 설정도 있다. (multipart.location) 추가적으로 관리가 필요하면 해당 경로도 지정하면 좋다. 임시적으로 저장되는 경로라 요청이 처리 된 후에는 자동으로 파일이 삭제된다.\n\n### 1.2 Upload Controller\n```java\n    @PostMapping(consumes = { MediaType.MULTIPART_FORM_DATA_VALUE })\n    public ResponseEntity upload(\n            @RequestPart(\"dto\") ... dto,\n            @RequestPart(\"image\") MultipartFile image)  {\n\n        // 확장자 추출\n        String originalFilename = image.getOriginalFilename();\n        int index = originalFilename.lastIndexOf(\".\");\n        String ext = originalFilename.substring(index + 1).toLowerCase();\n\n\n        if (!ext.equals(\"jpg\")) {\n            return new ResponseEntity(\"이미지 파일만 업로드 가능합니다.\", HttpStatus.BAD_REQUEST);\n        }\n\n\n        String savePath = \"./images/\";\n        String storeFileName = UUID.randomUUID() + \".\" + ext;\n        String now = LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"));\n\n        try \n            String key = savePath + now + \"/\" + storeFileName;\n            File temp = new File(savePath + now + \"/\");\n\n            if (!temp.exists()) {\n                temp.mkdirs();\n            }\n\n            FileOutputStream fileOutputStream = new FileOutputStream(key);\n            fileOutputStream.write(image.getBytes());\n            fileOutputStream.close();\n\n            dto.setImageUrl(\"/images/\" + now + \"/\" + storeFileName);\n        } catch (IOException e){\n            return new ResponseEntity(\"이미지 저장에 실패했습니다.\", HttpStatus.INTERNAL_SERVER_ERROR);\n        }\n        \n\t\t...\n    }\n```\nMultipartFile에 대해 확장자 유효성 검증을 처리하고 파일 저장을 하는 로직이 있다. 메서드 파라미터를 보면은 이미지 파일 뿐만 아니라 DTO 객체도 받아오는데. MultiPartFile과 JSON 요청을 같이 처리할려면  `@ReqeustPart` (@RequestBody가 아니다!)로 DTO를 받아야한다. 그렇지 않으면 스프링에서 예외가 발생한다. MultiPartFile로 DTO를 받고 해당 DTO는 요청시에 Content-Type을 application/json으로 지정하면 정상적으로 스프링에서 처리된다. 추가적으로 유효성 검증을 할때 파일의 위변조까지 체크할려면 추가적으로 [Apache Tika 라이브러리](https://tika.apache.org)를 이용하면 된다.\n\n이미지가 저장되는 경로는 프로젝트 경로의 `images/2023-05-01/` 형식의 폴더로 저장되고 저장되는 파일명은 중복성을 고려하여 UUID를 이용해서 저장된다. 따라서 파일이 업로드 되면 다음과 같이 저장되는 모습이다.\n```shell\n./\n├── README.md\n├── build/\n├── gradle/\n├── gradlew\n├── gradlew.bat\n├── images\n│   └── 2023-05-01\n│       ├── 0e04033c-c69b-4840-a17d-8052fb32653e.jpeg\n│       ├── 27fe8ce7-8bca-4642-8f0d-756fb0a4e1a2.jpeg\n│       ├── 34d274ca-6602-4305-979d-f28cdbdf8a91.jpeg\n│       ├── 70558e10-d795-4358-b443-07e6fc469ee2.jpeg\n│       ├── 88c6b931-b000-45c6-a5fb-ace650b54cb7.jpeg\n│       ├── 9452b9c8-3a09-4fb1-9052-231945701526.jpeg\n│       ├── 9572aa83-982c-4a45-8e9d-1164d1b375a0.jpeg\n│       ├── 97c0f0b6-e601-40ae-808f-1f92ec94974b.jpeg\n│       ├── d83dbdc6-ee63-49f4-b8e5-73c8049d069a.jpeg\n│       ├── ec24b9f6-c57e-4935-8e0c-1d27d08daee5.jpeg\n│       ├── fae23d62-57ec-4a93-9a96-cd7068c93dc7.jpeg\n│       └── ffa7a8bf-f984-4c08-9cb1-de66655ae81f.jpeg\n├── settings.gradle\n└── src\n    ├── main\n    │   ├── java\n    │   └── resources\n    └── test\n        └── java\n```\n스프링을 jar 파일로 실행해서 기능을 수행한다면 jar 파일이 위치한 경로에서 저장된다.\n\n### 1.3 이미지 업로드 API\n![](1.png)\n위와 같이 이미지 업로드 API를 호출한 모습이다. 이미지 뿐만아니라 추가적인 JSON 형식의 요청도 처리하는 API 이다.\n이러한 API (Form-data에 json 형식의 dto와 image를 사용하는 것)를 사용하는 Frontend 에서는 다음 코드를 참고하여 사용하면 된다.\n\n```js\n// axios를 이용한 api 호출 코드\nconst axios = require('axios');\nconst FormData = require('form-data');\nconst fs = require('fs');\nlet data = new FormData();\ndata.append('dto', '{\\n  \"description\": \"string\",\\n  \"name\": \"string\",\\n  \"prize\": 1000\\n}', {contentType: 'application/json'});\ndata.append('image', fs.createReadStream('BAE171ED-8C6A-4D86-B855-79E26B3D2FD5.jpeg'));\n\nlet config = {\n  method: 'post',\n  maxBodyLength: Infinity,\n  url: 'http://localhost:8080/api/wanted',\n  headers: { \n    ...data.getHeaders()\n  },\n  data : data\n};\n\naxios.request(config)\n.then((response) => {\n  console.log(JSON.stringify(response.data));\n})\n.catch((error) => {\n  console.log(error);\n});\n```\n\n\n## 2. 이미지 조회 구현하기\n저장된 이미지를 조회하기 위해서 저장된 이미지 파일들을 정적 리소스로 관리하여 불러올 수 있도록 스프링 서버를 설정한다.\n\n위 이미지 업로드를 구현하면 이미지의 저장경로는 `/images/2023-05-02/5a3f680c-6d6a-4de4-a283-6d6f12c221c1.jpeg` 와 같이 구성되는데. 해당 경로 그대로 `localhost:8080/images/2023-05-02/5a3f680c-6d6a-4de4-a283-6d6f12c221c1.jpeg`  와 같이 호출할 수 있도록 기능을 구현하였다.\n즉 스프링 정적 리소스를 조회할때 images/ 경로로 요청이 들어오면은 images/ 폴더 경로에 있는 리소스들을 조회할 수 있도록 설정한다.\n\n### 2.1 UploadPath Config 설정\napplication.yaml에 다음 설정을 추가한다.\n```yaml\nuploadPath: file:./images/ # Linux, Mac 경로\n```\n만약에 윈도우 환경에서 서버를 실행한다면 다음과 같은 경로로 지정해야한다.\n`file:///./images/` 또는 `file:///C:images/` \n\n### 2.2 WebMvcConfiguration\n```java\n@Configuration\npublic class WebMvcConfig implements WebMvcConfigurer {\n\n    @Value(\"${uploadPath}\")\n    private String uploadPath;\n\n    @Override\n    public void addResourceHandlers(ResourceHandlerRegistry registry) {\n        registry\n                .addResourceHandler(\"/images/**\")\n                .addResourceLocations(uploadPath);\n    }\n}\n```\n`WebMvcConfigurer`를 구현한 `@Configuration` 클래스를 작성한다.\n설정한 uploadPath 속성값을 불러오고 `addResourceHandlers` 메소드를 오버라이드하여 `/images/**` 경로의 요청들은 지정한 uploadPath로 리소스 파일을 찾을 수 있도록 코드를 작성했다.\n\n즉 [localhost:8080/images/2023-05-02/5a3f680c-6d6a-4de4-a283-6d6f12c221c1.jpeg]() 링크를 누르면 업로드된 이미지가 조회될 것이다. \n\n만약에 Spring Security를 사용하면 httpSecurity에서 `/images/**` 경로를 permitAll 처리를 해줘야한다.\n\n### 2.3 이미지 조회 결과\n![](0.png)\n\n이미지 업로드와 조회를 간단하게 구현해봤다. 이러한 기능들을 실제 배포를 위해서 구현한다면 이미지의 특성상 요청 크기가 매우 무겁기 때문에 미들웨어로 CDN과 같은 캐싱 서버를 둬서 리소스를 캐싱해서 제공하거나, 이미지의 크기가 요즘은 4K 이상은 넘기는 경우가 있으니 클라이언트에 보낼때 이미지 리사이징 기능을 적용하는 방법들을 고안해야한다....! \n\n# 레퍼런스\nhttps://velog.io/@orol116/Spring-이미지파일-업로드\n\nhttps://gilssang97.tistory.com/43\n\nhttps://creampuffy.tistory.com/119\n\nhttps://velog.io/@nestour95/Spring-boot-정적-리소스를-외부-디렉토리로-부터-불러오기","excerpt":"필자가 진행하는 토이 프로젝트 냥피스에서는 이미지를 업로드 하는 기능과 이미지 조회 기능을 제공한다.\n해당 기능을 구현하기 위해서 도움이 될만한 내용이 있으므로 이 기능을 구현하기 위한 분들은 읽어보면 좋을 것이다. Get Started 1. 이미지…","fields":{"slug":"/image-upload-view/"},"frontmatter":{"date":"May 02, 2023","title":"[Spring] 간단한 이미지 업로드 및 정적 리소스를 통한 이미지 조회를 구현해보자.","tags":["Spring","upload","multipart"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n[AWS - S3 리소스를 CloudFront로 캐싱하자](https://hoon9901.github.io/aws-s3-cloudfront/) 이어서\n\n## S3 이미지 리사이징 동작 순서\n1.  클라이언트에서 **`GET /\bimage-url?w=100&h=100&f=webp&q=80`** 요청을 보냄.\n2.  CDN에서 w, h, f, q 쿼리 파라미터가 붙어있으면 **`Lambda 함수를 트리거`**\n3.  해당 S3 Object(이미지)가 CDN에 캐싱이 되어있으면 해당 이미지를 사용하고, 없다면 S3에서 가져옴.\n4.  **`Sharp`** 모듈을 사용하여 **`w, h, f, q`** 인자를 통해 원하는 사이즈와 포맷, 품질로 이미지 리사이징\n5.  Base64 형식으로 인코딩하여 클라이언트에게 응답을 리턴\n6.  클라이언트는 응답을 읽어 화면에 렌더링.\n\n위와 같은 동작을 통해서 원하는 이미지를 얻을 수 있다.\n다음 목차들을 수행하여 구현하는 과정을 나타낸다.\n\n## AWS Cloud9 환경에서 코드 작성 시\nS3 원본 리소스를 이미지 리사이징할 Sharp 노드 모듈을 사용한 코드를 작성한다. 필자는 Cloud9 이라는 AWS IDE 를 사용함.\n```js\n'use strict';\n\nconst querystring = require('querystring');\nconst AWS = require('aws-sdk'); \nconst Sharp = require('sharp');\n\nconst S3 = new AWS.S3({\n  region: 'ap-northeast-2'\n});\nconst BUCKET = '\b버킷 이름';\n\nexports.handler = async (event, context, callback) => {\n  const { request, response } = event.Records[0].cf;\n  // Parameters are w, h, f, q and indicate width, height, format and quality.\n  const params = querystring.parse(request.querystring);\n\n  // Required width or height value.\n  if (!params.w && !params.h) {\n    return callback(null, response);\n  }\n\n  // Extract name and format.\n  const { uri } = request;\n  const [, imageName, extension] = uri.match(/\\/?(.*)\\.(.*)/);\n\n  // gif 포맷은 원본 반환\n  if (extension === 'gif' && !params.f) {\n    return callback(null, response);\n  }\n\n  // Init variables\n  let width;\n  let height;\n  let format;\n  let quality; // Sharp는 이미지 포맷에 따라서 품질(quality)의 기본값이 다릅니다.\n  let s3Object;\n  let resizedImage;\n\n  // Init sizes.\n  width = parseInt(params.w, 10) ? parseInt(params.w, 10) : null;\n  height = parseInt(params.h, 10) ? parseInt(params.h, 10) : null;\n\n  // Init quality.\n  if (parseInt(params.q, 10)) {\n    quality = parseInt(params.q, 10);\n  }\n\n  // Init format.\n  format = params.f ? params.f : extension;\n  format = format === 'jpg' ? 'jpeg' : format;\n\n  // For AWS CloudWatch.\n  console.log(`parmas: ${JSON.stringify(params)}`); // Cannot convert object to primitive value.\n  console.log(`name: ${imageName}.${extension}`); // Favicon error, if name is `favicon.ico`.\n\n  try {\n    s3Object = await S3.getObject({\n      Bucket: BUCKET,\n      Key: decodeURI(imageName + '.' + extension)\n    }).promise();\n  } catch (error) {\n    console.log('S3.getObject: ', error);\n    return callback(error);\n  }\n\n  try {\n    resizedImage = await Sharp(s3Object.Body)\n      .resize(width, height)\n      .toFormat(format, {\n        quality\n      })\n      .toBuffer();\n  } catch (error) {\n    console.log('Sharp: ', error);\n    return callback(error);\n  }\n\n  const resizedImageByteLength = Buffer.byteLength(resizedImage, 'base64');\n  console.log('byteLength: ', resizedImageByteLength);\n\n  // `response.body`가 변경된 경우 1MB까지만 허용됩니다.\n  if (resizedImageByteLength >= 1 * 1024 * 1024) {\n    return callback(null, response);\n  }\n\n  response.status = 200;\n  response.body = resizedImage.toString('base64');\n  response.bodyEncoding = 'base64';\n  response.headers['content-type'] = [\n    {\n      key: 'Content-Type',\n      value: `image/${format}`\n    }\n  ];\n  return callback(null, response);\n};\n```\n\n코드를 작성 후에 다음 명령어들을 실행한다.\n\n```js\n$ npm init -y\n$ npm install sharf\n```\n\n그러면 다음과 같이 구성된다.\n\n![](1.png)\n\nnode_modules를 위해서 cloud9을 사용했지만 로컬 환경에서 npm 구성 후에 람다로 프로젝트를 올려도될것같다.\n\n이제 동작할 코드 작성은 끝나고 람다를 생성해보자.\n\n## 로컬 환경에서 코드 작성 시\n![](2.png)\ncloud9과 마찬가지로 코드를 작성해서 `npm install sharf` 를 실행하고 zip 으로 파일들을 압축한다.\n\n\n### 빌드 환경이 x86_64 (생성한 람다 아키텍처)이 아닐 경우\n![](3.png)\n\n`npm install` 을 하고 람다에 배포하면 위와 같은 오류가 발생한다.\n\n로컬환경에서는 Linux 환경이 아니거나 또는 Apple ARM 일때 `npm install` 시 다음 명령어를 통해서 설치를 해야한다.\n```\nnpm i --platform=linux --arch=x64 {module}\n```\n\n람다에서 핸들러 경로를 `path/index.handler` 로 지정하면은 해결되긴 한다.\n패키지를 설치하고. 이제 zip 형식으로 압축하여 람다에 업로드하면 되는데. 압축 시 주의사항이 있다.\n\n![](4.png)\n압축을 코드가 위치한 곳에서 상위 디렉터리를 통해서 하면 위와 같은 오류가 발생한다.\n\n폴더로 압축해선 안되고. 압축 해제 시 파일이 바로 나오도록 압축하면 된다. 그렇게 하면 index.handler를 정상적으로 인식해서 람다가 실행한다\n\n## Lambda 생성\n###  코드 업로드\nLambda를 생성하자 버지니아 북부에서 생성해야한다. (서울에서 하면 배포 시  Lambda@Edge가 안뜸)\n필자는 런타임 Node.js 18.x 버전을 선택하였다. \n\n람다를 생성하면 코드 소스를 업로드하면 된다. Cloud9에서 작업했다면 다음과 같은 방법을 따르고 로컬 환경에서 빌드를 했다면 .zip 파일 형식으로 압축하여 업로드한다.\n### Cloud9에서 람다로 업로드 시\n![](5.png)\n좌측에 AWS - US East - Lambda - 생성한 람다 이름 - Upload Lambda 를 선택한다.\n그러고 다음 순서에 따라 선택한다.\n1. Upload Type : Directory\n2. No\n3. index.js 가 위치한 폴더 경로 - Open\n그러면 그 즉시 람다로 코드가 업로딩된다.\n\n### 로컬 환경에서 람다로 업로드 시\n![](6.png)\n- 코드 소스 - 에서 업로드 - .zip 파일\n을 통해서 압축한 코드를 업로드할 수 있다.\n10MB 이상 넘으면 S3 에서 업로드를 권장하지만 업로드하는데 지장이 없다.\n## IAM 설정\n이렇게해서 바로 실행은 할 수 가 없고 람다 IAM 권한 설정을 해야한다\nCloudFront로 요청이 들어올 때 Trigger로 Lambda@Edge가 작동되고. S3 원본에 접근하기 때문에 권한(정책)을 가지고있는 역활을 설정한다.\n\n- Lambda - 구성 - 권한 - 역활 이름 **클릭**\n- 권한 추가 - 정책 생성 - JSON \n```json\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"VisualEditor0\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"iam:CreateServiceLinkedRole\",\n                \"lambda:GetFunction\",\n                \"lambda:EnableReplication\",\n                \"cloudfront:UpdateDistribution\",\n                \"s3:GetObject\",\n                \"logs:CreateLogGroup\",\n                \"logs:CreateLogStream\",\n                \"logs:PutLogEvents\",\n                \"logs:DescribeLogStreams\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n```\n정책 편집을 종료하고, 역활 - 신뢰 관계 - 신뢰 정책 편집을 누른다.\n\n```json\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Service\": [\n                    \"edgelambda.amazonaws.com\",\n                    \"lambda.amazonaws.com\"\n                ]\n            },\n            \"Action\": \"sts:AssumeRole\"\n        }\n    ]\n}\n```\n위 설정을 통해 Lambda 함수가 기존에 가지고 있는 역활에 적절한 권한이 주어졌고 다음과 같이 볼 수 있다.\n\n\n![](7.png)\n\n## Lambda@Edge 배포\n\n![](8.png)\n작업 - 기능 - Lambda@Edge 배포를 클릭한다. (리전 확인 필수)\n\nCDN은 생성한 CloudFront 로 연결하고 캐시 동작을 \\* 로 선택한다.\nCloudFront 이벤트는 오리진 응답으로 선택한다.\n\n그리고 최종적으로 CloudFront에 다음과 같은 `쿼리 문자열` 설정을 해야한다. 해당 설정을 하지 않고 배포한다면 CDN으로 요청 시 쿼리 문자열을 지정해도 람다가 실행되지 않는다.\n\n![](9.png)\n\n이로써 이미지 리사이징 적용이 끝났다. CloudFront에 람다가 배포된 후 CDN URI를 통해서 가져올 이미지의 Key 를 지정한뒤 쿼리 문자열을 지정하여 리사이징을 호출한다.\n\n\n## 웹 성능 개선\n![](10.png)\n\nCDN으로 부터 이미지 리사이징된 리소스들을 받아온 모습이다. 원본 리소스를 조회했을 때 보다 매우 빠르게 작동한다.\n\n### 원본 리소스 크기\n원본 이미지의 사이즈가 1200x750 일때 다음과 같이 받아온다.\n![](11.png)\n\n### 캐싱 리소스 크기 \n이미지 리사이즈를 통해 640x640 이고 퀄리티를 75, 포맷을 webp 로 했을떄 다음과 같다.\n![](12.png)\n기존 리소스 크기가 약 290KB 일때 이미지 리사이즈를 통해서 약 22KB로 약  1/13정도로 크기가 줄어 든 것을 볼 수 있다.\n\n## 결론\n이미지 리사이징을 통해서 원본 이미지를 그대로 받아오는 것 보다 스토리지 비용이 상대적으로 감소하고 또한 네트워크 전송량에 따른 비용도 감소한다. 새로운 해상도나 모바일 환경에 맞춰서 해상도 대응 문제를 해결하기 쉽다. 최종적으로 많은 이미지를 그려도 적은 용량으로 브라우저에서 로딩하기 떄문에 사용자 경험도 매우 좋게 상승한다.\n\n## 레퍼런스\n\nhttps://lemontia.tistory.com/1071\n\nhttps://heropy.blog/2019/07/21/resizing-images-cloudfrount-lambda/\n\nhttps://tech.wired.company/cloudfront와-aws-lambda-edge를-활용한-이미지-최적화-dab488c0ef35\n\nhttps://velog.io/@dankim/Lambdaedge-cloudFront-S3\n\nhttps://velog.io/@su-mmer/CloudFront와-LambdaEdge를-이용한-이미지-리사이징\n\nhttps://medium.com/daangn/lambda-edge로-구현하는-on-the-fly-이미지-리사이징-f4e5052d49f3","excerpt":"AWS - S3 리소스를 CloudFront로 캐싱하자 이어서 S3 이미지 리사이징 동작 순서 클라이언트에서  요청을 보냄. CDN에서 w, h, f, q 쿼리 파라미터가 붙어있으면  해당 S3 Object(이미지)가 CDN에 캐싱이 되어있으면 해당…","fields":{"slug":"/aws-s3-image-resize/"},"frontmatter":{"date":"Apr 12, 2023","title":"[AWS] Lambda@Edge를 통해 이미지 리사이징을 해서 웹 성능 개선을 해보자","tags":["AWS","Cache","S3","CloudFront","Lambda"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n# S3에 CloudFront 적용하기\n\n현재 개발중인 서비스에서 이미지를 불러오는것을 S3에서 직접적으로 가져와 사용하고 있는데\n서비스 특성상 이러한 이미지와 영상과 같은 미디어 파일들을 많이 사용되는 서비스 구조라 \n서비스의 구조가 많이 무거워지고 리소스 사용량이 상당히 늘어날 것 같아 캐싱을 적용하기 위해서 \nAWS에서 제공하는 CDN인 CloudFront를 통해서 적용하는 과정을 알아보자.\n\n## CloudFront 생성\n\n![](1.png)\n\n1. CloudFront > 배포 > 생성으로 이동\n2. 원본 도메인은 사용중인 S3에 대한 도메인으로 선택\n\n![](2.png)\n- S3 버킷 액세스에 대한 설정인데. S3에 대한 모든 접근은 차단하고 CloudFront를 통해서만 접근이 가능하게 할려면 OAI 설정은 체크한다. \n\n그리고 배포를 생성함.\n\n## S3 버킷 권한 편집\nAmzone S3 > 버킷으로 이동해서 버킷 권한을 편집한다.\n\n```json\n{\n    \"Version\": \"2008-10-17\",\n    \"Id\": \"PolicyForCloudFrontPrivateContent\",\n    \"Statement\": [\n        {\n            \"Sid\": \"1\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity OAI-Here\"\n            },\n            \"Action\": \"s3:GetObject\",\n            \"Resource\": \"arn:aws:s3:::your-s3-bucket-here/*\"\n        },\n        {\n            \"Sid\": \"2\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity OAI-Here\"\n            },\n            \"Action\": \"s3:ListBucket\",\n            \"Resource\": \"arn:aws:s3:::your-s3-bucket-here\"\n        }\n    ]\n}\n```\n자신에 맞게 수정하여 권한을 편집한다.\nS3 버킷에 대해 `GetObject` , `ListBucket` 동작에 대한 권한을 부여하여 CloudFront가 S3 이미지를 가져올 수 있도록 한다.\n\n## S3 퍼블릭 액세스 수정\n추가적으로 기존 백엔드 코드(예: 스프링부트)에서 S3 에 대해 이미지 리소스를 업로드하는 코드를 작성해서 S3에 대해 AccessKey와 SecretKey를 통해서 작업했다면 S3 퍼블릭 액세스를 다음과 같이 수정한다.\n\n![](3.png)\n\n다음과 같은 설정하면은 기존 백엔드 코드에 추가적인 설정 없이 이미지를 업로드하면 S3에 올라간다.\n\n이제부턴 기존 S3 리소스 요청을 CloudFront 도메인을 통해서 수행하면된다.\n\n- 기존 URL `https://s3-url/image.jpeg`\n- 적용 후 URL `https://cloudfront-url/image.jpeg`\n\n## Cache 확인\nCDN 도메인으로 변경한 후 기존 S3 리소스를 가져오듯이 요청을 보내면 다음과 같이 응답 헤더를 볼 수 있다.\n\n![](4.png)\n\n`x-cache` 를 보면은 최초 요청은 `Miss from cloudfront` 이고 새로고침을 통해서 다시 요청을 보내면 다음과 같이 바뀐다.\n\n![](5.png)\n\n`Hit from cloudfront` 로 바뀐것을 볼 수 있고. 리소스 요청에 대한 응답 시간도 크게 줄은것을 볼 수 있다. (개인 환경과, 인터넷 속도, 이미지 크기에 따라 다름)\n\n필자는 리소스 36KB에 대해 약 120밀리세컨드로 받았고 그 후 캐싱된 이미지는 약 40밀리세컨드로 받아온 모습이다.\n\n이로써 AWS Cloudfront로 S3 리소스 캐싱 작업을 수행했고.\n\n## CloudFront - S3 요금 정책\nAWS 문서에 따르면 Cloudfront - S3 간에 전송된 데이터는 S3에서 요금이 부과되지 않는다.\n\n![](https://blog.kakaocdn.net/dn/dvQZ5Q/btrnFazzAb7/ttfyBK0Xn02p0BhX7b17cK/img.png)\n\nCloudFront와 S3 간에 대한 데이터는 요금이 부과되지 않는거지 Client (인터넷) 에서 CloudFront 간에 데이터 송수신 과 HTTP 요청에 대해선 부과된다. \n\n자세한 요금은 다음 이미지를 참고하자\n\n![](https://blog.kakaocdn.net/dn/bNlRAh/btrnBzNjJZb/kf5n4Yw0xlfszmzTfWNPM0/img.png)\n![](https://blog.kakaocdn.net/dn/cVU1N0/btrnHSebQNc/TfigOAnI0JSSk3dKoB1H4K/img.png)\n\n\n## 레퍼런스\nhttps://jw910911.tistory.com/110\n","excerpt":"S3에 CloudFront 적용하기 현재 개발중인 서비스에서 이미지를 불러오는것을 S3에서 직접적으로 가져와 사용하고 있는데\n서비스 특성상 이러한 이미지와 영상과 같은 미디어 파일들을 많이 사용되는 서비스 구조라 \n서비스의 구조가 많이 무거워지고 리…","fields":{"slug":"/aws-s3-cloudfront/"},"frontmatter":{"date":"Apr 05, 2023","title":"[AWS] S3 리소스를 CloudFront를 통해 캐싱하자","tags":["AWS","Cache","S3","CloudFront"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n이 문서는 필자가 와카타임 작동이 안되는 문제를 해결하는 과정을 담았습니다. \n\n빠르게 결론부터 보고 싶으시면은 해결법을 봐주세요.\n\n# 오류 내용\n![Untitled](0.png)\n\n![Untitled](1.png)\n이번주에 갑자기 와카타임이 갑자기 측정이 안된것을 확인.\n\n인텔리제이에서도 와카타임이 `initialized` 로 뜨고 작업 시간 측정이 안되더라 \n그래서 플러그인을 재설치했지만 해결하지 못했음.\n\n![Untitled](2.png)\nWakaTime 인텔리제이 플러그인이 위치한 곳을 확인해봄. jar 형식으로 플러그인이 등록되어있는데 클린 삭제하면 될거 같아서 해당 파일을 삭제 후 IDE를 다시 실행하니 플러그인이 삭제됨. 그 후 다시 플러그인을 설치해도 같은 증상.\n\n혹시나 API Key 형식이 이번에 `waka_` 접두사가 붙은 형식으로 바뀌었길래 그 문제가 싶어서 \nAPI Key를 다시 넣어주기 위해 Wakatime config 파일이 위치한 `~/.wakatime.cfg`  를 열어보고 API Key를 다시 등록했다.\n\n![Untitled](3.png)\n\n그래도 같은 증상으로 안됬다. \n\n이제는 로그를 확인해야할 것 같아서 `.wakatime.cfg` 설정 파일에 `debug = true`로 debug를 활성화하여 인텔리제이 IDE 로그를 확인해봤다.\n\n![Untitled](4.png)\n\n인텔리제이의 로그를 확인하는 방법은 `Help - Show Log in folder` 를 눌러서 `idea.log` 파일을 열어보면된다.\n\n```shell\n2023-03-30 20:22:10,598 [ 690863]   FINE - WakaTime - Executing CLI: [/Users/seonghun/.wakatime/wakatime-cli-darwin-arm64, --entity, /Users/seonghun/Desktop/dev/art-be/src/main/java/com/example/codebase/ArtBackendApplication.java, --time, 1680175310.3830, --key, XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXbada, --lines-in-file, 31, --alternate-project, art-be, --alternate-language, JAVA, --plugin, idea/2023.1 idea-wakatime/14.1.4, --extra-heartbeats]\n2023-03-30 20:22:10,612 [ 690877]   WARN - WakaTime - Cannot run program \"/Users/seonghun/.wakatime/wakatime-cli-darwin-arm64\": error=2, No such file or directory\njava.io.IOException: Cannot run program \"/Users/seonghun/.wakatime/wakatime-cli-darwin-arm64\": error=2, No such file or directory\n\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1143)\n\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1073)\n\tat java.base/java.lang.Runtime.exec(Runtime.java:594)\n\tat java.base/java.lang.Runtime.exec(Runtime.java:453)\n\tat com.wakatime.intellij.plugin.WakaTime.sendHeartbeat(WakaTime.java:305)\n\tat com.wakatime.intellij.plugin.WakaTime.processHeartbeatQueue(WakaTime.java:298)\n\tat com.wakatime.intellij.plugin.WakaTime.access$000(WakaTime.java:52)\n\tat com.wakatime.intellij.plugin.WakaTime$3.run(WakaTime.java:159)\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\nCaused by: java.io.IOException: error=2, No such file or directory\n\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:314)\n\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:244)\n\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1110)\n\t... 13 more\n```\n\n로그를 살펴보니 `.wakatime/wakatime-cli-darwin-arm64` 파일이 없어서 wakatime-cli 실행을 하지 못한다고 나와있다. wakatime-cli를 다시 설치해보자\n\nwakatime-cli의 실행은 공식문서에 나온대로 \n`python3 -c \"$(wget -q -O - https://raw.githubusercontent.com/wakatime/vim-wakatime/master/scripts/install_cli.py)\"`\n해당 명령어를 실행하면 되는데 다음과 같은 에러가 뜨면서 설치가 되지 않았다.\n\n```shell\n[WakaTime Install] Downloading wakatime-cli...\n[WakaTime Install] GitHub API Response 304\n[WakaTime Install] Downloading wakatime-cli from https://github.com/wakatime/wakatime-cli/releases/download/\"\"\"v1.70.1\n= v1.68.3\"\"\"\"\"\"\"\"\"/wakatime-cli-darwin-arm64.zip\n[WakaTime Install] Traceback (most recent call last):\n  File \"<string>\", line 198, in downloadCLI\n  File \"<string>\", line 469, in download\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py\", line 216, in urlopen\n    return opener.open(url, data, timeout)\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py\", line 519, in open\n    response = self._open(req, data)\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py\", line 536, in _open\n    result = self._call_chain(self.handle_open, protocol, protocol +\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n    result = func(*args)\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py\", line 1391, in https_open\n    return self.do_open(http.client.HTTPSConnection, req,\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py\", line 1348, in do_open\n    h.request(req.get_method(), req.selector, req.data, headers,\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py\", line 1282, in request\n    self._send_request(method, url, body, headers, encode_chunked)\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py\", line 1293, in _send_request\n    self.putrequest(method, url, **skips)\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py\", line 1127, in putrequest\n    self._validate_path(url)\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py\", line 1227, in _validate_path\n    raise InvalidURL(f\"URL can't contain control characters. {url!r} \"\nhttp.client.InvalidURL: URL can't contain control characters. '/wakatime/wakatime-cli/releases/download/\"\"\"v1.70.1\\n= v1.68.3\"\"\"\"\"\"\"\"\"/wakatime-cli-darwin-arm64.zip' (found at least '\\n')\n\n[WakaTime Install] Finished extracting wakatime-cli.\n```\n살펴보니 \n```\nhttp.client.InvalidURL: URL can't contain control characters. '/wakatime/wakatime-cli/releases/download/\"\"\"v1.70.1\\n= v1.68.3\"\"\"\"\"\"\"\"\"/wakatime-cli-darwin-arm64.zip' (found at least '\\n')\n```\n**유효하지 않는 URL** 로 확인되는데. 해당 경로중에 문제되어 보이는 부분은 무수한 따옴표로 둘러싸인 부분이다. 아마 내부적으로 파싱이 잘못된것으로 보이인다.  Wakatime 내부 작동이 어디선가 잘못됬거나 설정이 꼬인것으로 보인다. 그리고 와카타임의 로그를 살펴보면 (와카타임 로그 파일의 위치는 `~/.waktime.log` )\n\n```\n{\"caller\":\"cmd/run.go:292\",\"file\":\"Terminal\",\"func\":\"cmd.runCmd\",\"level\":\"error\",\"message\":\"failed to run command: sending heartbeat(s) failed: rate limited: won't send heartbeat due to backoff\",\"now\":\"2023-03-30T20:45:14+09:00\",\"os/arch\":\"darwin/arm64\",\"plugin\":\"iterm2-wakatime/0.0.1\",\"time\":1680176714.53137,\"version\":\"v1.70.1\"}\n```\n`won't send heartbeat due to backoff` 오류가 발생하는데 다음과 같은 해결방법을 따라하면 해결된다.\n# 해결법\n와카타임 개발자에 [따르면](https://github.com/wakatime/wakatime-cli/issues/770) \n`won't send heartbeat due to backoff` means previously there was a connection error so it's waiting a while.\nYou can reset the rate limit backoff by deleting `~/.wakatime-internal.cfg`. What error message do you see after deleting the internal file\n\n즉 와카타임 에러 중에 `won't send heartbeat due to backoff` 가 발생하면 해당 wakatime-internal.cfg 파일을 삭제하라고 한다. \n\n![Untitled](5.png)\n그리고 해당 파일에 내용을 보면 cli_version 이 아까 파이썬으로 설치했을때 실패한 로그와 비슷하지 않는가?.. wakatime 내부 설정 파일이 잘못되서 발생한 오류였던것!\n( 왜 저런 식으로 된지는 이유를 모르겠다. )\n\n![Untitled](6.png)\n\n해당 파일을 삭제하니 정상적으로 되는 모습이다..","excerpt":"이 문서는 필자가 와카타임 작동이 안되는 문제를 해결하는 과정을 담았습니다.  빠르게 결론부터 보고 싶으시면은 해결법을 봐주세요. 오류 내용  \n이번주에 갑자기 와카타임이 갑자기 측정이 안된것을 확인. 인텔리제이에서도 와카타임이  로 뜨고 작업 시간…","fields":{"slug":"/wakatime-is-dead/"},"frontmatter":{"date":"Mar 30, 2023","title":"[Wakatime] 와카타임이 갑자기 죽었다. won't send heartbeat due to backoff 오류 해결법","tags":["error","wakatime"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"# Cert-Manager\n![Untitled](0.png)\nCert-Manager는 Kubernetes 내부에서 HTTPS 통신을 위한 인증서를 생성하고 인증서가 만료되면 자동으로 갱신해주는 Certificate Manager Controller 이다.\n\n해당 문서에서는 Cert-Manager에 대해 간단한 설치 방법과 Kubernetes의 인그레스에 적용하는 방법을 알아본다.\n그리고 ACME의 HTTP01 챌린지가 아닌 DNS01 챌린지를 통해 도메인 검증을 하는 과정을 적용한다.\n\n## 시작하기 앞서\nCert-Manager를 Helm를 통해서 설치한다 설치하는 차트 버전은 1.11 이다.\n`installCRDs=true`를 통해 CRD 또한 함께 설치한다.\n\n### 설치\n```shell\nhelm repo add jetstack https://charts.jetstack.io &&\n    helm install cert-manager jetstack/cert-manager \\\n        --namespace cert-manager \\\n        --create-namespace \\\n        --version v1.11.0 \\\n        --set installCRDs=true\n```\n\n## Cert-Manager Issuer 생성\nACME 발급자에 대해 다양한 DNS 공급자가 지원되는데 Cloudflare를 이용해보자.\n\n토큰은 사용자 프로필 > API 토큰 > API 토큰에서 생성할 수 있다. 다음 설정이 권장된다.\n\n- Permissions:\n  - Zone - DNS - Edit\n  - Zone - Zone - Read\n- Zone Resources:\n  - Include - All Zones\n\n새 Issuer를 만들려면 먼저 새 API 토큰을 포함하는 Kubernetes Secret를 만든다.\n\n```yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: cloudflare-api-token-secret\n  namespace: cert-manager\ntype: Opaque\nstringData:\n  api-token: <API_TOKEN_HERE>\n```\n`cloudflare-api-token-secret` 이름을 가진 Secret 리소스를 생성한다.\napi-token의 value로 cloudflare에서 발급받은 key를 넣어주면된다.\n중요한 부분으로 namespace는 cert-manager가 설치된 곳으로 지정한다. 생략하면 Issuer에서 secret를 참조하지 못한다.\n\nCert-Manager에서 제공하는 Issuer는 ClusterIssuer와 그냥 Issuer가 있다 둘의 차이점은 네임스페이스이다. Issuer는 생성된 네임스페이스에서만 적용이 되고 Cluster Issuer는 전체 네임스페이스의 여러 앱에서 사용할 수 있다.\n\n다음은 두개의 ClusterIssuer를 생성하는 YAML 이다.\n```yaml\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-staging\nspec:\n  acme:\n    # The ACME server URL\n    server: https://acme-staging-v02.api.letsencrypt.org/directory\n    # Email address used for ACME registration\n    email: <Email>\n    # Name of a secret used to store the ACME account private key\n    privateKeySecretRef:\n      name: letsencrypt-staging\n    solvers:\n    - dns01:\n        cloudflare:\n          email: <Email>\n          apiTokenSecretRef:\n            name: cloudflare-api-token-secret\n            key: api-token\n---\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod\nspec:\n  acme:\n    # The ACME server URL\n    server: https://acme-v02.api.letsencrypt.org/directory\n    # Email address used for ACME registration\n    email: <Email>\n    # Name of a secret used to store the ACME account private key\n    privateKeySecretRef:\n      name: letsencrypt-prod\n\n    solvers:\n    - dns01:\n        cloudflare:\n          email: <Email>\n          apiTokenSecretRef:\n            name: cloudflare-api-token-secret\n            key: api-token\n```\nLet's Encrypt에 대해 스테이징 및 프로덕션의 두 발급자를 설정하는데.\n  \nLet's Encrypt 프로덕션 발급자는 매우 [엄격한 속도 제한](https://letsencrypt.org/docs/rate-limits/)이 있다. 실험하고 학습할 때 이러한 한계에 도달하기가 매우 쉽습니다. 이러한 위험 때문에 Let's Encrypt 스테이징 발급자로 시작하고 작동하는 것이 만족스러우면 프로덕션 발급자로 전환한다.\n\n## Ingress TLS 적용\nIngress에 CertManager의 TLS를 적용하기 위해선 YAML 명세 파일에 두가지 부분을 추가하면 된다.\n\n만약 두개의 서비스를 인그레스로 각각 서브 도메인을 지정한다면 다음과 같은 모습으로 구성된다.\n\n```yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: service-ingress\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/proxy-body-size: \"1000000m\"\n    cert-manager.io/cluster-issuer: \"letsencrypt-staging\"\nspec:\n  tls:\n  - hosts: \n    - <domain1>\n    - <domain2>\n    secretName: <TLS_SECRET_NAME>\n  rules:\n    - host: <domain1>\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: <service_name>\n                port:\n                  number: port1\n    - host: <domain2>\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: <service_name>\n                port:\n                  number: port2\n```\nannotations 부분에 `cert-manager.io/cluster-issuer: \"letsencrypt-staging\"` 부분을 추가한다. cluster-issuer가 아닌 경우 issuer를 사용하면 된다. \n즉 `cert-manager.io/issuer` 이다.\n그 다음으론 TLS secret를 지정한다 `secretName: <TLS_SECRET_NAME></TLS_SECRET_NAME>` 해당 Secret은 우리가 생성해야하는 것이 아닌, cert-manager가 생성하는 secret이다. 해당 인그레스를 적용해서 생성하면은 자동으로 Cert-Manager가 해당 Secret Name으로 TLS 비밀키를 생성한다. 생성된 Secret의 데이터는 TLS 관련 개인키와 공개키가 데이터로 포함된다.\n\n스테이징이 잘 등록되면은 Prod으로 변경한다. 스테이징 인증서로 인그레스 도메인에 접속하면은 신뢰되지 않는 인증서로 등록된다. \n\n## TLS 적용된 모습\n![Untitled](1.png)\n인증서를 letsencrypt-prod으로 등록해서 인그레스를 다시 수정해서 적용하면은 인증서가 정상적으로 등록되는데 만약에 제대로 등록이 안된다면 기존 Secret를 삭제하면된다.\n\n공식 문서에서 따르면 cert-manager가 감시하고 업데이트된 발급자로 요청을 다시 처리하도록 하는 기존 Secret를 삭제해야 한다고 한다. 이렇게 하면 새 인증서를 받는 프로세스가 시작되고 설명을 사용하여 상태를 볼 수 있다. \n\n# 레퍼런스\nhttps://cert-manager.io/docs/tutorials/acme/nginx-ingress/\nhttps://cert-manager.io/docs/configuration/acme/dns01/\nhttps://github.com/cert-manager/cert-manager/issues/2131","excerpt":"Cert-Manager \nCert-Manager는 Kubernetes 내부에서 HTTPS 통신을 위한 인증서를 생성하고 인증서가 만료되면 자동으로 갱신해주는 Certificate Manager Controller 이다. 해당 문서에서는 Cert-Ma…","fields":{"slug":"/cert-manager-begin/"},"frontmatter":{"date":"Mar 14, 2023","title":"[K8S] Cert-Manager 설치 및 ACME DNS01 챌린지를 통한 Let's encrypt 인증서 발급 및 사용","tags":["Kubernetes","Cert-Manager"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"# NestJS란\n![](nest-og.png)\n\n*Node.JS에 기반을 둔 웹 API 프레임워크\nExpress 또는 Fastify 프레임워크를 래핑하여 동작함*\n\nNode.js는 쉽게 사용하고 뛰어난 확장성이 있지만, 과도한 유연함으로 인해 SW의 품질이 일정하지 않고 알맞는 라이브러리를 찾기 위해 개발자가 많은 시간을 할애해야함. 이에 반해 NestJS는 데이터베이스, ORM, 설정(Configuration), 유효성 검사 등 수많은 기능을 기본으로 제공.\n그리고 기본적으로 설치하면 Express를 Platform으로 사용함. \n\n## 특징\n- 기본 기능과 추가적으로 필요한 라이브러리를 설치해 쉽게 확장할 수 있는 Node.js의 장점을 가짐\n- Angular로 부터 영향을 많이 받아. 모듈/컴포넌트 기반으로 작성하여 재사용성을 높임\n- IoC, DI, AOP 와 같은 객체지향 개념을 도입함\n- 기본적으로 Typescript를 채택\n\n자세한건 [NestJS 공식 가이드 문서](https://docs.nestjs.com) 참고\n# Express.js vs NestJS\n\n| 구분            | Express.js                                                                                                                                   | NestJS                                                                                                                                                        |\n| --------------- | ----------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 유연함, 확장성  | 가볍게 서버를 띄울 수 있음. 하지만 높은 자유도로 인해 개발에 맞는 라이브러리를 찾아야함, 깃허브에 보일러플레이트를 이용한 코드베이스가 많음 | 미들웨어, IoC, CQRS 등 이미 많은 기능이 프레임워크 자체에 포함됨. 사용자는 문서를 보고 쉽게 따라할 수 있음, 원하는 기능이 없다면 다른 라이브러리를 적용하면됨 |\n| TypeScript 지원 | 추가 설정을 통해 사용                                                                                                                     | 기본적으로 Typescript, 추가 설정으로 JS로도 작성 가능                                                                                                                                   |\n| 커뮤니티        | 가장 큼                                                                                                                                   | 꾸준히 증가                                                                                                                                                   |\n\n# Nest JS 벤치마크\n![](benchmark.png)\nNestJS에 Express와 Fastify를 적용했을 경우(Platform으로)와 Express, Fastify 자체 성능 측정표\n\n측정 결과는 Express가 Fastify보다 느리고, NestJS Platform으로 적용하면 약간 더 성능이 떨어지는 것을 알 수 있음. 이는 NestJS가 기본 제공하는 프레임워크의 크기가 크기 때문. 하지만 순수 Express나 Fastify로 서버를 개발하다보면 추가적으로 요구되는 라이브러리들이 추가되므로 결국 NestJS에서 제공하는 기능들을 모두 구현한다고 했을땐 성능 차이가 크게 나지는 않음.\n\nExpress 프레임워크는 2022년도에 4.18.2 버전을 업데이트하였지만 최근에 와서야 활발하게 업데이트가 되고 있지만 그전에는 진짜 몇달동안 공백기가 있었음. 5.0을 준비하는 이유 때문일 수 있고, 매우 안정적인 프레임워크라 문제없이 운용되고 있다고 볼 수 있지만 최신 트렌드를 따라가지 못한다는 우려가 있는것은 사실.\n\n반면에 NestJS는 꾸준히 발전 중. 최근 릴리즈가 v9.3.6 (2023-02-08, 현재 글이 생성된 날짜기준) 이고 [깃허브](https://github.com/nestjs)를 통해 커뮤니티도 활발히 하고 있음.","excerpt":"NestJS란  Node.JS에 기반을 둔 웹 API 프레임워크\nExpress 또는 Fastify 프레임워크를 래핑하여 동작함 Node.js는 쉽게 사용하고 뛰어난 확장성이 있지만, 과도한 유연함으로 인해 SW의 품질이 일정하지 않고 알맞는 라이브러…","fields":{"slug":"/what-is-nestjs/"},"frontmatter":{"date":"Feb 10, 2023","title":"NestJS의 개요 및 특징","tags":["Backend","NestJS"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"![Prometheus아키텍처](1.png)\n\n*Prometheus는 메트릭 수집, 알림, 서비스 디스커버리 기능을 제공하는 오픈소스 모니터링 시스템입니다.*\n\nPrometheus는 단기 작업을 위해 직접 스크랩 하거나\nshort-lived jobs를 push gateway를 통해 스크랩합니다.\n스크랩한 모든 sample(TSD, 시계열 데이터)을 local 저장소에 저장하고 이 데이터에 대한 규칙(rules)을 실행하여 기존 데이터에서 새 시계열을 집계 및 기록하거나 alert를 생성합니다. \nGrafana 또는 기타 APIConsumers를 사용해 수집된 데이터를 시각화할 수 있습니다.\n\n## Prometheus 특징\n- TSD를 스크랩하고 저장하는 메인 Prometheus 서버\n- Application 코드를 계측하기 위한 [Client Libraries](https://prometheus.io/docs/instrumenting/clientlibs/)\n- short-lived jobs를 위한 push gateway\n- 특수 목적의 exportes (HAProxy, StatsD, Graphite)\n- alert를 핸들링하는 (처리하는) alertManager\n- 다양한 지원 도구\n\n## Prometheus 데이터 수집 방식\nPrometheus의 데이터 수집방식은 Pull 방식입니다. (Push 방식도 지원함)\n![Push/Pull방식](2.png)\n- Push 방식 - 데이터를 가진 곳에서 필요한 곳(모니터링 서비스)으로 보내준다.\n- Pull 방식 - 데이터가 필요한 곳(모니터링 서비스)에서 가진 곳에 접속해 데이터를 긁어간다(Scrape)\n\n이러한 방식들의 장단점은 4가지 측면에서 자세히 살펴 볼 수 있습니다.\n1. 수집 대상이 Auto-scaling 등으로 가변적일 경우\n2. 수집 대상의 데이터 유연성 측면\n3. 보안 측면\n4. HA* 측면\n\n*프로그램 등의 시스템이 상당히 오랜 기간동안 지속적으로 정상 운영이 가능한 성질\n\n\n### 1. 수집대상이 가변적일 경우\n![가변적](3.png)\nPush 방식이 유리합니다.\n\n### 2. 수집 대상의 데이터 유연성 측면\n![유연성](4.png)\nPull 방식이 유리합니다.\n\n### 3. 보안 측면\n![보안](5.png)\nPush 방식이 유리합니다. \n\n그 이유는 Pull 방식은 수집 대상에서 중앙 모니터링이 접근할 수 있는 IP, Port 등을 수신 대기해야합니다.\n\n### 4. HA 측면\n![HA](6.png)\nPull 방식이 유리합니다.\n\nPush 방식은 수집 대상이 중앙에 데이터 전송을 재시도를 지속적으로 해야하므로 영향이 생깁니다.\nPull 방식은 중앙 모니터링이 장애가 발생하더라도 수집 대상에는 영향이 없습니다.\n\n## Prometheus Metrics\n- Metrics 구성\n![metrics](7.png)\nPrometheus 메트릭 구성은 아래와 같습니다.\n`메트릭이름{필드1=값,필드2=값} @시간 샘플데이터(float 64)`\n\n- Metrics 표현 형식\n![metrics](8.png)\nPrometheus Metrics은 사람이 쉽게 이해할만한 표현 형식입니다.\n- \\# HELP 는 메트릭 이름, 간단한 설명(주석)\n- \\# TYPE 은 메트릭 타입 (Prometheus Metric Type : Counter, Gauge, Histogram, Summary)\n\n## Prometheus 아키텍처\n![아키텍처](9.png)\n모니터링의 기능으로 아키텍처를 파악하면 3가지로 구분될 수 있습니다.\n1. 수집 - 수집 대상으로 부터 Exporter를 설치, Prometheus Server가 Pull 방식으로 데이터 수집\n         Service Discover를 통해 Target 서버에 대한 정보를 편리하게 가져옴\n2. 저장 - Prometheus는 Sample(시계열 데이터) 수집시, In-Memory에 저장하고 있다가 주기적으로 Disk에 Flush함\n3. 서빙 - PromQL를 통해 질의하거나 외부 API 나 Prometheus Web UI, Grafana를 통해 데이터를 내보내거나 시각화\n\n## Prometheus 적합성\n\n### Prometheus는 언제 적합한가?\n이러한 경우에 Prometheus가 적합할 수 있습니다.\n1. 단순 숫자로 된 시계열 기록\n2. 모니터링과 고도의 동적인 서비스 지향 아키텍처 모니터링\n\nPrometheus는 MSA(Micro Service Architecture)에서 다차원 데이터 수집 및 쿼리 지원은 강점\nPrometheus는 모니터링 시스템으로서 안정성을 위해 설계되었고 각 프로메테우스 서버는 독립형이며 네트워크 스토리지 또는 원격 서비스에 의존하지 않습니다.\n\n### Prometheus는 언제 적합하지 않는가?\n요청당 청구 (per-request billing)과 같이 100% 정확도가 필요한 경우 수집된 데이터가 충분히 자세하고 완전하지 않을 수 있어서 좋은 선택이 아닐 수 있습니다.\n\n청구(billing)을 위해 데이터를 수집하고 분석하는데 다른 시스템을 사용하고 나머지 모니터링을 Prometheus를 사용하는게 가장 좋음","excerpt":"Prometheus는 메트릭 수집, 알림, 서비스 디스커버리 기능을 제공하는 오픈소스 모니터링 시스템입니다. Prometheus는 단기 작업을 위해 직접 스크랩 하거나\nshort-lived jobs를 push gateway를 통해 스크랩합니다.\n스크…","fields":{"slug":"/what-is-prometheus/"},"frontmatter":{"date":"Feb 09, 2023","title":"[Monitoring] Prometheus 개요 및 특징 그리고 데이터 수집 방식","tags":["Prometheus","Monitoring"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"# 1. 의존성 설정\n\n```groovy\nimplementation 'org.springframework.boot:spring-boot-starter-mail'\n```\n\nbuild.gradle 에 추가\n\n# 2.SMTP 설정\n\n```yaml\nspring:\n  mail:\n    host: smtp.gmail.com # SMTP 서버 호스트\n    port: 587 # SMTP 서버 포트\n    username: id # SMTP 서버 로그인 아이디 (발신자)\n    password: pw # SMTP 서버 로그인 패스워드 (앱 비밀번호)\n    properties:\n      mail:\n        smtp:\n          socketFactory.class: javax.net.ssl.SSLSocketFactory # 필수 아님\n          auth: true # 사용자 인증 시도 여부 (기본값 : false)\n          timeout: 5000 # Socket Read Timeout 시간(ms) (기본값 : 무한대)\n          starttls:\n            enable: true # StartTLS 활성화 여부 (기본값 : false)\n```\n\n구글 STMP 설정을 적용합니다.\n\n# 3. Controller 작성\n\n```groovy\n@Autowired\nprivate final MailSendService mailService;\n    \n@ApiOperation(value = \"이메일 인증 API\")\n@PreAuthorize(\"isAnonymous() or permitAll()\")\n@GetMapping(\"/mail\")\npublic ResponseEntity checkMail(@RequestParam String email) {\n        try {\n            log.info(\"이메일 인증 요청 발생 \\n 요청 이메일 : \" + email);\n            return new ResponseEntity(**mailService.joinEmail(email)**, HttpStatus.OK);\n        } catch (RuntimeException e) {\n            return new ResponseEntity(e.getMessage(), HttpStatus.BAD_REQUEST);\n        }\n    }\n```\n\n`Get` 메소드 코드를 작성합니다. \n\n`RequestParm`을 통해 email을 받아오고 `mailService.joinEmail(email)` 메소드를 호출하여 \n\n사용자의 이메일로 인증 번호를 발송합니다.\n\n# 4. Service 작성\n\n```java\n@Service\n@Slf4j\npublic class MailSendService {\n\n    private JavaMailSender emailSender;\n\n    public MailSendService(JavaMailSender emailSender) {\n        this.emailSender = emailSender;\n    }\n\n    public String joinEmail(String email) throws MessagingException{\n        String setFrom = \"보내는 사람\";\n        String toMail = email; // 보낼 사람\n        String title = \"[Test] 회원가입 인증 이메일\";\n        int authNumber = makeRandomNumber();\n        String content =\n                \"내용1\" +\n                        \"</br></br>\" +\n                        \"인증번호 : \" + authNumber + \"</br></br>\" +\n                        \"test\";\n        sendMail(setFrom, toMail, title, content);\n        return Integer.toString(authNumber);\n    }\n\n    private int makeRandomNumber() {\n        Random r = new Random();\n        int checkNum = r.nextInt(888888) + 111111;  // 111111 ~ 99999 사이의 난수 발생\n        log.info(\"이메일 인증번호 생성 : \" + checkNum);\n        return checkNum;\n    }\n\n    private void sendMail(String setFrom, String toMail, String title, String content)  throws MessagingException{\n        MimeMessage message = emailSender.createMimeMessage();   // 스프링에서 제공하는 메일 API\n        MimeMessageHelper helper = new MimeMessageHelper(message, true, \"utf-8\");\n        helper.setFrom(setFrom);\n        helper.setTo(toMail);\n        helper.setSubject(title);\n        helper.setText(content, true); // true -> html 형식\n        emailSender.send(message);\n    }\n}\n```\n\n# 5. Test 코드 작성\n\n```java\n    @Test\n    @DisplayName(\"이메일 인증 API 작동한다\")\n    public void test2() throws Exception {\n\n        mockMvc.perform(\n                        get(\"/api/mail\")\n                                .contentType(MediaType.APPLICATION_JSON)\n                                .param(\"email\", \"수신자 이메일\")\n                )\n                .andExpect(status().isOk())\n                .andDo(print());\n    }\n```\n\n\n# 6. 결과\n![Untitled](0.png)\n\n해당 방식의 문제점으로는 API의 응답에서 인증번호가 반환된다는 것이다.\n\n사용자가 해당 API 만 가지고 실질적으로 메일에 적힌 인증 번호로 가입해야하는데\n\n현 방식으로는 API 응답만 보고도 메일 안봐도 인증번호를 알 수 있다는것.\n\n해당 문제를 해결하기 위해 Redis에 인증번호를 저장하고 유효 시간동안 인증 처리를 해보자.\n\n다음 글에서 계속..\n\n# 레퍼런스\n\n[[Spring] SMTP 서버를 이용한 이메일 발송](https://dev-aiden.com/spring/Spring-%EC%9D%B4%EB%A9%94%EC%9D%BC-%EB%B0%9C%EC%86%A1/)","excerpt":"1. 의존성 설정 build.gradle 에 추가 2.SMTP 설정 구글 STMP 설정을 적용합니다. 3. Controller 작성  메소드 코드를 작성합니다.  을 통해 email을 받아오고  메소드를 호출하여  사용자의 이메일로 인증 번호를 발송…","fields":{"slug":"/springboot-mail-auth-smtp-gmail/"},"frontmatter":{"date":"Oct 08, 2022","title":"[SpringBoot] 회원가입 시 이메일 인증을 구현해보자 (Gmail)","tags":["SpringBoot"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"## 싱글톤 범위\n```java\nClient client1 = ctx.getBean(\"client\", Client.class);\nClient client2 = ctx.getBean(\"client\", Client.class);\n```\n\n위 코드에서 `client1` 객체와 `client2` 객체는 동일한 객체이다. \n\n스프링 컨테이너는 빈 객체를 한 개만 생성한다. 한 식별자에 대해 한 개의 객체만 존재하는 빈은 싱글톤(`Singleton`) 범위(`Scope`)를 갖는다. 별도 설정을 하지 않으면 빈은 싱글톤 범위를 갖는다\n\n## 프로토타입 범위\n\n```java\n// client 빈의 범위가 프로토타입\nClient client1 = ctx.getBean(\"client\", Client.class);\nClient client2 = ctx.getBean(\"client\", CLient.class);\n```\n\n위 코드에 서 `client` 빈의 범위가 프로토타입이면 `client1` 과 `client2` 는 서로 다른 객체이다.\n\n사용 빈도가 낮지만 빈의 범위를 프로토타입으로 지정할 수 있다. 프로토타입으로 지정하면 빈 객체를 구할 때 마다 매번 새로운 객체를 생성한다.\n\n### 포로토타입 범위의 라이프사이클\n\n프로토타입 범위를 갖는 빈은 완전한 라이프사이클을 따르지 않는다. 스프링 컨테이너는 프로토타입의 빈 객체를 생성하고 프로퍼티를 설정하고 초기화 작업까지는 수행하지만, 컨테이너를 종료한다고 해서 반드시 생성한 프로토타입 빈 객체의 소멸 메서드를 실행하지는 않는다. **따라서 프로토타입 범위의 빈을 사용할 때는 빈 객체의 소멸 처리를 직접해야한다**\n\n## @Scope 어노테이션\n\n### 프로토타입 범위 지정\n\n특정 빈을 프로토타입 범위로 지정하려면 다음과 같이 사용하면 된다.\n\n```java\n@Bean\n**@Scope(\"prototype\")**\npublic Client client() {\n\tClient client = new Client();\n\tclient.setHost(\"host\");\n\treturn client;\n}\n```\n\n- @Bean 어노테이션과 함께 @Scope 어노테이션을 “prototype” 값을 갖도록 한다\n\n### 싱글톤 범위 지정\n\n싱글톤 범위를 명시적으로 지정하고 싶다면 다음과 같이 사용하면 된다.\n\n```java\n@Bean(initMethod = \"connect\", destroyMethod = \"close\")\n@Scope(\"singleton\")\npublic Client2 client2() {\n\tClient2 client = new Client2();\n\tclient.setHost(\"host\");\n\treturn client;\n}\n```\n\n- @Bean 어노테이션과 함께 @Scope 어노테이션을 “singleton” 값을 갖도록 한다","excerpt":"싱글톤 범위 위 코드에서  객체와  객체는 동일한 객체이다.  스프링 컨테이너는 빈 객체를 한 개만 생성한다. 한 식별자에 대해 한 개의 객체만 존재하는 빈은 싱글톤() 범위()를 갖는다. 별도 설정을 하지 않으면 빈은 싱글톤 범위를 갖는다 프로토타…","fields":{"slug":"/bean_scope_annotation/"},"frontmatter":{"date":"Aug 16, 2022","title":"[Spring] 빈 객체의 생성과 관리 범위(@Scope 어노테이션)","tags":["Spring","스프링5입문시리즈"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"모든 클래스가 `InitializingBean`, `DisposableBean` 인터페이스를 상속받아 구현할 수 있는 것은 아니다. \n\n외부에서 제공받은 클래스(외부 라이브러리 등)를 스프링 `Bean` 객체로 설정하고 싶을 때도 있다. 이 경우에는 소스코드를 수정하지 않는 이상 두 인터페이스를 구현할 수 없다. \n\n이렇게 해당 인터페이스를 구현할 수 없거나 이 두 인터페이스를 사용하고 싶지 않은 경우에는 스프링 설정에서 직접 메소드를 지정할 수 있다.\n\n## 1. @Bean 태그 속성으로 메소드 지정\n\n```java\npublic class Client2 {\n\n    private String host;\n\n    public void setHost(String host) {\n        this.host = host;\n    }\n\n    public void connect() {\n        System.out.println(\"Client2.connect() 실행\");\n    }\n\n    public void send() {\n        System.out.printf(\"Client2.send() to \" + host);\n    }\n\n    public void close() {\n        System.out.printf(\"Client2.close() 실행\");\n    } \n}\n```\n\n`Clien2` 클래스를 빈으로 사용하려면(Client2가 외부 라이브러리에서 제공하는 클라이언트 인 경우도 포함) 초기화 과정에서 `connect()` 메소드를 실행하고 소멸 과정에서 `close()` 메소드를 실행해야 한다면 다음과 같이 `@Bean` 어노테이션의 속성을 지정해주면 된다.\n\n```java\n@Bean(initMethod = \"connect\", destroyMethod = \"close\")\n    public Client2 client2() {\n        Client2 client2 = new Client2();\n        client2.setHost(\"외부 라이브러리\");\n        return client2;\n    }\n```\n\n- `initMethod` 속성 : 초기화 과정에 사용할 메소드 이름 지정\n- `destoryMethod` 속성 : 소멸 과정에 사용할 메소드 이름 지정\n\n⚠️ `initMethod`, `destroyMethod` 속성에 지정한 메소드는 파라미터가 없어야한다. \n파라미터가 존재할 경우 스프링 컨테이너는 예외를 발생시킨다.\n\n위 설정을 추가한뒤 스프링을 실행하자. \n다음과 같이 `Clien2`  빈 객체를 위한 초기화/소멸 메소드가 실행된 것을 알 수 있다.\n\n```java\nClient2.connect() 실행\n7월 22, 2022 11:09:53 오전 org.springframework.context.support.AbstractApplicationContext doClose\n정보: Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@4b952a2d: startup date [Fri Jul 22 11:09:53 KST 2022]; root of context hierarchy\nClient2.close() 실행\nClient.destroy() 실행]\n```\n\n## 2. 빈 설정 메소드에서 직접 초기화\n\n설정 클래스는 자바 코드이므로 `initMethod` 속성을 사용하는 대신 다음과 같이 빈 설정 메서드에서 직접 초기화를 수행해도 된다.\n\n```java\n@Bean(destroyMethod = \"close\")\n    public Client2 client3() {\n        Client2 client2 = new Client2();\n        client2.setHost(\"외부 라이브러리\");\n        **client2.connect(); // 직접 초기화 메소드 호출**\n        return client2;\n    }\n```\n\n## 3. 설정 코드에서 커스텀 초기화 메소드 실행 시 주의할점\n\n초기화 메소드가 두번 불리지 않도록 하는 것\n\n```java\n\t\t@Bean\n    public Client client() {\n        Client client = new Client(); // initializingBean 구현체임\n        client.setHost(\"외부 라이브러리\");\n        client.afterPropertieset();\n        return client2;\n    }\n```\n\n이 코드는 빈 설정 메소드에서 `afterProperitesSet()` 메소드를 호출한다. 그런데 `Client` 클래스는 `InitalizingBean` 인터페이스를 구현했기 때문에 스프링 컨테이너는 빈 객체 생성 이후 `afterPropertiesSet()`메소드를 실행한다. 즉 해당 메소드가 두번 호출되는 것이다.\n\n초기화 관련 메소드를 빈 설정 코드에서 직접 실행할 때는 이렇게 초기화 메소드가 두번 호출되지 않도록 주의해야한다.","excerpt":"모든 클래스가 ,  인터페이스를 상속받아 구현할 수 있는 것은 아니다.  외부에서 제공받은 클래스(외부 라이브러리 등)를 스프링  객체로 설정하고 싶을 때도 있다. 이 경우에는 소스코드를 수정하지 않는 이상 두 인터페이스를 구현할 수 없다.  이렇게…","fields":{"slug":"/bean_custom_method/"},"frontmatter":{"date":"Jul 22, 2022","title":"[Spring] InitializingBean, DisposableBean 구현없이 초기화/소멸 메소드 실행하기","tags":["Spring","스프링5입문시리즈"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"스프링 컨테이너는 빈 객체를 초기화하고 소멸하기 위해 빈 객체의 지정한 메서드를 호출한다. 스프링은 다음의 두 인터페이스에 이 메서드를 정의한다.\n\n- org.springframework.beans.factory.**initalizingBean**\n- org.springframework.beans.factory.**DisposableBean**\n\n두 인터페이스는 다음과 같다\n\n```java\npublic interface initalizingBean {\n\tvoid afterPropertiesSet() throw Exception;\n}\n\npublic interface DisposableBean {\n\tvoid destroy() throw Exception;\n}\n```\n\n- 빈 객체를 생성한 뒤에 **초기화 과정이** 필요 : `InitalizingBean` 인터페이스를 상속하고 afterPropertiesSet() 메소드를 구현한다.\n- 빈 객체의 **소멸 과정이** 필요 :  `DisposableBean` 인터페이스를 상속하고 `destroy()` 메소드를 구현한다.\n\n### 초기화와 소멸과정이 필요한 예\n\n1. 데이터베이스 커넥션 풀\n    \n    커넥션 풀을 위한 빈 객체는 초기화 과정에 데이터베이스 연결을 생성한다. 컨테이너를 사용하는 동안 연결을 유지하고 빈 객체를 소멸할 때 사용중인 데이터베이스 연결을 끊어야 한다.\n    \n2. 채팅 클라이언트\n    \n    채팅 클라이언트는 시작할 때 서버와 연결을 생성하고 종료할 때 연결을 끊는다. 이때 서버와의 연결을 생성하고 끊는 작업을 초기화/소멸 시점에 수행하면 된다.\n    \n\n### 간단한 코드 예제를 통해 알아보기\n\n간단하게 빈 객체의 초기화와 소멸 시점을 코드를 작성하고 실행해서 알아보자\n\n```java\npublic class Client implements InitializingBean, DisposableBean {\n\n    private String host;\n\n    public void setHost(String host) {\n        this.host = host;\n    }\n\n    @Override\n    public void afterPropertiesSet() throws Exception {\n        System.out.println(\"Client.afterPropertiesSet() 실행\");\n    }\n\n    public void send() {\n        System.out.println(\"Client.sned() to \" + host);\n    }\n\n    @Override\n    public void destroy() throws Exception {\n        System.out.println(\"Client.destroy() 실행\");\n    }\n}\n```\n\n실행되는 순서를 알아보기 위해 콘솔에 관련 메세지를 출력하도록 했다.\n\n`Client` 클래스를 위한 설정 클래스는 다음과 같다.\n\n```java\n@Configuration\npublic class AppCtxForClient {\n\n    @Bean\n    public Client client() {\n        Client client = new Client();\n        client.setHost(\"host\");\n        return client;\n    }\n\n}\n```\n\n이제 `AppCtxForClient`를 이용해서 스프링 컨테이너를 생성하고 `Client` 빈 객체를 구해 사용하는 코드를 작성한다.\n\n```java\npublic class Main {\n\n    public static void main(String[] args) throws IOException {\n        AbstractApplicationContext ctx = new AnnotationConfigApplicationContext(\n            AppCtxForClient.class);\n\n        Client client = ctx.getBean(Client.class);\n        client.send();\n\n        ctx.close();\n    }\n}\n```\n\n`Main` 클래스를 실행해보면 다음과 같은 메세지가 출력된다.\n\n```java\nClient.afterPropertiesSet() 실행\nClient.sned() to host\nClient.destroy() 실행\n7월 14, 2022 6:06:00 오후 org.springframework.context.support.AbstractApplicationContext doClose\n정보: Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@4b952a2d: startup date [Thu Jul 14 18:05:59 KST 2022]; root of context hierarchy\n```\n\n1. 스프링 컨테이너 생성\n2. 빈 객체 생성\n3. 빈 객체 초기화\n    1. `afterPropertiesSet` 메소드 실행\n4. 스프링 컨테이너 종료\n5. 빈 객체 소멸\n    1. `destory` 메소드 실행\n\n만약 `ctx.close()` 메소드가 실행되지 않다면 컨테이너의 종료 과정을 수행하지 않기 때문에 빈 객체의 소멸 과정도 실행되지 않는다.","excerpt":"스프링 컨테이너는 빈 객체를 초기화하고 소멸하기 위해 빈 객체의 지정한 메서드를 호출한다. 스프링은 다음의 두 인터페이스에 이 메서드를 정의한다. org.springframework.beans.factory.initalizingBean org.spr…","fields":{"slug":"/spring-bean-init-and-disposable/"},"frontmatter":{"date":"Jul 14, 2022","title":"[Spring] 빈 객체의 초기화와 소멸 : initalizingBean과 DisposableBean 인터페이스 ","tags":["Spring","스프링5입문시리즈"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n외부 라이브러리 없이, 웹 표준을 만족하는 API인 Web Speech API 만으로 TTS를 사용해보자.\n\nWeb Speech API는 크게 SpeechSynthesis(Text-to-Speech)와 SpeechRecognition (Asynchronous Speech Recognition) 두 가지로 나뉜다.\n\nSpeechSynthesis는 텍스트를 음성으로 변환하는 API이고, SpeechRecognition은 음성을 텍스트로 변환하는 API이다. 우리가 사용해야할 API는 SpeechSynthesis이다. 해당 API는 대부분의 모던 브라우저에서는 지원된다. (해당 API가 지원하는 브라우저 목록이 궁금하다면? [https://caniuse.com/?search=speech](https://caniuse.com/?search=speech))\n\n## 1. Web Speech API 세팅\n\n```jsx\nconst pitch = 1;\nconst rate = 1;\n\nasync function populateVoiceList(synth: SpeechSynthesis) {\n    try {\n      const voices = await synth.getVoices().sort(function (a, b) {\n        const aname = a.name.toUpperCase();\n        const bname = b.name.toUpperCase();\n        if (aname < bname) return -1;\n        else if (aname === bname) return 0;\n        else return +1;\n      });\n  \n      return voices;\n    } catch (error) {\n      throw new Error(\"Failure retrieving voices\");\n    }\n}\n\nexport async function speak(textToRead: string, synth: SpeechSynthesis) {\n    if (speechSynthesis.onvoiceschanged !== undefined) {\n      speechSynthesis.onvoiceschanged = () => populateVoiceList\n    }\n  \n    if (synth.speaking) {\n      console.error(\"speechSynthesis.speaking\")\n      return\n    }\n    if (textToRead !== \"\") {\n      const utterThis = new SpeechSynthesisUtterance(textToRead)\n      utterThis.onend = function (event) {\n      }\n      utterThis.onerror = function (event) {\n        console.error(\"SpeechSynthesisUtterance.onerror\")\n      }\n      // utterThis.voice = voices[0]\n      utterThis.pitch = pitch\n      utterThis.rate = rate\n      synth.speak(utterThis)\n    }\n}\n```\n\n`speechSynthesis.onvoiceschanged` 조건문은 우리가 사용할 수 있는 음성 목록을 가져온다.\n\n- 해당 부분에 synth.getVoices()를 통해 임의의 사용자 지정 음성 목록을 만들면 유용하다.\n\n이 단계를 건너뛰면 `SpeechSynthesis`에 음성을 제공하지 않아 오류가 발생할 수 있다. 비동기로 설정하지 않으면 음성 합성기가 읽기를 시도할 때 음성이 잘리거나 준비되지 않을 수 있는 문제가 발생한다.\n\n그 후 함수의 인자로 넘어온 textToRead 문자열 검사를 한 후, synth.speak(utterThis) 함수를 사용하므로 음성 재생을 한다.\n\n## 2. Button으로 TTS 재생\n\n```jsx\n<Button\n   variant=\"outlined\"\n   startIcon={<CampaignIcon />}\n   onClick={() => {\n       speechSynthesis.cancel();\n       speak('여름에 해당하는 이미지를 찾으세요', window.speechSynthesis);\n}}>\n설명 듣기\n</Button>\n```\nmui component의 Button 컴포넌트를 구현하여 사용했다.\n\n버튼이 클릭되면 speechSynthesis API를 종료하고, 제작한 speak 함수를 호출한다.\n\n![Untitled](1.png)\n\n위 와 같은 모습으로 간단하게 TTS 기능을 구현할 수 있다.\n\n# 레퍼런스\n\n[https://blog.seulgi.kim/2016/08/web-speechsynthesis-tts-api.html](https://blog.seulgi.kim/2016/08/web-speechsynthesis-tts-api.html)\n\n[https://www.singlestoneconsulting.com/blog/how-to-build-a-text-to-speech-app-with-the-web-speech-api/](https://www.singlestoneconsulting.com/blog/how-to-build-a-text-to-speech-app-with-the-web-speech-api/)","excerpt":"외부 라이브러리 없이, 웹 표준을 만족하는 API인 Web Speech API 만으로 TTS를 사용해보자. Web Speech API는 크게 SpeechSynthesis(Text-to-Speech)와 SpeechRecognition (Asynchro…","fields":{"slug":"/react-tts/"},"frontmatter":{"date":"Jul 13, 2022","title":"[React] 외부 라이브러리 없이 Text To Speech(TTS)를 사용해보자","tags":["React"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"# 0. 시작하기 전\n이미지 파일을 실시간으로 감지하고, 스프링 서버로 전송하는 것을 구현하였습니다.\n\n기본적인 구조는 클라이언트-서버 구조를 가지고있습니다\n\n클라이언트는 파일을 생성하고 파일을 감지하여 서버로 전송합니다\n\n서버는 클라이언트로 부터 받은 파일을 어떤 폴더로 저장하는 기능을 수행합니다\n\n# 1. 실시간 파일 감지 프로그램\n\n어떤 프로그램에 의해 어떤 경로에 이미지 파일이 지속적으로 생성된다고 가정하겠습니다.\n\n해당 컴퓨터(이하 클라이언트)에서 자바의 `WatchService`를 이용해 파일을 실시간으로 감지합니다.\n\n이 감지하는 프로그램의 코드를 보겠습니다.\n\n## Main.java\n\n```java\npackage org.example;\n\npublic class Main {\n    public static void main(String[] args) {\n        try {\n            FileWatch fileWatch = new FileWatch();\n            fileWatch.create();\n            fileWatch.run();\n        } catch (Exception e) {\n            e.getStackTrace();\n        }\n    }\n\n}\n```\n\n- `fileWatch` 인스턴스를 생성하고 초기화합니다.\n- 그리고 `create()` 와 `run()` 메소드를 호출하였습니다.\n- try-catch 으로 감싸 예외 처리를 해줬습니다.\n\n\n`main` 메소드 코드를 통해 자세한 프로그램 기능과 역활은 잘 모르겠지만 이 프로그램의 동작 구조를 파악할 수 있습니다.\n\n`create()` 메소드를 통해 어떠한 생성, 초기화 작업을 할것이고. `run()` 메소드를 통해 어떠한 작업을 하는 것을 볼 수 있습니다.\n\n이제부터 FileWatch클래스의 역활과 기능을 자세히 살펴보겠습니다.\n\n## FileWatch.java\n\n```java\npackage org.example;\n\nimport okhttp3.*;\nimport org.jetbrains.annotations.NotNull;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.nio.file.*;\nimport java.util.List;\nimport java.util.Scanner;\n\npublic class FileWatch {\n    private WatchService watchService;\n\n    private Path path;\n\n    private static Integer createdFileCount = 0;\n\n    private final String serverUrl = \"http://localhost:8080/upload\";\n\n    public FileWatch() {}\n\n    public void create() throws IOException {\n\t\t\t\t...\n    }\n\n    public void run() throws Exception {\n\t\t\t\t...\n    }\n\n    void fileSendToServer(String fileName, String currentFilePath){\n\t\t\t\t...\n    }\n\n}\n```\n\nFileWatch는 사용자가 지정한 경로를 실시간으로, 파일 변경에 대해 감지하고 HTTP 통신을 통해 서버로 파일을 전송합니다.\n\n자바에서 제공하는 WatchService 클래스를 멤버로 가지는데 WatchService에 대해 간단하게 알아보겠습니다.\n\n### WatchService란?\n\n자바에는 한 디렉토리(폴더) 내부 파일의 변화를 감지할 수 있는 기능을 제공합니다.\n\n디렉토리안에 있는 파일이 생성, 수정, 삭제되었을 때 이를 감지합니다.\n\n그리고 WatchService는 파일변경 통지 매커니즘으로 알려집니다.\n\n해당 서비스의 동작 순서는 이러합니다.\n\n1. 생성 : WatchService를 초기화\n2. 감시자 지정 : 감지할 경로를 등록하고 어떤 변화를 감시할 것인지를 지정.\n3. 서비스 실행 : \n    디렉토리에 WatchService를 등록한 순간부터 내부 변경이 발생하면 WatchEvent가 발생하고 WatchService는 해당 이벤트 정보를 가진 WatchKey를 생성해 Queue에 넣어집니다. \n    \n    프로그램은 루프를 돌면서 WatchService의 take() 메서드를 호출해 WatchKey가 들어올 때 까지 대기하고 있다가 WatchKey가 큐에 들어오면 WatchKey를 얻어 처리.\n    \n4. 이벤트 처리 : WatchEvent 리스트에서 WatchEvent를 하나씩 꺼내 이벤트 종류와 Path 객체를 얻고 처리.\n5. 이벤트 초기화 : 한번 사용 된 WatchKey는 reset() 메소드로 초기화해야합니다.\n    그 이유는 새로운 WatchEvent가 발생하면 큐에 다시 들어가기 때문입니다\n    초기화에 성공시 true, 감시하는 디렉토리가 삭제됬거나 키가 유효하지 않을 경우 false를 반환\n6. 종료 : \n    WatchKey가 유요하지 않게되면 루프를 빠져나와 WatchService의 close() 메소드를 호출하고 종료\n    \n\n## FileWatch.create()\n\n```java\npublic void create() throws IOException {\n\t\t\t\tScanner sc = new Scanner(System.in);\n        watchService = FileSystems.getDefault().newWatchService();\n\n        System.out.println(\"서버 경로를 입력해주세요(입력안할 시 기본 URL) :\");\n        String tempUrl = sc.nextLine();\n        if (!tempUrl.equals(\"\")) {\n            serverUrl = tempUrl;\n        }\n        System.out.println(serverUrl + \"로 연결합니다\");\n\n        System.out.print(\"경로를 입력해주세요 : \");\n        String filePath = sc.nextLine();\n\n        path = Paths.get(filePath);\n\n        path.register(watchService,\n                StandardWatchEventKinds.ENTRY_CREATE,\n                StandardWatchEventKinds.ENTRY_MODIFY,\n                StandardWatchEventKinds.ENTRY_DELETE,\n                StandardWatchEventKinds.OVERFLOW\n        );    \n}\n```\n\n`create` 메소드에서는 서버 경로를 입력받고 감시할 디렉터리 경로를 입력받습니다.\n\n```java\n       **path.register(watchService,\n                StandardWatchEventKinds.ENTRY_CREATE,\n                StandardWatchEventKinds.ENTRY_MODIFY,\n                StandardWatchEventKinds.ENTRY_DELETE,\n                StandardWatchEventKinds.OVERFLOW\n        );**  \n```\n\n`Path` 객체를 통해 `WatchService`를 등록합니다. `StandardWatchEventKinds`를 지정하여 **생성**, **수정**, **삭제**, 유효 처리에 대한 이벤트를 감지하도록 등록하였습니다.\n\n## FileWatch.run()\n\n```java\npublic void run() throws Exception {\n        String watchPath = path.getParent() + \"/\" + path.getFileName() + \"/\";\n        System.out.println(\"감시하는 경로 : \" + watchPath + \"\\n\");\n\n        while (true) {\n            WatchKey key = watchService.take();\n            List<WatchEvent<?>> watchEvents = key.pollEvents();\n\n            for (WatchEvent<?> event : watchEvents) {\n                WatchEvent.Kind<?> kind = event.kind();\n                Path newFIle = (Path) event.context();\n                Path absolutePath = newFIle.toAbsolutePath();\n\n                if (kind.equals(StandardWatchEventKinds.ENTRY_CREATE)) {\n                    String filepaths = watchPath + newFIle.getFileName().toString();\n                    System.out.println(String.format(\"[%d번] 파일 생성됨 : %s\", ++createdFileCount, newFIle.getFileName()));\n                    fileSendToServer(newFIle.getFileName().toString(),filepaths);\n\n                } else if (kind.equals(StandardWatchEventKinds.ENTRY_MODIFY)) {\n                    System.out.println(\"파일 수정됨 : \" + newFIle.getFileName() + \"\\n\");\n                } else if (kind.equals(StandardWatchEventKinds.ENTRY_DELETE)) {\n                    System.out.println(\"파일 삭제됨 : \" + newFIle.getFileName() + \"\\n\");\n                } else if (kind.equals(StandardWatchEventKinds.OVERFLOW)) {\n                    System.out.println(\"Overflow \\n\");\n                }\n            }\n            if (!key.reset()) {\n                try {\n                    watchService.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n    }\n```\n\n`run()` 메소드에서는 파일 감지 이벤트를 조건문으로 생성 시, 수정 시, 각각에 대한 적절한 처리를 해줬습니다.\n\n파일이 생성되면 `fileSendToServer` 메소드로 파일의 이름, 경로를 인자로 넘겨 서버로 전송합니다.\n\n## FileWatch.fileSendToServer(…)\n\n```java\nvoid fileSendToServer(String fileName, String currentFilePath){\n        OkHttpClient client = new OkHttpClient();\n\n        RequestBody requestBody = new MultipartBody.Builder().setType(MultipartBody.FORM)\n                .addFormDataPart(\n                        \"file\", // 파라미터\n                        fileName,\n                        RequestBody.create(MediaType.parse(\"text/csv\"), new File(currentFilePath))\n                ).build();\n        Request request = new Request.Builder()\n                .url(serverUrl)\n                .post(requestBody)\n                .build();\n        System.out.println(String.format(\"파일 경로 : %s\", currentFilePath));\n\n        client.newCall(request).enqueue(new Callback() {\n            @Override\n            public void onFailure(@NotNull Call call, @NotNull IOException e) {\n                System.out.println(\"전송 실패 : \" + call.request().toString());\n                System.out.println(\"에러 내용 : \" + e.getMessage());\n                System.out.println();\n\n            }\n\n            @Override\n            public void onResponse(@NotNull Call call, @NotNull Response response) throws IOException {\n                System.out.println(\"전송 응답 : \" + response.body().string());\n                System.out.println();\n            }\n        });\n    }\n```\n\n`OkHTTPClient` 라이브러리를 사용해 간단하게 HTTP 통신을 수행합니다.\n\n`RequestBody` 객체로 파일에 대한 형식과, 파라미터, 파일 이름에 대해 설정 합니다.\n\n`Request` 객체를 통해 서버의 경로와 Body에 대한 설정을 하고\n\n`client.newCall()` 메소드를 통해 실질적으로 서버로 HTTP 요청을 전송.\n\n콜백함수를 통해 정상,실패에 대한 처리를 해줬습니다.\n\nFileWatch에 대한 코드 설명은 끝났습니다. 이제부터 파일 통신을 담당하는 스프링 서버를 보겠습니다.\n# 2. 스프링 파일 서버\n\n- build.gradle\n    \n    ```java\n    plugins {\n        id 'org.springframework.boot' version '2.7.0'\n        id 'io.spring.dependency-management' version '1.0.11.RELEASE'\n        id 'java'\n        id 'org.springframework.experimental.aot' version '0.12.0'\n    }\n    \n    group = 'com.hoon'\n    version = '0.0.1-SNAPSHOT'\n    sourceCompatibility = '11'\n    \n    configurations {\n        compileOnly {\n            extendsFrom annotationProcessor\n        }\n    }\n    \n    repositories {\n        maven { url 'https://repo.spring.io/release' }\n        mavenCentral()\n    }\n    \n    dependencies {\n        implementation 'org.springframework.boot:spring-boot-starter-validation'\n        implementation 'org.springframework.boot:spring-boot-starter-web'\n        compileOnly 'org.projectlombok:lombok'\n        annotationProcessor 'org.projectlombok:lombok'\n        testImplementation 'org.springframework.boot:spring-boot-starter-test'\n    }\n    \n    tasks.named('test') {\n        useJUnitPlatform()\n    }\n    \n    tasks.named('bootBuildImage') {\n        builder = 'paketobuildpacks/builder:tiny'\n        environment = ['BP_NATIVE_IMAGE': 'true']\n    }\n    ```\n    \n    자바 버전은 11, 스프링은 2.7.0 버전을 사용하고, 롬복과 유효처리 의존성을 가집니다.\n    \n\n파일 서버는 간단하게 하나의 컨트롤러를 가지고 따로 영속성 처리를 위한 데이터베이스를 가지고 있지 않습니다. 따라서 간단한 패키지 구조를 가집니다.\n\n## FileController.java\n\n```java\n@RestController\n@Slf4j\npublic class FileController {\n    @Value(\"${uploadPath}\")\n    private String FILE_UPLOAD_PATH;\n\n    @PostMapping(value = \"/upload\", consumes = {MediaType.MULTIPART_FORM_DATA_VALUE})\n    public ResponseEntity addFiles(@RequestParam(\"file\") MultipartFile file) {\n        try {\n            saveFile(file);\n        } catch (Exception e) {\n            return new ResponseEntity(e.getMessage(), HttpStatus.BAD_REQUEST);\n        }\n        return new ResponseEntity(\"파일이 업로드 되었습니다\", HttpStatus.OK);\n    }\n\n    public void saveFile(MultipartFile file) throws IOException {\n        String newFileName = UUID.randomUUID() + \"_\" + file.getOriginalFilename();\n        File saveFile = new File(FILE_UPLOAD_PATH, newFileName);\n        log.info(\"새로운 파일 저장! 경로 : \" + saveFile.getAbsolutePath());\n        FileCopyUtils.copy(file.getBytes(), saveFile);\n    }\n}\n```\n\n서버의 `/upload` URL로 `POST` 요청을 처리하는 `addFiles` 메소드가 있습니다. 파일을 저장할때 중복으로 저장할 수 있으므로 UUID를 통해 파일명을 새롭게 수정해줬습니다.\n\n정상적으로 파일이 업로드되었으면 200 Code를 반환하고 그러지 않으면 400 Code를 반환합니다.\n\n`saveFile` 메소드는 요청으로 받은 파일을 서버 지정한 경로로 파일을 저장하는데 해당 저장 경로는 `application.properties`에서 지정합니다.\n\n## application.properties\n\n```java\nspring.servlet.multipart.maxFileSize=10MB\nspring.servlet.multipart.maxRequestSize=10MB\nuploadPath=./images/\n```\n\n# 3. 실행 결과\n\n## FileWatch 프로그램\n\n![실시간으로 파일을 감지하고 서버로 전송하고 정상적으로 응답이 받아오는 모습](1.png)\n\n실시간으로 파일을 감지하고 서버로 전송하고 정상적으로 응답이 받아오는 모습\n\n## FileServer\n\n![클라이언트로 부터 받은 파일을 정상적으로 저장하는 모습](2.png)\n\n클라이언트로 부터 받은 파일을 정상적으로 저장하는 모습\n\n이로써 간단하게 실시간으로 파일을 감지하고 서버로 파일을 전송하는 프로그램을 제작해봤습니다.\n","excerpt":"0. 시작하기 전 이미지 파일을 실시간으로 감지하고, 스프링 서버로 전송하는 것을 구현하였습니다. 기본적인 구조는 클라이언트-서버 구조를 가지고있습니다 클라이언트는 파일을 생성하고 파일을 감지하여 서버로 전송합니다 서버는 클라이언트로 부터 받은 파일…","fields":{"slug":"/filedetect-springfileserver/"},"frontmatter":{"date":"Jul 06, 2022","title":"실시간으로 파일 감지하고 스프링으로 파일 통신을 해보자","tags":["SpringBoot","ToyProject","FileWatch"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"# JPA 및 H2 세팅\n\nbuild.gradle 파일에 h2, jpa 의존성을 추가합니다.\n\n```\nimplementation 'org.springframework.boot:spring-boot-starter-data-jpa'\nruntimeOnly 'com.h2database:h2'\n```\n\n그리고 application.properties 파일에 h2 와 jpa 에 대한 설정을 작성합니다.\n\n```\n# h2 설정\nspring.h2.console.enabled=true\nspring.datasource.driver-class-name=org.h2.Driver\nspring.datasource.url=jdbc:h2:mem:testdb\nspring.datasource.username=sa\nspring.datasource.password=\n\n# JPA 설정\nspring.jpa.database-platform=org.hibernate.dialect.H2Dialect\nspring.jpa.hibernate.ddl-auto=create-drop\nspring.jpa.properties.hibernate.show_sql=true\nspring.jpa.properties.hibernate.format_sql=true\n\nlogging.level.org.hibernate.type.descriptor.sql=trace\n```\n\n- `spring`\n    - `h2`\n        - `console.enabled` : h2 console 페이지 활성화\n    - `datasource`\n        - `driver-class-name` : 데이터베이스 드라이버를 지정\n        - `url` : 데이터베이스의 경로를 지정합니다 (jdbc:h2:mem → 인메모리)\n        - `username, password` : 데이터베이스 접속하는 유저 정보\n    - `jpa`\n        - `database-platform` : SQL 문법을 지정합니다.\n        - `properties.hibernate.show_sql` : hibernate를 통해 CRUD의 SQL을 로그로 보여줍니다\n        - `properties.hibernate.format_sql` : SQL 문법에 대한 보기좋게 포맷 지정\n        - `hibernate`\n            - `ddl-auto` : 서버를 실행할때 DB 초기화 전략을 지정합니다. (create-drop)\n- `logging`\n    - `level`\n        - `org.hibernate.type.descriptor.sql`: 로깅을 통해 보여지는 SQL문의 내부 값을 출력합니다\n\n# H2 세팅 확인\n\n그리고 서버를 실행해 h2 데이터베이스의 콘솔을 시작합니다.\n\n[http://localhost:8080/h2-console](http://localhost:8080/h2-console) 로 접속을합니다.\n\n![Untitled](1.png)\n\n해당 페이지가 나오게 되는데 Connect 버튼을 눌러 DB에 접속합니다.\n\n![Untitled](2.png)\n\n해당 페이지가 나타나면 정상적으로 h2 세팅이 완료됬습니다.\n\n# JPA 세팅 확인\n\n- JPA 의 동작 원리\n    \n    ![Untitled](3.png)\n    \n\nJPA가 정상적으로 구동하는지 테스트로 코드를 수정합니다.\n\n## User 클래스 수정\n\nUser Entity 클래스을 수정합니다.\n\n```java\n@Entity\n@Getter\n@Setter\n@ToString\npublic class User {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    private String name;\n}\n```\n\n- @Entity : 지정한 클래스를 DB의 테이블과 일대일 매칭\n- @Id : PK 필드를 지정\n- @GenratedValue : PK의 키값 생성 전략 지정 (GenerationType.IDENTITY는 DB에 전략생성 위임)\n\n## UserRepository 수정\n\n이전에는 UserRepository 인터페이스가 상속을 받지 않았고, UserRepositoryImpl 구현체가 있었습니다.\n\n이제는 JPA를 통해서 DB CRUD를 진행하므로 인터페이스를 작성하고 JpaRepository를 상속만 하면됩니다.\n\n```java\npublic interface UserRepository extends JpaRepository<User, Long> {\n\n    Optional<User> findByName(String name);\n}\n\n/* 개발자가 직접 쿼리를 작성한 예시 (참고로 JPQL은 테이블이 아닌 엔티티를 대상으로 쿼리를 발생함)\npublic interface PostsRepository extends JpaRepository<Posts, Long> {\n\n    @Query(\"select p from Posts p order by p.id desc\")\n    List<Posts> findAllDesc();\n*/\n```\n\n- @Query : 어노테이션을 메소드에 지정하여 개발자가 직접 쿼리(JPQL, SQL)를 작성할 수 있습니다. (`nativeQuery = true` 옵션을 통해 SQL 문으로 작성함)\n    \n    해당 어노테이션은 SQL 문법오류를 체크하지 못하고 런타임 에러가 발생하지 못하는 단점 있으므로 이는 Querydsl을 참고해주세요\n    \n\nJPA 의 엄청난 쿼리메소드 기능을 통해 이용자의 이름을 DB에 검색하는 기능을 추가하겠습니다.\n\n인터페이스에 findByName 메소드를 추가합니다. \n\n해당 메소드는 name 변수를 매개변수로 받아서 DB에 해당 name과 동일한 객체를 찾아 반환합니다.\n\n## 서버 실행\n\n이제 서버를 구동하여 JPA 가 정상적으로 작동하는지 확인해보겠습니다.\n\n```java\n2022-01-20 00:55:24.381  INFO 2081 --- [           main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.H2Dialect\nHibernate: \n    \n    drop table if exists user CASCADE \nHibernate: \n    \n    create table user (\n       id bigint generated by default as identity,\n        name varchar(255),\n        primary key (id)\n    )\n2022-01-20 00:55:24.508  INFO 2081 --- [           main] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]\n```\n\n서버를 실행하면 로그에 해당 Hibernate 로그가 발생하는 것을 볼수있습니다. 이것은 application.properties에 작성한 `show_sql` 속성을 통해서 Hibernate의 CRUD가 SQL 구문으로 출력되는 것이고, `ddl-auto` 에 속성을 통해 우리가 지정한 전략(create-drop)을 통해서 DB의 테이블이 초기화되는 부분입니다.\n\n그리고 @Entity 으로 지정한 User 클래스가 테이블로 생성되는 구문 또한 확인할 수 있습니다.\n\n### User 테이블 생성확인\n\n[http://localhost:8080/h2-console](http://localhost:8080/h2-console) 에 접속하여, USER 테이블이 생성됬는지 확인하겠습니다.\n\n![Untitled](4.png)\n\nUSER 테이블이 정상적으로 생성됬습니다. \n\n### DB 저장 확인\n\n이제 API 를 통해 회원가입을 진행하고 해당 값이 정상적으로 저장됬는지 확인하겠습니다.\n\n- 요청 : `POST` [http://localhost:8080/user/new?name=hoon](http://localhost:8080/user/new?name=hoon)\n- 응답 :\n    \n    ```json\n    저장됨 hoon\n    ```\n    \n- 서버 로그\n    \n    ```json\n    Hibernate: \n        select\n            user0_.id as id1_0_,\n            user0_.name as name2_0_ \n        from\n            user user0_ \n        where\n            user0_.name=?\n    2022-01-20 01:09:03.889 TRACE 2081 --- [nio-8080-exec-9] o.h.type.descriptor.sql.BasicBinder      : binding parameter [1] as [VARCHAR] - [hoon]\n    Hibernate: \n        insert \n        into\n            user\n            (id, name) \n        values\n            (null, ?)\n    2022-01-20 01:09:03.909 TRACE 2081 --- [nio-8080-exec-9] o.h.type.descriptor.sql.BasicBinder      : binding parameter [1] as [VARCHAR] - [hoon]\n    ```\n    \n\n해당 요청(회원가입)이 서버 로그에 select, insert 쿼리가 발생하는 것을 확인할 수 있습니다.\n\n이제 h2 콘솔에서 저장된 값을 확인하겠습니다.\n\n![Untitled](5.png)\n\n이제 h2 및 jpa 의 기본적인 설정이 끝났습니다.\n\n추가적인 사용법은 레퍼런스를 참고해주세요\n\n## Reference\n\n[https://dololak.tistory.com/285](https://dololak.tistory.com/285)\n\n[Spring 에서 h2 database 간단 사용법](https://oingdaddy.tistory.com/264) \n\n[https://www.icatpark.com/entry/JPA-기본-Annotation-정리](https://www.icatpark.com/entry/JPA-%EA%B8%B0%EB%B3%B8-Annotation-%EC%A0%95%EB%A6%AC)","excerpt":"JPA 및 H2 세팅 build.gradle 파일에 h2, jpa 의존성을 추가합니다. 그리고 application.properties 파일에 h2 와 jpa 에 대한 설정을 작성합니다.    : h2 console 페이지 활성화   : 데이터베이스…","fields":{"slug":"/spring-how-to-h2-jpa-setting/"},"frontmatter":{"date":"Jul 05, 2022","title":"[SpringBoot] 프로젝트에 H2 및 JPA 세팅법","tags":["SpringBoot"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"# 컨테이너 라이프사이클\n스프링 컨테이너는 초기화와 종료라는 라이프사이클을 갖는다.\n\n```java\n// 1. 컨테이너 초기화\nAnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationConfigApplicationContext(AppContext.class)\n\n// 2. 컨테이너에서 빈 객체를 구해서 사용\nGreeter g = ctx.getBean(\"greeter\", Greeter.class);\nString msg = g.greet(\"스프링\");\nSystem.out.println(mgs);\n\n// 3. 컨테이너 종료\nctx.close();\n```\n\n`AnnotationConfigApplicationContext`의 생성자를 이용해서 컨텍스트를 객체를 생성하는데 이 시점에 스프링 컨테이너를 초기화한다. 스프링 컨테이너는 설정 클래스에서 정보를 읽어와 알맞은 빈 객체를 생성하고 각 빈을 연결하는 작업을 수행한다.\n\n컨테이너 초기화가 완료되면 컨테이너를 사용할 수 있다. 컨테이너를 사용한다는 것은 `getBean()`과 같은 메서드를 이용해서 컨테이너에 보관된 빈 객체를 구한다는 것을 뜻함.\n\n컨테이너 사용이 끝나면 컨테이너를 종료한다. 컨테이너를 종료할 때 사용하는 메서드가 `close()`메서드이다. `close()`메서드는 `AbstractApplicationContext` 클래스에 정의되어 있다. 자바 설정을 사용하는 `AnnotationConfigApplicationContext` 클래스 모두 `AbstractApplicationContext` 클래스를 상속받고 있다.\n\n컨테이너를 초기화하고 종료할 땐 다음의 작업도 함께 수행한다.\n\n- 컨테이너 초기화 → 빈 객체의 생성, 의존 주입, 초기화\n- 컨테이너 종료 → 빈 객체의 소멸\n\n# 빈의 라이프사이클\n스프링 컨테이너는 빈 객체의 라이프사이클을 관리한다. 컨테이너가 괸리하는 빈 객체의 라이프사이클은 다음과 같다.\n\n- 빈 객체의 라이프사이클\n    1. 객체 생성\n    2. 의존 설정 → 의존 자동 주입을 통한 의존 설정 수행 \n    3. 초기화\n    4. 소멸\n\n스프링 컨테이너를 초기화할 때 스프링 컨테이너는 가장 먼저 빈 객체를 생성하고 의존을 설정한다. \n모든 의존 설정이 완료되면 빈 객체의 초기화를 수행한다. 빈 객체를 초기화하기 위해 스프링은 빈 객체의 지정된 메서드를 호출한다. 스프링 컨테이너를 종료하면 스프링 컨테이너는 빈 객체의 소멸을 처리한다. 이때에도 지정한 메서드를 호출한다.","excerpt":"컨테이너 라이프사이클 스프링 컨테이너는 초기화와 종료라는 라이프사이클을 갖는다. 의 생성자를 이용해서 컨텍스트를 객체를 생성하는데 이 시점에 스프링 컨테이너를 초기화한다. 스프링 컨테이너는 설정 클래스에서 정보를 읽어와 알맞은 빈 객체를 생성하고 각…","fields":{"slug":"/spring-bean-lifecycle/"},"frontmatter":{"date":"Jun 28, 2022","title":"[Spring] 스프링 컨테이너와 빈의 라이프사이클","tags":["Spring","스프링5입문시리즈"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"컴포넌트 스캔 기능을 사용해서 자동 빈 등록할 때에는 충돌에 주의해야한다.\n\n크게 두가지의 충돌이 발생할 수 있다.\n\n# 1. 빈 이름 충돌\n\n- 두개의 패키지에 같은 이름의 클래스가 존재할 때(모두 `@Component` 가 붙어있음)\n- `ConflictingBeanDefinitionException` 발생함\n    - 클래스를 빈으로 등록할 떄 사용한 빈 이름이 타입이 일치하지 않는(다른 타입) 클래스의 빈 이름과 충돌이 난다는 것\n\n컴포넌트 스캔 과정에서 쉽게 발생할 수 있다. 컴포넌트 스캔과정에서 서로 다른 타입인데 같은 빈 이름을 사용하는 경우가 있다면 **둘 중 하나에 명시적으로 빈 이름을 지정해서 이름 충돌을 피해야한다**.\n\n# 2. 수동 등록한 빈과 충돌\n## 수동 등록한 빈의 경우\n```java\n@Component\npublic class MemberDao {\n\t\t...\n}\n```\n\n- 해당 클래스는 컴포넌트 스캔 대상\n- 자동 등록된 빈의 이름은 “`memberDao`”\n\n다음과 같이 설정 클래스에 직접 `MemberDao` 클래스를 “`memberDao`”라는 이름의 빈으로 등록하면 어떻게 될까?\n\n```java\n@Configuration\n@ComponentScan(basePackages = {\"spring\"})\npublic class AppCtx {\n\t\t@Bean\n\t\tpublic MemberDao memberDao() {\n\t\t\tMemberDao memberDao = new MemberDao();\n\t\t\treturn memberDao;\n\t\t}\n}\n```\n\n스캔할 때 사용하는 빈 이름과 수동 등록한 빈 이름이 같은 경우,\n\n수동 등록한 빈이 우선된다. 즉 `MemberDao` 타입의 빈은 `AppCtx`에서 정의한 한개만 존재.\n\n## 다른 이름의 빈을 수동 등록할 경우\n다음과 같이 다른 이름을 사용한다면?\n\n```java\n@Configuration\n@ComponentScan(basePackages = {\"spring\"})\npublic class AppCtx {\n\t\t@Bean\n\t\tpublic MemberDao memberDao2() {\n\t\t\tMemberDao memberDao = new MemberDao();\n\t\t\treturn memberDao;\n\t\t}\n}\n```\n\n이 경우 스캔 등록한 “`memberDao`” 빈과 수동 등록한 “`memberDao2`” 빈이 모두 존재한다. `MemberDao` 타입의 빈이 두 개가 생성되므로 자동 주입(`@Autowired`)하는 코드는 `@Qualifier` 어노테이션을 사용해서 알맞은 빈을 선택해야한다.","excerpt":"컴포넌트 스캔 기능을 사용해서 자동 빈 등록할 때에는 충돌에 주의해야한다. 크게 두가지의 충돌이 발생할 수 있다. 1. 빈 이름 충돌 두개의 패키지에 같은 이름의 클래스가 존재할 때(모두  가 붙어있음)  발생함 클래스를 빈으로 등록할 떄 사용한 빈…","fields":{"slug":"/component-scan-conflict/"},"frontmatter":{"date":"Jun 27, 2022","title":"[Spring] 컴포넌트 스캔에 따른 충돌처리","tags":["Spring","스프링5입문시리즈"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n# @Component 어노테이션\n스프링이 검색해서 빈으로 등록할 수 있도록 할려면 클래스에 `@Component` 어노테이션을 붙여야 한다.\n`@Componet` 어노테이션은 해당 클래스를 스캔 대상으로 표시한다.\n\n```java\n**@Component**\npublic class MemberDao {\n\tprivate static long nextId = 0;\n\tprivate Map<String, Member> map = new HashMap<>();\n\t... 생략\n}\n```\n\n`@Component` 어노테이션에 값을 주었는지에 따라 빈으로 등록할 때 사용할 이름이 결정된다.\n- `value` 값을 주지 않았다면 : 클래스 이름의 첫 글자를 소문자로 바꾼 이름을 사용한다.\n    - ex) `MemberDao` 클래스라면,  “`memberDao`”를 빈 이름으로 사용하고\n        \n        `MemberRegisterService` 클래스라면 “`memberRegisterService`”를 빈 이름으로 사용한다.\n        \n# @ComponentScan 어노테이션\n\n`@Component` 어노테이션을 붙인 클래스를 스캔해서 스프링 빈으로 등록하려면 설정 클래스(`@Configuration`)에 `@ComponentScan` 어노테이션을 적용해야 한다.\n\n```java\n@Configuration\n@ComponentScan(basePackages = {\"com.example.sp5chap04.spring\"})\npublic class AppCtx {\n\n    @Bean\n    @Qualifier(\"printer\")\n    public MemberPrinter memberPrinter1() {\n        return new MemberPrinter();\n    }\n\n    @Bean\n    @Qualifier(\"summaryPrinter\")\n    public MemberPrinter memberPrinter2() {\n        return new MemberSummaryPrinter();\n    }\n\n    @Bean\n    public VersionPrinter versionPrinter() {\n        VersionPrinter versionPrinter = new VersionPrinter();\n        versionPrinter.setMajorVersion(5);\n        versionPrinter.setMinorVersion(0);\n        return versionPrinter;\n    }\n}\n```\n\n`@Component` 어노테이션을 붙인 클래스를 검색해서 `Bean`으로 등록해주기 때문에 설정 코드가 줄어들었다.\n\n- `basePackages` 속성 : 해당 속성값을 `{”com.example.sp5chap04.spring”}` 로 해주었다.\n    - 이 속성은 스캔 대상 패키지 목록을 지정한다.\n    - `“com.example.sp5chap04.spring”` 패키지와 그 하위 패키지에 속한 클래스를 스캔 대상으로 지정한다.\n\n## 스캔 대상에서 제외하거나 포함하기\n\n### excludeFilters 속성\n\n`excludeFilters` 속성을 사용하면 스캔할 때 특정 대상을 자동 등록 대상에서 제외할 수 있다.\n\n```java\n@Configuration\n**@ComponentScan(basePackages = {\"com.example.sp5chap04.spring\"}, excludeFilters = @ComponentScan.Filter(type = FilterType.REGEX, pattern = \"spring\\\\.*Dao\"))**\npublic class AppCtxWithExclude {\n\n    @Bean\n    public MemberDao memberDao() {\n        return new MemberDao();\n    }\n    \n    @Bean\n    @Qualifier(\"printer\")\n    public MemberPrinter memberPrinter1() {\n        return new MemberPrinter();\n    }\n\n    @Bean\n    @Qualifier(\"summaryPrinter\")\n    public MemberSummaryPrinter memberPrinter2() {\n        return new MemberSummaryPrinter();\n    }\n\n    @Bean\n    public VersionPrinter versionPrinter() {\n        VersionPrinter versionPrinter = new VersionPrinter();\n        versionPrinter.setMajorVersion(5);\n        versionPrinter.setMinorVersion(0);\n        return versionPrinter;\n    }\n\n}\n```\n\n`@Filter` 어노테이션의 `type` 속성 값으로  `FilterType.REGEX`를 주었다. 이는 정규표현식을 사용해서 제외 대상을 지정한다는 것을 의미한다.\n\n`pattern` 속성은 `FilterType`에 적용할 값을 설정한다. `“spring.”`으로 시작하고 `Dao`로 끝나는 정규표현식을 지정했으므로 `spring.MemberDao` 클래스를 컴포넌트 스캔 대상에서 제외한다.\n\n### FilterType.ASPECTJ\n\n```java\n@ComponentScan(basePackages = {\"com.example.sp5chap04.spring\"}, excludeFilters = @ComponentScan.Filter(type = FilterType.ASPECTJ, pattern = \"spring.*Dao\"))\n```\n\n`FilterType.ASPECTJ`를 필터타입으로 설정할 수 있다. 이 타입을 사용하면 정규표현식 대신 `AspectJ` 패턴을 사용해서 대상을 지정한다.\n\n- `AspectJ` 패턴이 동작하려면 의존 대상에 `aspectjweaver` 모듈을 추가해야한다.\n    \n    ```java\n    \t<dependency>\n    \t\t\t<groupId>org.aspectj</groupId>\n    \t\t\t<artifactId>aspectjweaver</artifactId>\n    \t\t\t<version>1.8.13</version>\n    \t\t</dependency>\n    ```\n    \n\n### FilterType.ANNOTATION\n\n특정 어노테이션을 붙인 타입을 컴포넌트 대상에서 제외할 수도 있다.\n\n```java\n@Retention(RUNTIME)\n@Target(TYPE)\npublic @interface NoProduct {\n}\n\n@Retention(RUNTIME)\n@Target(TYPE)\npublic @interface ManualBean {\n}\n```\n\n이 두 어노테이션을 붙인 클래스를 컴포넌트 스캔 대상에서 제외하려면 다음과 같이 `excludeFilters` 속성을 설정한다.\n\n```java\n@Configuration\n@ComponentScan(basePackages = {\"com.example.sp5chap04.spring\"}, excludeFilters = @ComponentScan.Filter(type = FilterType.ANNOTATION, classes = {NoProduct.class, ManualBean.class ))\npublic class AppCtxWithExclude {\n\n}\n```\n\n`type` 속성 값으로 `FilterType.ANNOTATION`을 사용하면 `classes` 속성에 필터로 사용할 어노테이션 타입을 값으로 준다.\n\n```java\n@ManualBean\n@Component\npublic class MemberDao {\n\t...\n}\n```\n\n`@ManualBean` 어노테이션을 제외 대상에 추가했으므로 `MemberDao` 클래스를 컴포넌트 스캔 대상에서 제외한다.\n\n## FilterType.ASSIGNABLE_TYPE\n\n특정 타입이나 그 하위 타입을 컴포넌트 스캔 대상에서 제외하려면 `ASSIGNABLE_TYPE`을 `FilterType`으로 사용한다.\n\n```java\n@Configuration\n@ComponentScan(basePackages = {\"com.example.sp5chap04.spring\"}, excludeFilters = @ComponentScan.Filter(type = FilterType.ASSIGNABLE_TYPE, classes = MemberDao.class ))\npublic class AppCtxWithExclude {\n```\n\n`classes` 속성에는 제외할 타입 목록을 지정한다. 제외할 타입이 한 개 이상이면 배열 표기를 사용할 수 있다.\n\n## 설정할 필터가 두개 이상\n\n`@ComponentScan`의 `excludeFilters` 속성에 배열을 사용해서 `@Filter` 목록을 전달하면 된다.\n\n```java\n@Configuration\n@CompoenentScan(basePackages = {\"com.example.sp5chap04.spring\"}, excludeFilters = {\n\t@Filter(type = FilterType.ANNOTATION, classes = ManualBean.class), \n\t@Filter(type = FilterType.REGEX, pattern = \"spring2\\\\.*\")\n})\n```","excerpt":"@Component 어노테이션 스프링이 검색해서 빈으로 등록할 수 있도록 할려면 클래스에  어노테이션을 붙여야 한다.\n 어노테이션은 해당 클래스를 스캔 대상으로 표시한다.  어노테이션에 값을 주었는지에 따라 빈으로 등록할 때 사용할 이름이 결정된다.…","fields":{"slug":"/component_scan/"},"frontmatter":{"date":"Jun 24, 2022","title":"[Spring] @Component, @ComponentScan 으로 스캔 대상 지정","tags":["Spring","스프링5입문시리즈"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"# @Configuration  클래스에서 의존 주입(명시적 주입)을 했는데 자동 주입 대상이면 어떻게 될까?\n\n```java\npublic class MemberInfoPrinter {\n\t...\n\t\n\t**@Autowired // 자동 주입**\n\t@Qualifier(\"printer\")\n\tpublic void setPrinter(MemberPrinter printer){\n\t\tthis.printer = printer;\n\t}\n}\n```\n\nMemberInfoPrinter 클래스의 setPrinter 메소드는 위와 같이 @Autowired 어노테이션이 붙어 있다.\n\n```java\n@Configuration\npublic class AppCtx {\n\t...\n\t\n\t@Bean\n\t@Qualifier(\"printer\")\n\tpublic MemberPrinter memberPrinter1() {\n\t\treturn new MemberPrinter();\n\t}\n\n\t@Bean\n\t@Qualifier(\"summaryPrinter\")\n\tpublic MemberSummaryPrinter memberPrinter2() {\n\t\treturn new MemberSummaryPrinter();\n\t}\n\t\n\t@Bean\n\tpublic MemberList listPrinter() {\n\t\treturn new MemberListPrinter();\n\t}\n\n\t@Bean\n\tpublic MemberInfoPrinter infoPrinter() {\n\t\tMemberInfoPrinter infoPrinter = new MemberInfoPrinter();\n\t\t**infoPrinter.setPrinter(memberPrinter2()); // 세터로 의존 주입**\n\t\treturn infoPrinter;\n\t}\n}\n```\n\n`infoPrinter()` 메소드는 `MemberInfoPrinter` 클래스의 `setPrinter()` 메소드를 호출해서 `memberPrinter2` `Bean`(**이메일과 이름만 출력한다**)을 주입한다.\n\n이 상태에서 Spring 애플리케이션을 실행하고 info 명령어를 실행해보자.\n\n그러면 과연 info 명령어를 실행하였을 때 이메일과 이름만을 출력할까?\n\n### 출력 결과\n\n```java\n명령어를 입력하세요:\nnew a@b.c ABC abc abc\n등록했습니다.\n\n명령어를 입력하세요:\ninfo a@b.c\n**[null] 회원 정보: 아이디=1, 이메일=a@b.c, 이름=ABC, 등록일=2022-06-23**\n```\n\n출력 결과를 보면 회원의 전체 정보를 보여준다. 이는 `memberPrinter2` `Bean`(`MemberSummaryPrinter` 타입 객체)이 아닌 `memberPrinter1` `Bean`을 사용해서 회원 정보를 출력한 것을 의미한다.\n\n즉 설정 클래스(@Configuration)에서 세터 메서드를 통해 의존을 주입해도 해당 세터 메서드에 @Autowired 어노테이션이 붙어있으면 자동 주입을 통해 일치하는 빈을 주입한다.\n\n```java\n\t**@Autowired // 자동 주입**\n\t@Qualifier(\"printer\")\n\tpublic void setPrinter(MemberPrinter printer){ \n\t// SummaryPrinter 타입 Bean이 아닌 MemberPrinter를 주입받는다.\n\t\tthis.printer = printer;\n\t}\n\n```\n\n**따라서 @Autowired 어노테이션을 사용했다면 설정 클래스에서 객체를 주입하기 보다는 스프링이 제공하는 자동 주입을 사용하는 편이 낫다.**\n\n<aside>\n✅ 자동 주입을 하는 코드와 수동으로 주입하는 코드가 섞여 있으면 주입을 제대로 하지 않아서 NPE 예외가 발생했을 때 원인을 찾는데 시간이 걸릴 수 있다. 의존 자동 주입(Autowired)를 일관되게 사용해야 이런 문제가 줄어든다. @Autowired를 사용하고 있다면 일부 자동 주입을 적용하기 어려운 코드를 제외한 나머지 코드는 @Autowird를 사용하자.\n\n</aside>","excerpt":"@Configuration  클래스에서 의존 주입(명시적 주입)을 했는데 자동 주입 대상이면 어떻게 될까? MemberInfoPrinter 클래스의 setPrinter 메소드는 위와 같이 @Autowired 어노테이션이 붙어 있다.  메소드는  클래…","fields":{"slug":"/autowired_and_manual_injection/"},"frontmatter":{"date":"Jun 23, 2022","title":"[Spring] @Autowird 자동 의존 주입과 명시적 의존 주입 간의 관계","tags":["Spring","스프링5입문시리즈"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"# @Autowired 어노테이션을 이용한 의존 자동 주입\n## 자동 주입 기능을 사용하지 않은 코드 (직접 의존 주입)\n````java\n    @Bean\n    public MemberDao memberDao(){\n        return new MemberDao();\n    }\n    \n    @Bean\n    public ChangePasswordService changePwdSvc() {\n        ChangePasswordService pwdSvc = new ChangePasswordService();\n        **pwdSvc.setMemberDao(memberDao());**\n        return pwdSvc;\n    }\n````\n위 코드에서는 직접 세터 메소드를 통해 의존 주입을 하고있다 <br/>\n자동 주입 기능을 사용하면 스프링이 알아서 의존 객체를 찾아서 주입한다.\n\n```java\n    @Bean\n    public MemberDao memberDao(){\n        return new MemberDao();\n    }\n    \n    @Bean\n    public ChangePasswordService changePwdSvc() {\n        ChangePasswordService pwdSvc = new ChangePasswordService();\n        return pwdSvc;\n    }\n```\n\n자동 주입 기능을 사용하면, 위 코드 처럼 의존 객체를 명시하지 않아도,<br/>\n스프링이 필요한 의존 Bean 객체를 찾아서 주입해준다.\n\n# 자동 주입 기능 사용\n매우 간단하다. 의존을 주입할 대상에 @Autowired 어노테이션을 붙이기만 하면 된다.\n## @Autowired \n\nBean 객체의 메소드에 @Autowired 어노테이션을 붙이면 스프링은 해당 메서드를 호출한다.\n</br> 이때 메서드 파라미터 타입에 해당하는 Bean 객체를 찾아 인자로 주입한다.\n\n```java\n@Bean\npublic MemberDao memberDao(){\n        return new MemberDao();\n        }\n\n\n// 1. 필드 자동 주입\n@Autowired\nprivate MemberDao mebmerDao;\n\n// 2. 메서드 자동 주입\n@Autowired\npublic void setMemberDao(MemberDao memberDao) {\n    this.memberDao = memberDao;\n}\n```\n\n@Autowired 어노테이션을 필드나, 세터 메서드에 붙이면 \n</br> 스프링은 타입이 일치하는 Bean 객체를 찾아서 주입한다.\n\n## 자동 주입 예외 케이스\n### 주입해야할 빈 객체가 없다면?\n```\nError creating bean with name 'memberRegSvc': Unsatisfied dependency expressed through field 'memberDao'; \nnested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.example.sp5chap04.spring.MemberDao' available: expected at least 1 bean which qualifies as autowire candidate\n```\nmemberRegSvc Bean 객체가 생성하는 도중, 의존하는 memberDao 객체를 스프링이 찾이를 못해 `NoSuchBeanDefinitionException` \n</br> 예외가 발생했다.\n\n### 주입해야할 빈이 두개 이상이면?\n```java\n    // MemberPrinter 를 주입받는 세터 메서드\n\t@Autowired\n    public void setMemberPrinter(MemberPrinter printer) {\n        this.printer = printer;\n    }\n    \n    // 동일한 Bean 객체를 생성한다\n    @Bean\n    public MemberPrinter memberPrinter1() {\n        return new MemberPrinter();\n    }\n\n    @Bean\n    public MemberPrinter memberPrinter2() {\n        return new MemberPrinter();\n    }\n```\n해당 코드 처럼, MemberPrinter 타입의 Bean 객체가 2개 정도 만들어진 상태에서는 어떻게 될까?\n\n```\nspringframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type 'com.example.sp5chap04.spring.MemberPrinter' available: expected single matching bean but found 2: memberPrinter1,memberPrinter2\n```\n\nMemberPrinter 타입의 빈이 여러개 있어서, 한정할 수 없는데, </br>\n해당 타입 빈이 한개가 아니라, 이름이 memberPrinter1, memberPrinter2 인 두개의 빈을 </br>\n발견 했다는 사실을 알려준다. </br>\n\n## @Qualifier 어노테이션\n자동 주입 가능한 빈이 두 개 이상이면 자동 주입할 빈을 지정하는 방법이 필요할 때 시용한다. <br/>\n@Qualifier 어노테이션을 사용하면 자동 주입 대상 빈을 한정할 수 있다.\n\n```java\n@Configuration\npublic class AppCtx {\n    \n    ...\n    \n    @Bean\n    **@Qualifier(\"printer\")**\n    public MemberPrinter memberPrinter1(){\n        return new MemberPrinter();\n    }\n\n    @Bean\n    public MemberPrinter memberPrinter2() {\n        return new MemberPrinter();\n    }\n}\n```\n위 코드에서 memberPrinter1() 메소드에 \"printer\" 값을 갖는 @Qualifier 어노테이션을 붙였다 <br/>\n이 설정은 해당 Bean의 한정 값으로 \"printer\"를 지정한다.\n\n이렇게 지정한 한정 값은 @Autowired 어노테이션에서 자동 주입할 빈을 한정할 때 사용한다.\n```java\npublic class MemberListPrinter{\n    \n    ...\n    \n\t@Autowired\n\t@Qualifier(\"printer\")\n\tpublic void setMemberPrinter(MemberPrinter printer) {\n\t\tthis.printer = printer;\n\t}\n}\n```\nsetMemberPrinter() 메소드에 @Autowired 어노테이션을 붙였으므로 MemberPrinter 타입의 빈을 자동 주입한다. <br/>\n이떄 @Qualifier 어노테이션 값이 \"printer\" 이므로 한정 값이 \"printer\"인 Bean을 의존 주입 후보로 사용한다.\n\n@Autowired 어노테이션을 필드, 메서드에 모두 적용할 수 있으므로 @Qualifier 어노테이션도 필드, 메소드 모두 적용할 수 있다.","excerpt":"@Autowired 어노테이션을 이용한 의존 자동 주입 자동 주입 기능을 사용하지 않은 코드 (직접 의존 주입) 위 코드에서는 직접 세터 메소드를 통해 의존 주입을 하고있다 \n자동 주입 기능을 사용하면 스프링이 알아서 의존 객체를 찾아서 주입한다. …","fields":{"slug":"/spring_autowired/"},"frontmatter":{"date":"Jun 23, 2022","title":"[Spring] @Autowird 어노테이션을 이용한 의존 자동 주입과 @Qualifier 빈 한정자","tags":["Spring","스프링5입문시리즈"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n# 주입 대상 객체를 모두 빈 객체로 설정해야 하나?\n주입할 객체가 꼭 스프링 빈이어야 할 필요는 없다.\n\n```java\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\npublic class AppCtxNoMemberPrinterBean {\n      private MemberPrinter printer = new MemberPrinter();\n          ...\n}\n```\n이 설정 코드는 `MemberPrinter`를 빈으로 등록하지 않았다.\n이렇게 해도 정상적으로 작동한다.\n\n객체를 스프링 빈으로 등록할 때와, 하지 않을 떄의 차이점\n- 스프링 컨테이너가 객체를 관리하는지 여부\n- 위 코드와 같이 설정하면 ``MemberPrinter``를 빈으로 등록하지 않으므로 스프링 컨테이너에서 `MemberPrinter`를 구할 수 없다.\n\n```java\n// MemberPrinter를 빈으로 등록하지 않았으므로\n// 아래 코드는 Exception이 발생한다.\nMemberPrinter printer = ctx.getBean(MemberPrinter.class);\n```\n스프링 컨테이너는 자동 주입, 라이프사이클 관리 등 단순 객체 생성 외에 객체 관리를\n\n위해 다양한 기능을 제공하는데  빈으로 등록한 객체에만 적용한다\n\n### 결론\n스프링 컨테이너가 제공하는 관리 기능이 필요없고 \n\ngetBean() 메소드로 구할 필요가 없다면 빈 객체로 꼭 등록해야 하는 것을 아니다\n\n최근에는 의존 자동 주입 기능을 프로젝트 전반에 걸쳐 사용하는 추세이기 때문에\n\n의존 주입 대상은 스프링 빈으로 등록하는 것이 보통이다.# 주입 대상 객체를 모두 빈 객체로 설정해야 하나?\n주입할 객체가 꼭 스프링 빈이어야 할 필요는 없다.","excerpt":"주입 대상 객체를 모두 빈 객체로 설정해야 하나? 주입할 객체가 꼭 스프링 빈이어야 할 필요는 없다. 이 설정 코드는 를 빈으로 등록하지 않았다.\n이렇게 해도 정상적으로 작동한다. 객체를 스프링 빈으로 등록할 때와, 하지 않을 떄의 차이점 스프링 컨…","fields":{"slug":"/injection_object_is_bean/"},"frontmatter":{"date":"Mar 21, 2022","title":"[Spring] 주입 대상 객체를 모두 빈으로 해야하나?","tags":["Spring","스프링5입문시리즈"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n# Spring Cloud - Config Server/Client\n\n![spring cloud config server 구성 아키텍쳐](1.png)\n\nspring cloud config server 구성 아키텍쳐\n\n- Spring Cloud Config Server 의 저장소는\n  - git, vault, aws s3, redis, jdbc 등 과 같은 저장소를 사용할 수 있습니다.\n\n# 스프링 클라우드 Config\n\n- 스프링 클라우드 구성 서버는 애플리케이션의 모든 마이크로서비스가 구성에 의존할 수 있는 서버를 사용해서중앙 집중식 구성을 제공할 수 있습니다.\n\n### 중앙 집중식 구성의 장점 (= 스프링 클라우드 구성 서버의 장점 )\n\n1. 구성이 더 이상 애플리케이션 코드에 패키징되어 배포되지 않는다. 따라서 애플리케이션을 다시 빌드하거나 배포하지 않고 구성을 변경하거나 원래 값으로 환원할 수 있다.\n2. 공통적인 구성을 공유하는 마이크로서비스가 자신의 속성 설정으로 유지/관리하지않고도 동일한 속성들을 공유할 수 있다. 그리고 속성 변경이 필요하면 한 곳에서 한번만 변경해도 모든 마이크로서비스에 적용할 수 있다.\n3. 보안에 민감한 구성 속성은 애플리케이션 코드와는 별도로 암호화하고 유지/관리할 수 있다. 그리고 복호화된 속성 값을 언제든지 애플리케이션에서 사용할 수 있으므로 복호화를 하는 코드가 애플리케이션에 없어도 된다.\n\n### 구성서버 - 자동 속성 갱신\n\n![spring actuator 를 통한 속성 자동 리프레시](2.png)\n\nspring actuator 를 통한 속성 자동 리프레시\n\n구성 서버를 중앙 속성 서버로 두고, 스프링 Actuator 와, cloud bus, RabbitMQ 를 통해\n\n해당 이미지 처럼 개발자가 속성을 새롭게 수정하였으면, WebHook (/actuator/bus-refresh) 경로로 요청을 보내 변경된 속성을 갱신하고, 운영중인 서버로 부터 설정을 업데이트 하라고 요청을 할 수 있습니다.\n\n## 구성 서버\n\nconfig server 를 구성서버라고 부르겠습니다.\n\n스프링 구성 서버를 제작하고, 설정을 받는 것을 해보겠습니다\n\n### 구성 서버 설정\n- build.gradle\n```groovy\n    implementation 'org.springframework.boot:spring-boot-starter-web'\n    implementation 'org.springframework.cloud:spring-cloud-config-server:3.1.0'\n\n    implementation 'org.springframework.vault:spring-vault-core:2.3.2'\n\n    implementation 'org.springframework.boot:spring-boot-starter-actuator:2.6.3'\n```\n해당 의존성을 추가합나디.\n\n- Main 클래스\n\n```java\n@SpringBootApplication\n**@EnableConfigServer**\npublic class VaultdemoApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(VaultdemoApplication.class, args);\n    }\n\n}\n```\n\n**EnableConfigServer** 어노테이션을 달아서, 구성서버 자동 설정합니다.\n\n- application.yml\n\n```yaml\nserver:\n  port: 8888\n\nspring:\n  profiles:\n    active:\n      - native\n      - vault\n\n  cloud:\n    config:\n      server:\n        native:\n          search-locations: file:./config\n        vault:\n          kv-version: 1\n          authentication: token\n          token: \"vault token\"\n          host: localhost\n          scheme: http\n          port: 8200\n```\n\n위 설정들은 구성 서버 자체 구성에 필요한 속성들입니다.\n\n구성 서버가 클라이언트(개발 서버[config가 필요한 곳])에 제공하는 config 는 git, vault, native 등(서버 파일 시스템)의 repository (저장소)에서 가져옵니다.\n\n현재 서버의 속성을 보시면은 구성을 가져올 저장소가 두 곳 인것을 볼 수 있습니다.\n\n- native : 프로젝트 경로의 config 디렉터리 내부 파일(설정 파일들이 위치)\n- vault : vault 의 secret 경로\n  - 클라이언트에서 vault의 token 을 발급 하지 않고 속성만 받을 수 있게 구성 서버에서 token을 지정하였습니다.\n\n### 구성 서버 native 속성 파일\n\n- /config/test.yml\n\n```bash\nmessage:\n  hello: \"hi\"\n```\n\nnative 저장소에 있는 설정 파일입니다.\n\n### 구성 서버 vault secret\n\n```bash\n❯ curl -X GET http://localhost:8200/v1/test-app/dev -H \"X-Vault-Token: token값\" | jq\n\n{\n  \"request_id\": \"0f62463e-fec4-7c60-7103-d6baf2fc04c7\",\n  \"lease_id\": \"\",\n  \"renewable\": false,\n  \"lease_duration\": 3153600000,\n  \"data\": {\n    **\"hello\": \"world\",\n    \"this\": \"is\"**\n  },\n  \"wrap_info\": null,\n  \"warnings\": null,\n  \"auth\": null\n}\n```\n\n- test-app/dev [key , value 저장소]\n  - hello : world\n  - this : is\n\n### 구성 서버 테스트 하기\n\n![Untitled](3.png)\n\n- localhost:8888 : 구성 서버의 호스트 이름과 포트\n- application : 애플리케이션 이름(spring.application.name)\n- default : 활성화된 스프링 프로파일(E.g. production) (14.2.2)\n- master : Git 라벨/분기(생략 가능, master가 기본값)\n\n- test 속성 받기\n  ```bash\n  ❯ curl -X GET http://localhost:8888/test/default | jq\n    \"name\": \"test\",\n    \"profiles\": [\n      \"default\"\n    ],\n    \"label\": null,\n    \"version\": null,\n    \"state\": null,\n    \"propertySources\": [\n      {\n        **\"name\": \"file:config/test.yml\",**\n        \"source\": {\n          **\"message.hello\": \"hi\"**\n        }\n      }\n    ]\n  }\n  ```\n  [localhost:8888](http://localhost:8888)/test/default 로 요청을 보냈습니다.\n  test.yml 속성을 받아온것을 볼 수 있습니다.\n\n# 레퍼런스\n\n[https://cloud.spring.io/spring-cloud-config/reference/html/#\\_environment_repository](https://cloud.spring.io/spring-cloud-config/reference/html/#_environment_repository)\n\n[https://lejewk.github.io/vault-get-started/](https://lejewk.github.io/vault-get-started/)\n\n[https://www.vaultproject.io/docs/commands](https://www.vaultproject.io/docs/commands)\n\n[https://wonit.tistory.com/502](https://wonit.tistory.com/502)\n\n[https://velog.io/@ha0kim/스프링-인-액션-14.리액티브-데이터-퍼시스턴스](https://velog.io/@ha0kim/%EC%8A%A4%ED%94%84%EB%A7%81-%EC%9D%B8-%EC%95%A1%EC%85%98-14.%EB%A6%AC%EC%95%A1%ED%8B%B0%EB%B8%8C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%8D%BC%EC%8B%9C%EC%8A%A4%ED%84%B4%EC%8A%A4)\n","excerpt":"Spring Cloud - Config Server/Client  spring cloud config server 구성 아키텍쳐 Spring Cloud Config Server 의 저장소는 git, vault, aws s3, redis, jdbc 등…","fields":{"slug":"/spring-cloud-config/"},"frontmatter":{"date":"Mar 07, 2022","title":"Spring Cloud Config Server/Client","tags":["SpringBoot","Cloud","Config"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n![토이프로젝트에서 WebHook 알림 발생](1.png)\n\n이 글에서는 스프링부트에서 디스코드 WebHook을 사용하여, 어떠한 이벤트 요청이 오면, 알림을 알려주는 것을 해보겠습니다.\n\n# WebHook 이란?\n\n![Untitled](2.png)\n\nWebHook은 웹페이지 또는 웹앱에서 발생하는 특정 행동(이벤트)들을 커스텀 Callback 형식으로 반환해주는 방법입니다.\n\n일반적인 API(Polling)는 클라이언트가 서버를 호출하는 방식인데, WebHook의 경우 서버에서 특정 이벤트가 발생했을 때 클라이언트를 호출하는 방식이며 역방향 API라고도 부르기합니다.\n\n따라서 서버에서 이벤트가 발생했을 때 클라이언트의 어느 URL로 데이터를 보내는 것을 (Callback URL) 구현하는 것을 생각하신다면 WebHook을 사용하시면 좋을 것 같습니다.\n\n# 디스코드 채널 WebHook 설정\n\n![Untitled](3.png)\n\n특정 채널에 웹훅을 만들기 위해서는, 채널 편집에 들어가서, 연동을 들어가시고, 웹후크를 생성해줍니다.\n\n아바타 사진과, 이름 등과 같은 설정을 하시고 **웹후크 URL 복사**를 눌러줍니다.\n\n해당 웹후크 URL 로 서버에서 어떤 데이터를 담아 요청을 보내면 되겠습니다.\n\n# WebHook 어떻게 사용하는가?\n\n[디스코드 공식문서 Create Message](https://discord.com/developers/docs/resources/channel#create-message) 를 보시면 Json 형식의 데이터로 POST 요청을 웹후크 URL을 보내면 됩니다.\n\n```json\n{\n  \"content\": \"Hello, World!\",\n  \"tts\": false,\n  \"embeds\": [{\n    \"title\": \"Hello, Embed!\",\n    \"description\": \"This is an embedded message.\"\n  }]\n}\n```\n\n공식 문서의 예제 코드에서는 위 Json형식의 데이터를 보내게 되는데요 한번 API를 요청을 보내보면\n\n![Untitled](4.png)\n\n이런식으로 오는것을 볼 수 있습니다. 자세한 사용은 공식문서를 참고하셔서 어떤 데이터를 어떻게 보낼지 찾아보시면 되겠습니다.\n\n# 스프링부트에서 WebHook 메시지 보내기\n\n서버에서 어떠한 요청(이벤트)이 발생하게 되면은, 디스코드로 메세지를 보내는 것을 구현하겠습니다.\n\n## 프로젝트 패키지 구성\n\n- controller\n    - `EventController`\n- discord\n    - config\n        - `BotConfiguration`\n    - service\n        - `WebHookService`\n\n## application-discord.yml\n\n```java\ndiscord:\n  webhookURL: \"웹후크URL\"\n```\n\n웹후크 URL을 지정합니다\n\n## BotConfiguration 클래스\n\n```java\n@Configuration\npublic class BotConfiguration {\n\n    @Bean\n    public WebHookService webHookService(){\n        return new WebHookService();\n    }\n}\n```\n\nConfiguration을 통해서 WebHookService Bean을 생성하겠습니다.\n\n## WebHookService 클래스\n\n```java\npublic class WebHookService {\n\n    @Value(\"${discord.webhookURL}\")\n    private  String url;\n\n    public void callEvent(){\n        JSONObject data = new JSONObject();\n\n        data.put(\"content\", \"[알림] 이벤트가 발생하였습니다\");\n\n        send(data);\n    }\n\n    private void send(JSONObject object){\n        HttpHeaders headers = new HttpHeaders();\n        headers.setContentType(MediaType.APPLICATION_JSON);\n\n        RestTemplate restTemplate = new RestTemplate();\n        HttpEntity<String> entity = new HttpEntity<>(object.toString(), headers);\n        restTemplate.postForObject(url, entity, String.class);\n    }\n}\n```\n\n서비스 클래스에서 `callEvent` 메소드가 실행되면 `JSON` 객체를 생성하고, `content` Key에 `value`로 알림을 보낼 메세지 내용을 작성했습니다.\n\n그리고 `send` 메소드에 파라미터로 `JSON` 객체를 담고 해당 메소드를 실행합니다.\n\n`send` 메소드에서는 `RestTemplate` 스프링 객체를 통해서,Json 객체를 HTTP Body에 담고 `POST` 요청을 웹후크 URL로 보내게됩니다.\n\n## EventController 클래스\n\n```java\n@Controller\n@RequiredArgsConstructor\n@RequestMapping(\"/api/event\")\npublic class EventController {\n\n    private final WebHookService webHookService;\n    \n    @PostMapping(\"\")\n    public String postEvent(){\n\t\t\t\t// 이벤트 처리 ...\n        webHookService.callEvent();\n        return \"이벤트 발생!\";\n    }\n```\n\n컨트롤러에서는 `/api/event` Post 요청이 들어오면 orderEvent 그 요청을 처리하게 되는데요. \n\n내부에선 이벤트 비즈니스 로직을 수행하고, 웹후크를 통해서 알림을 보냅니다.\n\n## 서버 구동\n\n이젠 스프링부트 서버를 구동하여, API를 요청해서 알림 메세지를 받아보겠습니다.\n\n![Untitled](5.png)\n\n```java\n❯ curl -X POST \"http://localhost:8080/api/event\"\n```\n\n해당 URL 로 POST 요청을 보내게되면은, 디스코드에 알림이 발생하는 것을 볼 수 있습니다!\n\n이런식으로 디스코드 WebHook을 사용하시면되고, 메세지를 커스텀하여, 웹후크 메세지를 보내시면 되겠습니다.\n\n# 레퍼런스\n\n[https://discord.com/developers/docs/resources/channel#create-message](https://discord.com/developers/docs/resources/channel#create-message)\n\n[https://leffept.tistory.com/329](https://leffept.tistory.com/329)\n","excerpt":"이 글에서는 스프링부트에서 디스코드 WebHook을 사용하여, 어떠한 이벤트 요청이 오면, 알림을 알려주는 것을 해보겠습니다. WebHook 이란?  WebHook은 웹페이지 또는 웹앱에서 발생하는 특정 행동(이벤트)들을 커스텀 Callback 형식…","fields":{"slug":"/springboot-disord-webhook/"},"frontmatter":{"date":"Feb 19, 2022","title":"[SpringBoot] 디스코드 WebHook으로 알림 보내기","tags":["SpringBoot","Discord","WebHook"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"![Untitled](1.png)\n\n쇼핑물에서 이용자의 구매이력을 조회 시, N+1 문제가 발생해 성능저하가 일어나는 상황에서\n간단한 해결법으로 성능 향상을 이루는 법을 알아보겠습니다.\n\n## N+1 문제란?\n\n연관 관계에서 발생하는 이슈로 연관 관계가 설정된 엔티티를 조회할 경우에 조회된 데이터 갯수(n) 만큼 연관관계의 조회 쿼리가 추가로 발생하여 데이터를 읽어오게 되는 문제\n\n## 엔티티 연관관계\n\n- 주문 엔티티\n    \n    ```java\n    @Entity\n    @Table(name = \"orders\")\n    @Getter\n    @Setter\n    public class Order {\n    \n        @Id\n        @GeneratedValue(strategy = GenerationType.IDENTITY)\n        @Column(name = \"order_id\")\n        private Long id;\n    \n        @ManyToOne(fetch = FetchType.LAZY)\n        @JoinColumn(name = \"member_id\")\n        private Member member;\n    \n        private LocalDateTime orderDate;\n    \n        @Enumerated(EnumType.STRING)\n        private OrderStatus orderStatus;\n    \n        @OneToMany(mappedBy = \"order\", cascade = CascadeType.ALL\n                , orphanRemoval = true, fetch = FetchType.LAZY) \n        private List<OrderItem> orderItems = new ArrayList<>();\n    ```\n    \n    한 주문(`order`)에는 사용자가 주문한 여러개의 상품들(`orderItems`)에 대해 `@OneToMany` 연관관계를 적용했습니다.\n    \n- 주문 상품 엔티티\n    \n    ```java\n    @Entity\n    @Getter\n    @Setter\n    public class OrderItem  {\n    \n        @Id\n        @GeneratedValue(strategy = GenerationType.IDENTITY)\n        @Column(name = \"order_item_id\")\n        private Long id;\n    \n        @ManyToOne(fetch = FetchType.LAZY)\n        @JoinColumn(name = \"item_id\")\n        private Item item;\n    \n        @ManyToOne(fetch = FetchType.LAZY)\n        @JoinColumn(name = \"order_id\")\n        private Order order;\n    \n        private int orderPrice; // 주문가\n        private int count;      // 수량\n    ```\n    \n    주문 상품(`orderItem`)은 하나의 주문(`order`)에 대해 종속(`@ManyToOne`)되있습니다.\n    \n    그리고 상품들에 대한 정보를 가지고있습니다 (여러개의 상품들(주문) → 하나의 상품(진열))\n    \n\n간단하게 정리하자면 \n\n- 주문에는 여러개의 주문 상품들이 들어있습니다.\n- 주문 상품은 하나의 주문에 종속되어 있습니다.\n- 주문 상품은 하나의 상품에 종속되어 있습니다 (실질적인 상품에 대한 정보들)\n- 1 주문 → N 주문 상품\n\n## getOrderList 메소드\n\nN+1 문제가 일어나게 되는 원인인 사용자의 주문이력을 반환하는 메소드입니다.\n\n```java\npublic Page<OrderHistoryDto> getOrderList(String email, Pageable pageable) {\n        List<Order> orders = orderRepository.findOrders(email, pageable);\n        Long totalCount = orderRepository.countOrder(email);\n\n        List<OrderHistoryDto> orderHistoryDtos = new ArrayList<>();\n\n        for (Order order : orders) {\n            OrderHistoryDto orderHistoryDto = OrderHistoryDto.of(order);\n            List<OrderItem> orderItems = order.getOrderItems(); // 문제가 일어나는 부분\n            for (OrderItem orderItem : orderItems) {\n                ItemImg itemImg = itemImgRepository.findByItemIdAndRepImgYn(orderItem.getItem().getId(), \"Y\");\n                OrderItemDto orderItemDto = OrderItemDto.of(orderItem, itemImg.getImgUrl());\n                orderHistoryDto.addOrderItemDto(orderItemDto);\n            }\n\n            orderHistoryDtos.add(orderHistoryDto);\n        }\n        return new PageImpl<OrderHistoryDto>(orderHistoryDtos, pageable, totalCount);\n    }\n```\n\n해당 로직을 보시면은 반복문을 순회하면서 `order.getOrderItems()`를 호출할 때마다 조회 쿼리문이 추가적으로 실행되고 있습니다.\n\n`orders` 리스트(사용자의 주문건들)의 사이즈 만큼 쿼리문이 실행됩니다. 만약 `orders`의 사이즈가 100이었다면 100번의 쿼리문이 더 실행되는 것입니다. 현재는 `order_id` 에 하나의 주문 번호가 조건으로 설정되는 것을 볼수있습니다.\n\n```java\nHibernate: \n    select\n        orderitems0_.order_id as order_id9_5_0_,\n        orderitems0_.order_item_id as order_it1_5_0_,\n        orderitems0_.order_item_id as order_it1_5_1_,\n        orderitems0_.create_time as create_t2_5_1_,\n        orderitems0_.update_time as update_t3_5_1_,\n        orderitems0_.created_by as created_4_5_1_,\n        orderitems0_.modified_by as modified5_5_1_,\n        orderitems0_.count as count6_5_1_,\n        orderitems0_.item_id as item_id8_5_1_,\n        orderitems0_.order_id as order_id9_5_1_,\n        orderitems0_.order_price as order_pr7_5_1_ \n    from\n        order_item orderitems0_ \n    where   // 문제의 부분\n        orderitems0_.order_id=?\n```\n\n만약 `orders`의 주문 아이디를 `“where order_id in (id1, id2, id3, ... )”` 이런식으로 `in` 쿼리로 한번에 조회할 수 있다면 100개가 실행될 쿼리를 하나의 쿼리로 조회할 수 있습니다.\n\n### 무엇이 문제인가\n\n- 하나의 주문을 조회하는 쿼리를 호출한다\n- 주문을 조회할때 주문상품들을 조회하는 쿼리가 하나의 주문을 조회하는 만큼 호출된다.\n\n## batch-size 로 해결하기\n\n- application.properties 설정 추가하기\n    \n    ```java\n    spring.jpa.properties.hibernate.default_batch_fetch_size=1000\n    ```\n\n`batch-size` 옵션은 연관된 하위 엔티티를 로딩할 때 상위 엔티티 ID를 지정한 숫자만큼 `in` 쿼리로 로딩합니다. \n\n예로 들어 `batch-size:1000`으로 되어있으면, 상위 엔티티인 `order`의 id 1000개를 `in` 쿼리로 `orderItem`를 조회하게 됩니다.\n\n해당 옵션을 추가한 후 다시 구매 이력을 조회하면 반복문에서 `order.getOrderItems()` 최초 실행할 때 로그를 보겠습니다.\n\n- 2건의 주문이력을 요청할때\n```java\nHibernate: \n    select\n        orderitems0_.order_id as order_id9_5_1_,\n        orderitems0_.order_item_id as order_it1_5_1_,\n        orderitems0_.order_item_id as order_it1_5_0_,\n        orderitems0_.create_time as create_t2_5_0_,\n        orderitems0_.update_time as update_t3_5_0_,\n        orderitems0_.created_by as created_4_5_0_,\n        orderitems0_.modified_by as modified5_5_0_,\n        orderitems0_.count as count6_5_0_,\n        orderitems0_.item_id as item_id8_5_0_,\n        orderitems0_.order_id as order_id9_5_0_,\n        orderitems0_.order_price as order_pr7_5_0_ \n    from\n        order_item orderitems0_ \n    where\n        orderitems0_.order_id in (\n            ?, ?\n        )\n```\n\n해당 로그를 보시면은 조건절에 in 쿼리문이 실행되는 것을 볼 수 있습니다.\n\n이렇게 간단한 설정을 통해 in 쿼리문으로 조회하도록 성능 이슈를 해결했습니다\nJPA에서 N+1 을 해결하는 방법들은 여러개 이니 batch_size는 연관관계에서 데이터 사이즈를 정확하게 알고 있을 때 조심해서 사용하시면 됩니다.\n\n### Reference\n\n[스프링 부트 쇼핑몰 프로젝트 with JPA](http://www.yes24.com/Product/Goods/103453774)\n\n[Spring Batch JPA에서 N+1 문제 해결](https://jojoldu.tistory.com/414)","excerpt":"쇼핑물에서 이용자의 구매이력을 조회 시, N+1 문제가 발생해 성능저하가 일어나는 상황에서\n간단한 해결법으로 성능 향상을 이루는 법을 알아보겠습니다. N+1 문제란? 연관 관계에서 발생하는 이슈로 연관 관계가 설정된 엔티티를 조회할 경우에 조회된 데…","fields":{"slug":"/spring-jpa-N+1-problem/"},"frontmatter":{"date":"Jan 28, 2022","title":"[Spring JPA] 쇼핑물 주문이력 조회 시 N+1 문제 해결하기","tags":["Spring JPA"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"# 1. 회원가입 API 작성\n\n## SecurityUtil 클래스\n\n간단한 유틸리티 메소드를 만들기 위해 `SecurityUtil` 클래스를 util 패키지에 생성하겠습니다.\n\n```java\npublic class SecurityUtil {\n\n   private static final Logger logger = LoggerFactory.getLogger(SecurityUtil.class);\n\n   private SecurityUtil() {\n   }\n\n   public static Optional<String> getCurrentUsername() {\n      final Authentication authentication = SecurityContextHolder.getContext().getAuthentication();\n\n      if (authentication == null) {\n         logger.debug(\"Security Context에 인증 정보가 없습니다.\");\n         return Optional.empty();\n      }\n\n      String username = null;\n      if (authentication.getPrincipal() instanceof UserDetails) {\n         UserDetails springSecurityUser = (UserDetails) authentication.getPrincipal();\n         username = springSecurityUser.getUsername();\n      } else if (authentication.getPrincipal() instanceof String) {\n         username = (String) authentication.getPrincipal();\n      }\n\n      return Optional.ofNullable(username);\n   }\n```\n\n`getCurrentUsername` 메소드의 역활은 SecurityContext의 Authentication 객체를 이용해 `username`을 리턴해주는 간단한 유틸성 메소드입니다. \n\n`SecurityContext`에 Authenticaion 객체가 저장되는 시점은 JwtFilter의 `doFilter`메소드에서 Request가 들어올때 SecurityContext에 Authenticaion 객체를 저장해서 사용하게 됩니다.\n\n## UserService 클래스\n\n회원가입, 유저 정보 조회등의 메소드를 만들기 위해 UserService 클래스를 생성하겠습니다.\n\n```java\n@Service\npublic class UserService {\n    private final UserRepository userRepository;\n    private final PasswordEncoder passwordEncoder;\n\n    public UserService(UserRepository userRepository, PasswordEncoder passwordEncoder) {\n        this.userRepository = userRepository;\n        this.passwordEncoder = passwordEncoder;\n    }\n\n@Transactional\n    public User signup(UserDto userDto) {\n        if (userRepository.findOneWithAuthoritiesByUsername(userDto.getUsername()).orElse(null) != null) {\n            throw new RuntimeException(\"이미 가입되어 있는 유저입니다.\");\n        }\n\n        Authority authority = Authority.builder()\n                .authorityName(\"ROLE_USER\")\n                .build();\n\n        User user = User.builder()\n                .username(userDto.getUsername())\n                .password(passwordEncoder.encode(userDto.getPassword()))\n                .nickname(userDto.getNickname())\n                .authorities(Collections.singleton(authority))\n                .activated(true)\n                .build();\n\n        return userRepository.save(user);\n    }\n\n    @Transactional(readOnly = true)\n    public Optional<User> getUserWithAuthorities(String username) {\n        return userRepository.findOneWithAuthoritiesByUsername(username);\n    }\n\n    @Transactional(readOnly = true)\n    public Optional<User> getMyUserWithAuthorities() {\n        return SecurityUtil.getCurrentUsername().flatMap(userRepository::findOneWithAuthoritiesByUsername);\n    }\n}\n```\n\nUserService 클래스는 `UserRepository`, `PasswordEncoder`를 주입받습니다.\n\n`singup` 메소드는 username이 DB에 존재하지 않으면 Authority와 User 정보를 생성해서 UserRepository의 `save`메소드를 통해 DB에 정보를 저장합니다. \n\n여기서 **중요한 점**은 `singup` 메소드를 통해 가입한 회원은 USER ROLE을 가지고 있고 `data.sql` 에서 자동 생성되는 admin 계정은 USER, ADMIN ROLE을 가지고 있습니다 이 차이를 통해 권한검증 부분을 테스트 하겠습니다.\n\n그리고 유저 권한정보를 가져오는 메소드가 2개 있습니다.\n\n`getUserWithAuthorities`는 username을 기준으로 정보를 가져오고\n\n`getMyUserWithAuthorities`는 SecurityContext에 저장된 username의 정보만 가져옵니다.\n\n이 두가지 메소드의 허용권한을 다르게 해서 권한검증에 대한 부분을 테스트하겠습니다.\n\n# 2. 권한 검증\n\n## UserController 클래스\n\n`UserService`의 메소드들을 호출할 `UserController` 클래스를 생성하겠습니다.\n\n```java\n@RestController\n@RequestMapping(\"/api\")\npublic class UserController {\n    private final UserService userService;\n\n    public UserController(UserService userService) {\n        this.userService = userService;\n    }\n\n    @PostMapping(\"/signup\")\n    public ResponseEntity<User> signup(@Valid @RequestBody UserDto userDto) {\n        return ResponseEntity.ok(userService.signup(userDto));\n    }\n\n    @GetMapping(\"/user\")\n    @PreAuthorize(\"hasAnyRole('USER','ADMIN')\")\n    public ResponseEntity<User> getMyUserInfo(HttpServletRequest request) {\n        return ResponseEntity.ok(userService.getMyUserWithAuthorities().get());\n    }\n\n    @GetMapping(\"/user/{username}\")\n    @PreAuthorize(\"hasAnyRole('ADMIN')\")\n    public ResponseEntity<User> getUserInfo(@PathVariable String username) {\n        return ResponseEntity.ok(userService.getUserWithAuthorities(username).get());\n    }\n}\n```\n\n- `@PreAuthorize`\n    - 해당 메서드가 호출되기 이전에 권한을 검사한다\n- `hasAnyRole([role1, role2])`\n    - 현재 사용자의 권한이 파라미터의 권한 중 일치하는 것이 있는 경우 `true` 를 리턴\n\n`sinup` 메소드는 UserDto를 매개변수로 받아서 UserService의 `singup` 메소드를 호출합니다.\n\n`getMyUserInfo` 메소드는 `@PreAuthorize`를 통해서 USER, ADMIN 두가지 권한 모두 허용했고\n\n`getUserInfo` 메소드는 ADMIN 권한만 호출할 수 있도록 설정했습니다 그리고 `UserService`에서 만들었던 username 매개변수를 기준으로 유저 정보와 권한 정보를 리턴하는 API가 되겠습니다. \n\n# 3. Response 시 DTO를 통해서만 받기\n\n## 기존 문제점\n\n추가적으로 지금까지 로직을 보시면 사용자 요청에 대해 응답을 Entity 그대로 전달하기 때문에 문제가있습니다.  문제점을 보기위해 Entity를 통해 반환을 하게 되면 어떤 결과를 나오는지 보겠습니다.\n\n- Response - `POST` /api/signup\n\n```json\n{\n    \"userId\": 3,\n    \"username\": \"hoon\",\n    \"password\": \"$2a$10$PZhLrJzS9YQX1.M5.ezMhu/VFAbtSiYLU.ExF3qzlBrrk7bHPyzdm\",\n    \"nickname\": \"nick\",\n    \"activated\": true,\n    \"authorities\": [\n        {\n            \"authorityName\": \"ROLE_USER\"\n        }\n    ]\n}\n```\n\n해당 응답 결과처럼, 보시면은 중요한 정보들이 그대로 반환이 됩니다 그 이유는 `UserService`의 회원가입 로직을 처리하는 메소드가 User Entity 그대로 반환해주기 때문에 사용자 측에서는 해당 결과를 받게됩니다.\n\n보안적인 측면에서도 안좋은 방식이므로 DTO를 통해 응답하도록 코드를 수정하겠습니다.\n\n## 해결법\n\n### AuthorityDto 클래스 생성\n\n권한정보에 대한 DTO 클래스를 작성하겠습니다.\n\n```java\n@Getter\n@Setter\n@Builder\n@AllArgsConstructor\n@NoArgsConstructor\npublic class AuthorityDto {\n    private String authorityName;\n}\n```\n\n### UserDto 클래스 수정\n\n아래와 같이 권한 정보에 대한 `authorityDtoSet` 필드를 추가하고 `from` 메소드를 추가합니다.\n\n```java\nprivate Set<AuthorityDto> authorityDtoSet;\n\n    public static UserDto from(User user) {\n        if(user == null) return null;\n\n        return UserDto.builder()\n                .username(user.getUsername())\n                .nickname(user.getNickname())\n                .authorityDtoSet(user.getAuthorities().stream()\n                        .map(authority -> AuthorityDto.builder().authorityName(authority.getAuthorityName()).build())\n                        .collect(Collectors.toSet()))\n                .build();\n    }\n```\n\n`from` 메소드는 `User` 객체를 매개변수로 받아서 해당 객체가 `null`이 아니면, 해당 객체를 `UserDto`로 생성해서 반환합니다.\n\n### UserService 클래스 수정\n\n`User`로 반환하던 이전 메소드들을 `UserDto`로 반환하도록 수정하겠습니다. (굵은 글씨를 봐주세요)\n\n```java\n@Transactional\n    public **UserDto** signup(UserDto userDto) {\n        if (userRepository.findOneWithAuthoritiesByUsername(userDto.getUsername()).orElse(null) != null) {\n            throw new RuntimeException(\"이미 가입되어 있는 유저입니다.\");\n        }\n\n        Authority authority = Authority.builder()\n                .authorityName(\"ROLE_USER\")\n                .build();\n\n        User user = User.builder()\n                .username(userDto.getUsername())\n                .password(passwordEncoder.encode(userDto.getPassword()))\n                .nickname(userDto.getNickname())\n                .authorities(Collections.singleton(authority))\n                .activated(true)\n                .build();\n\n        return **UserDto.from**(userRepository.save(user));\n    }\n\n    @Transactional(readOnly = true)\n    public **UserDto** getUserWithAuthorities(String username) {\n        return **UserDto.from**(userRepository.findOneWithAuthoritiesByUsername(username)**.orElse(null))**;\n    }\n\n    @Transactional(readOnly = true)\n    public **UserDto** getMyUserWithAuthorities() {\n        return **UserDto.from**(SecurityUtil.getCurrentUsername().flatMap(userRepository::findOneWithAuthoritiesByUsername)**.orElse(null))**;\n    }\n```\n\n회원가입 로직을 처리하는 `signup` 메소드는 기존 소스 그대로에서 `UserDto.from` 을 통해 `User`를 Dto로 생성해서 반환합니다.\n\n나머지 두개의 권한 정보을 반환하는 메소드도 `UserDto`로 반환하도록 수정합니다.\n\n기존에는 `Optional`을 통해서 `null` 예외처리를 해줬지만, 이젠 `null` 값이 들어오면 해당 값 그대로 리턴합니다.\n\n### UserController 클래스 수정\n\n요청에 대해 `User`로 반환하던 이전 메소드들을 `UserDto`로 반환하도록 수정하겠습니다.\n\n```java\n@PostMapping(\"/signup\")\n    public ResponseEntity<**UserDto**> signup(@Valid @RequestBody UserDto userDto) {\n        return ResponseEntity.ok(userService.signup(userDto));\n    }\n\n    @GetMapping(\"/user\")\n    @PreAuthorize(\"hasAnyRole('USER','ADMIN')\")\n    public ResponseEntity<**UserDto**> getMyUserInfo(HttpServletRequest request) {\n        return ResponseEntity.ok(userService.getMyUserWithAuthorities());\n    }\n\n    @GetMapping(\"/user/{username}\")\n    @PreAuthorize(\"hasAnyRole('ADMIN')\")\n    public ResponseEntity<**UserDto**> getUserInfo(@PathVariable String username) {\n        return ResponseEntity.ok(userService.getUserWithAuthorities(username));\n    }\n```\n\n기존과 비슷하게 반환하는 객체를 `UserDto`로 변경해줍니다.\n\nAPI 요청에 대해 `Entity`을 반환하는것이 아닌 `Dto`를 반환하는 코드로 변경을 완료했습니다.\n\n# 4. 회원가입 API 테스트\n\n이제 우리가 만든 3개의 API를 Postman, H2 Console를 이용해 테스트해보겠습니다.\n\n## 회원가입 요청\n\nURL : [http://localhost:8080/api/signup](http://localhost:8080/api/signup) 경로로 `POST` 요청을 보냅니다.\n\n![Untitled](5-1.png)\n\n- Response\n    \n    ```json\n    {\n        \"username\": \"hoon\",\n        \"nickname\": \"nick\",\n        \"authorityDtoSet\": [\n            {\n                \"authorityName\": \"ROLE_USER\"\n            }\n        ]\n    }\n    ```\n    \n\n회원가입 API에 대한 응답이 정상적으로 반환됬습니다 이제 가입된 유저정보를 H2 Console 에서 확인해보겠습니다.\n\n### H2 Console\n\n<img src=\"5-2.png\" width=\"300\" height=\"500\"/>\n\n추가한 유저 정보가 잘 등록된것을 볼수있습니다.\n\n이제 권한이 다른 두 계정(admin, uesr)을 가지고 두 개의 API를 테스트해보겠습니다.\n\n## 권한 API 테스트\n\n먼저 ADMIN 권한만 허용했던 API를 테스트하겠습니다.\n\nURL : [http://localhost:8080/api/user/hoon](http://localhost:8080/api/user/hoon) 경로로 GET 요청을 합니다.\n\n- Response - `GET` /api/user/hoon\n    \n    ![Untitled](5-3.png)\n    \n\n401 상태가 반환된것을 볼수있습니다.\n\n### JWT Token 가져오기\n\nADMIN 계정을 로그인해서 token을 가져오겠습니다,\n\nURL : [http://localhost:8080/api/authenticate](http://localhost:8080/api/authenticate) 경로에 POST 요청을 보냅니다.\n\n- Response - `POST` /api/authenticate\n    \n    ```json\n    {\n        \"token\": \"eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJhZG1pbiIsImF1dGgiOiJST0xFX0FETUlOLFJPTEVfVVNFUiIsImV4cCI6MTY0MjE2NTU3N30.UyNbN-cX82pIRHOMKWTjnDSTLX-TWzER3otxNaKKTxeB9egSL2gp8FMzr5wznIFRXEyBdU-1cFMcKnQerBjiGg\"\n    }\n    ```\n    \n\n그리고 해당 어드민 유저의 토큰을 HTTP Headers에 `Authorization : Bearer {jwt_token}` 형식으로 담고 다시 권한 API 경로로 GET 요청을 보냅니다.\n\n### ADMIN 권한 테스트\n\n- Response - `GET` /api/user/hoon\n    \n    ```json\n    {\n        \"username\": \"hoon\",\n        \"nickname\": \"nick\",\n        \"authorityDtoSet\": [\n            {\n                \"authorityName\": \"ROLE_USER\"\n            }\n        ]\n    }\n    ```\n    \n\n/api/user/hoon 경로는 `ROLE_ADMIN` 권한을 가진 유저만 접근할 수 있는데. 정상적으로 응답이 된것을 확인할수있습니다.\n\n### USER 권한 테스트\n\n이번에는 hoon 계정의 토큰으로 이 API를 재호출 해보도록 하겠습니다.\n\n기존에 로그인 API를 hoon 계정으로 요청하고, 토큰을 발급받습니다.\n\n- Response - `POST` /api/authenticate\n    \n    ```json\n    {\n        \"token\": \"eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJob29uIiwiYXV0aCI6IlJPTEVfVVNFUiIsImV4cCI6MTY0MjE2NjA1N30.UMN19s9OGrX10qcO6tgET91rggoatwtfutr6L2iuL4da67vF7vR_4D1zXOKb4_0pCVtamREhGsDm_Y-iMImBPg\"\n    }\n    ```\n    \n\nhoon 계정으로 POST 요청을 했고 해당 토큰을 이용해서 다시 API 를 호출하겠습니다.\n\n- Response - `GET` /api/user/hoon\n    \n    ```json\n    {\n        \"timestamp\": \"2022-01-13T13:15:29.386+00:00\",\n        \"status\": 403,\n        \"error\": \"Forbidden\",\n        \"path\": \"/api/user/hoon\"\n    }\n    ```\n    \n\nhoon 계정의 토큰으로 요청을 해보면 `403 Foribidden` 에러가 반환된 것을 볼수있습니다.\n\n해당 403 Forbidden 에러는 저희가 작성한 `JwtAccessDeniedHandler`에 의해 발생됬습니다.\n\n이번에는 USER권한을 허용해줬던 API를 hoon 계정의 토큰으로 호출해보겠습니다.\n\n- Response - `GET` /api/user\n    \n    ```json\n    {\n        \"username\": \"hoon\",\n        \"nickname\": \"nick\",\n        \"authorityDtoSet\": [\n            {\n                \"authorityName\": \"ROLE_USER\"\n            }\n        ]\n    }\n    ```\n    \n\nhoon 계정으로 발급받은 토큰으로 이 API 는 잘 호출되는 것을 볼수있습니다.\n\n이제 해당 강의에서 준비한 JWT Tutorial의 모든 부분이 완료됬습니다. 읽어주셔서 감사합니다😊\n\n# Reference\n\n[https://gaemi606.tistory.com/entry/Spring-Boot-Spring-Security-PreAuthorize사용하기](https://gaemi606.tistory.com/entry/Spring-Boot-Spring-Security-PreAuthorize%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0)\n\n[https://steemit.com/kr-dev/@igna84/spring-security-preauthorize-postauthorize](https://steemit.com/kr-dev/@igna84/spring-security-preauthorize-postauthorize)","excerpt":"1. 회원가입 API 작성 SecurityUtil 클래스 간단한 유틸리티 메소드를 만들기 위해  클래스를 util 패키지에 생성하겠습니다.  메소드의 역활은 SecurityContext의 Authentication 객체를 이용해 을 리턴해주는 간단한…","fields":{"slug":"/springboot-jwt-tutorial5/"},"frontmatter":{"date":"Jan 14, 2022","title":"SpringBoot JWT 튜토리얼 - 5장 회원가입, 권한검증 [최종]","tags":["SpringBoot","JWT","튜토리얼"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"# 1. DTO 클래스 생성\n\n## LoginDto 클래스\n\n외부와의 통신에 사용할 DTO 패키지 및 클래스를 생성합니다.\n\n```java\n@Getter\n@Setter\n@Builder\n@AllArgsConstructor\n@NoArgsConstructor\npublic class LoginDto {\n\n    @NotNull\n    @Size(min = 3, max = 50)\n    private String username;\n\n    @NotNull\n    @Size(min = 3, max = 100)\n    private String password;\n}\n```\n\nLombok 어노테이션(Get, Set 등)이 추가되었고 @Valid 관련 어노테이션을 추가했습니다.\n\n로그인 할 이용자의 아이디, 비밀번호를 담을 username, password 필드를 가집니다.\n\n## TokenDto 클래스\n\nToken 정보를 Response 할때 사용할 TokenDto를 만들겠습니다.\n\n```java\n@Getter\n@Setter\n@Builder\n@AllArgsConstructor\n@NoArgsConstructor\npublic class TokenDto {\n\n    private String token;\n}\n```\n\n## UserDto 클래스\n\n회원가입시에 사용할 UserDto 클래스도 미리 만들어주겠습니다.\n\n```java\n@Getter\n@Setter\n@Builder\n@AllArgsConstructor\n@NoArgsConstructor\npublic class UserDto {\n\n    @NotNull\n    @Size(min = 3, max = 50)\n    private String username;\n\n    @JsonProperty(access = JsonProperty.Access.WRITE_ONLY)\n    @NotNull\n    @Size(min = 3, max = 100)\n    private String password;\n\n    @NotNull\n    @Size(min = 3, max = 50)\n    private String nickname;\n}\n```\n\n# 2. Repository 관련 코드 작성\n\n이제 Repository들을 만들어주기 위해 repository 패키지를 생성합니다.\n\n## UserRepository 인터페이스\n\n이전에 만들었던 User 엔티티에 매핑되는 UserRepository 인터페이스를 만들겠습니다.\n\n```java\npublic interface UserRepository extends JpaRepository<User, Long> {\n    @EntityGraph(attributePaths = \"authorities\")\n    Optional<User> findOneWithAuthoritiesByUsername(String username);\n}\n```\n\n- `EntityGraph` : 쿼리가 수행될때 Lazy 조회가 아니고 Eager조회로 authorities 정보를 같이가져옵니다.\n    - Lazy, Eager : 지연로딩(lazy), 즉시로딩(eager) 연관관계의 데이터를 어떻게 가져올지 (fetch)\n\n`JpaRepository`를 `extends` 하면 `findAll`, `save` 등의 메소드를 기본적으로 사용할 수 있습니다.\n\n`findOneWithAuthoritiesByUsername` 메소드는 username을 기준으로 User 정보를 가져올때 권한 정보도 같이 가져오게됩니다.\n\n# 3. 로그인 API, 관련 로직 생성\n\n## CustomUserDetailsService 클래스\n\nSpring Security에서 중요한 부분중 하나인 UserDetailsService를 구현한 CustomUserDetailsService 클래스를 생성하겠습니다. \n\n먼저 service 패키지를 만들어고 해당 패키지에 클래스를 생성합니다.\n\n```java\n@Component(\"userDetailsService\")\npublic class CustomUserDetailsService implements UserDetailsService {\n    private final UserRepository userRepository;\n\n    public CustomUserDetailsService(UserRepository userRepository) {\n        this.userRepository = userRepository;\n    }\n\n    @Override\n    @Transactional\n    public UserDetails loadUserByUsername(final String username) {\n        return userRepository.findOneWithAuthoritiesByUsername(username)\n                .map(user -> createUser(username, user))\n                .orElseThrow(() -> new UsernameNotFoundException(username + \" -> 데이터베이스에서 찾을 수 없습니다.\"));\n    }\n\n    private org.springframework.security.core.userdetails.User createUser(String username, User user) {\n        if (!user.isActivated()) {\n            throw new RuntimeException(username + \" -> 활성화되어 있지 않습니다.\");\n        }\n        List<GrantedAuthority> grantedAuthorities = user.getAuthorities().stream()\n                .map(authority -> new SimpleGrantedAuthority(authority.getAuthorityName()))\n                .collect(Collectors.toList());\n        return new org.springframework.security.core.userdetails.User(user.getUsername(),\n                user.getPassword(),\n                grantedAuthorities);\n    }\n}\n```\n\n`UserDetailsService`를 `implements`하고 `UserRepository`를 주입받습니다. `loadUserByUsername` 메소드를 오버라이드해서 로그인시에 DB에서 유저정보와 권한정보를 가져오게됩니다.\n\n해당 정보를 기반으로 해서 `userdetails.user` 객체를 생성해서 리턴합니다.\n\n## AuthController 클래스\n\n로그인 API를 추가하기 위해서 AuthController 클래스를 만들겠습니다.\n\n```java\n@RestController\n@RequestMapping(\"/api\")\npublic class AuthController {\n    private final TokenProvider tokenProvider;\n    private final AuthenticationManagerBuilder authenticationManagerBuilder;\n\n    public AuthController(TokenProvider tokenProvider, AuthenticationManagerBuilder authenticationManagerBuilder) {\n        this.tokenProvider = tokenProvider;\n        this.authenticationManagerBuilder = authenticationManagerBuilder;\n    }\n\n    @PostMapping(\"/authenticate\")\n    public ResponseEntity<TokenDto> authorize(@Valid @RequestBody LoginDto loginDto) {\n\n        UsernamePasswordAuthenticationToken authenticationToken =\n                new UsernamePasswordAuthenticationToken(loginDto.getUsername(), loginDto.getPassword());\n\n        Authentication authentication = authenticationManagerBuilder.getObject().authenticate(authenticationToken);\n        SecurityContextHolder.getContext().setAuthentication(authentication);\n\n        String jwt = tokenProvider.createToken(authentication);\n\n        HttpHeaders httpHeaders = new HttpHeaders();\n        httpHeaders.add(JwtFilter.AUTHORIZATION_HEADER, \"Bearer \" + jwt);\n\n        return new ResponseEntity<>(new TokenDto(jwt), httpHeaders, HttpStatus.OK);\n    }\n}\n```\n\n이전에 만들었던 `TokenProvider`, `AuthenticationManagerBuilder` 를 주입받습니다.\n\n로그인 API 경로는 `/api/authenticate` 경로이고 `POST` 요청을 받습니다.\n\n### authorize 메소드\n\n`authorize` 메소드는 LoginDto의 username, password를 매개변수로 받고 이를 이용해 `UsernamePasswordAuthenticationToken`을 생성합니다.\n\nauthenticationToken을 이용해서 Authentication 객체를 생성하려고 `authenticate` 메소드가 실행이될 때 `CustomUserDetailsService` 클래스의 `loadUserByUsername` 메소드가 실행됩니다.\n\n이 결과값을 이용해서 Authenticaion 객체를 생성하고 이를 SecurityContext 에 저장하고 Authenticaion 객체를 `createToken` 메소드를 통해서 JWT Token 을 생성합니다.\n\nJWT Token 을 Response Header에 넣어주고 TokenDto를 이용해서 Response Body에도 넣어서 리턴하게 됩니다.\n\n# 4. 로그인 API 테스트\n\n자 이제 로그인 API 를 포스트맨으로 테스트해보겠습니다.\n\n## 로그인 요청\n\n [http://localhost:8080/api/authenticate](http://localhost:8080/api/authenticate) 경로로 아래와 같이 `POST` 요청을 보냅니다.\n\n![Untitled](4-1.png)\n\nadmin 계정 정보는 data.sql의 insert문이 서버가 시작될때 자동실행되어 DB에 저장된 상태입니다.\n\n- 405 HTTP 상태 코드가 발생하면?\n    - Server Log\n    \n    ```json\n    2022-01-12 18:35:18.364 DEBUG 5197 --- [nio-8080-exec-1] com.example.jwttutorial.jwt.JwtFilter    : 유효한 JWT 토큰이 없습니다, uri: /api/authenticate\n    2022-01-12 18:35:18.373  WARN 5197 --- [nio-8080-exec-1] .w.s.m.s.DefaultHandlerExceptionResolver : Resolved [org.springframework.web.HttpMediaTypeNotSupportedException: Content type 'text/plain;charset=UTF-8' not supported]\n    2022-01-12 18:35:18.374 DEBUG 5197 --- [nio-8080-exec-1] com.example.jwttutorial.jwt.JwtFilter    : 유효한 JWT 토큰이 없습니다, uri: /error\n    ```\n    \n    - Response\n    \n    ```json\n    {\n        \"timestamp\": \"2022-01-12T09:33:18.957+00:00\",\n        \"status\": 415,\n        \"error\": \"Unsupported Media Type\",\n        \"path\": \"/api/authenticate\"\n    }\n    ```\n    \n    위와 같이 응답이 반환되면 POST 요청을 보낼때 `JSON` 형식으로 보내시면됩니다.\n    \n\n## 정상 응답\n\n정상적으로 요청이 응답된다면 서버에선 해당 sql문 query 내용이 로그로 나타납니다\n\n```sql\nHibernate: \n    select\n        user0_.user_id as user_id1_1_0_,\n        authority2_.authority_name as authorit1_0_1_,\n        user0_.activated as activate2_1_0_,\n        user0_.nickname as nickname3_1_0_,\n        user0_.password as password4_1_0_,\n        user0_.username as username5_1_0_,\n        authoritie1_.user_id as user_id1_2_0__,\n        authoritie1_.authority_name as authorit2_2_0__ \n    from\n        user user0_ \n    left outer join\n        user_authority authoritie1_ \n            on user0_.user_id=authoritie1_.user_id \n    left outer join\n        authority authority2_ \n            on authoritie1_.authority_name=authority2_.authority_name \n    where\n        user0_.username=?\n```\n\n그리고 Repsonse 내용으로 아래와 같이 Token이 정상적으로 리턴됩니다.\n\n```json\n{\n    \"token\": \"eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJhZG1pbiIsImF1dGgiOiJST0xFX0FETUlOLFJPTEVfVVNFUiIsImV4cCI6MTY0MjA2NjU2NH0.QLtuqh874mipMl-h0cO6p4Jf430RGf2uBArr5nWcnmnvG6YqVo0qFXGxEwbPHD9u7J4Zl1GIL0YuWQTXWdUYHA\"\n}\n```\n\n이제 DTO 클래스, Repository, 로그인 API의 개발이 완료되었습니다. \n\n디음 편에서는 회원가입 API를 만들고 회원가입한 유저와 admin 관리자의 권한 검증을 구성하겠습니다.\n\n- Postman의 유용한 기능\n\n![Untitled](4-2.png)\n\n위와 같이 Tests 탭에서 Response의 데이터를 전역변수에 저장해서 다른 Request에서도 사용할 수 있습니다.\n\n# Reference\n\n[Spring Docs - JpaRepository](https://docs.spring.io/spring-data/jpa/docs/current/api/org/springframework/data/jpa/repository/JpaRepository.html)","excerpt":"1. DTO 클래스 생성 LoginDto 클래스 외부와의 통신에 사용할 DTO 패키지 및 클래스를 생성합니다. Lombok 어노테이션(Get, Set 등)이 추가되었고 @Valid 관련 어노테이션을 추가했습니다. 로그인 할 이용자의 아이디, 비밀번호…","fields":{"slug":"/springboot-jwt-tutorial4/"},"frontmatter":{"date":"Jan 13, 2022","title":"SpringBoot JWT 튜토리얼 - 4장 DTO,Repository,로그인 구현","tags":["SpringBoot","JWT","튜토리얼"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"# 1. JWT 설정추가\n\napplication.yml 파일을 열고, jwt 설정을 추가하겠습니다.\n\n```yaml\njwt:\n  header: Authorization\n  #HS512 알고리즘을 사용할 것이기 때문에 512bit, 즉 64byte 이상의 secret key를 사용해야 한다.\n  #echo 'silvernine-tech-spring-boot-jwt-tutorial-secret-silvernine-tech-spring-boot-jwt-tutorial-secret'|base64\n  secret: c2lsdmVybmluZS10ZWNoLXNwcmluZy1ib290LWp3dC10dXRvcmlhbC1zZWNyZXQtc2lsdmVybmluZS10ZWNoLXNwcmluZy1ib290LWp3dC10dXRvcmlhbC1zZWNyZXQK\n  token-validity-in-seconds: 86400\n```\n\n- header : JWT를 검증하는데 필요한 정보\n- secret : HS512 알고리즘을 사용할 것이기 때문에 512bit, 즉 64byte 이상의 secret key를 사용해야 한다\n    - 위 예제에서는 Secret Key 를 Base64 로 인코딩한 값임.\n- token-validity-in-seconds : 토큰의 만료시간을 지정함 (단위는 초)\n\n이제 build.gradle 파일로 가서 JWT 관련 라이브러리를 추가합니다.\n\n```yaml\nimplementation group: 'io.jsonwebtoken', name: 'jjwt-api', version: '0.11.2'\nruntimeOnly group: 'io.jsonwebtoken', name: 'jjwt-impl', version: '0.11.2'\nruntimeOnly group: 'io.jsonwebtoken', name: 'jjwt-jackson', version: '0.11.2'\n```\n\n그 후 그래들을 다시 불러와, 프로젝트에 의존성을 설치해줍니다. \n\nJWT 개발을 위한 준비는 완료되었고 이제 JWT 코드를 개발하겠습니다.\n\n# 2. JWT 관련 코드 작성\n\n## TokenProvider 클래스\n\njwt 패키지를 생성하고, 토큰의 생성과 토큰의 유효성 검증등을 담당할 Token Provider 를 만들겠습니다.\n\n```java\n@Component\npublic class TokenProvider implements InitializingBean {\n\n    private final Logger logger = LoggerFactory.getLogger(TokenProvider.class);\n\n    private static final String AUTHORITIES_KEY = \"auth\";\n\n    private final String secret;\n    private final long tokenValidityInMilliseconds;\n\n    private Key key;\n\n    public TokenProvider(\n            @Value(\"${jwt.secret}\") String secret,\n            @Value(\"${jwt.token-validity-in-seconds}\") long tokenValidityInSeconds) {\n        this.secret = secret;\n        this.tokenValidityInMilliseconds = tokenValidityInSeconds * 1000;\n    }\n\n    @Override\n    public void afterPropertiesSet() {\n        byte[] keyBytes = Decoders.BASE64.decode(secret);\n        this.key = Keys.hmacShaKeyFor(keyBytes);\n    }\n}\n```\n\n`InitializingBean`  인터페이스를 구현하여, `afterPropertiesSet` 메소드를 Override 한 이유는\n\nBean이 생성이 되고, 의존성 주입을 받은 후에 secret 값을 Base64 Decode 해서 key 변수에 할당합니다.\n\n### createToken 메소드\n\nAuthentication 객체의 권한정보를 이용해서 토큰을 생성하는 createToken 메소드를 추가합니다.\n\n```java\npublic String createToken(Authentication authentication) {\n      String authorities = authentication.getAuthorities().stream()\n         .map(GrantedAuthority::getAuthority)\n         .collect(Collectors.joining(\",\"));\n\n      long now = (new Date()).getTime();\n      Date validity = new Date(now + this.tokenValidityInMilliseconds);\n\n      return Jwts.builder()\n         .setSubject(authentication.getName())\n         .claim(AUTHORITIES_KEY, authorities)\n         .signWith(key, SignatureAlgorithm.HS512)\n         .setExpiration(validity)\n         .compact();\n   }\n```\n\nauthenticaion 객체를 받아서 권한 설정을 하고, application.yml 에서 설정했던 토큰 만료시간을 설정하고 토큰을 생성합니다.\n\n### getAuthenticaion 메소드\n\ntoken을 매개변수로 받아서, 토큰에 담긴 정보를 이용해 Authenticaion 객체를 리턴하는 메소드를 작성합니다.\n\n```java\npublic Authentication getAuthentication(String token) {\n      Claims claims = Jwts\n              .parserBuilder()\n              .setSigningKey(key)\n              .build()\n              .parseClaimsJws(token)\n              .getBody();\n\n      Collection<? extends GrantedAuthority> authorities =\n         Arrays.stream(claims.get(AUTHORITIES_KEY).toString().split(\",\"))\n            .map(SimpleGrantedAuthority::new)\n            .collect(Collectors.toList());\n\n      User principal = new User(claims.getSubject(), \"\", authorities);\n\n      return new UsernamePasswordAuthenticationToken(principal, token, authorities);\n   }\n```\n\ntoken으로 클레임을 만들고, 클레임에서 권한정보를 받아서 유저 객체를 만들어서 최종적으로 Authenticaion 객체를 리턴합니다.\n\n- Claims : JWT 의 속성정보, java 에서 Claims 는 Json map 형식의 인터페이스임\n\n### validateToken 메소드\n\ntoken을 매개변수로 받아서, 토큰의 유효성 검증을 수행하는 validateToken 메소드를 작성합니다.\n\n```java\npublic boolean validateToken(String token) {\n      try {\n         Jwts.parserBuilder().setSigningKey(key).build().parseClaimsJws(token);\n         return true;\n      } catch (io.jsonwebtoken.security.SecurityException | MalformedJwtException e) {\n         logger.info(\"잘못된 JWT 서명입니다.\");\n      } catch (ExpiredJwtException e) {\n         logger.info(\"만료된 JWT 토큰입니다.\");\n      } catch (UnsupportedJwtException e) {\n         logger.info(\"지원되지 않는 JWT 토큰입니다.\");\n      } catch (IllegalArgumentException e) {\n         logger.info(\"JWT 토큰이 잘못되었습니다.\");\n      }\n      return false;\n   }\n```\n\n토큰을 파싱하고, 발생하는 예외들을 캐치하여, 문제가 있음면 false, 정상이면 true를 리턴합니다.\n\n## JwtFilter 클래스\n\nJWT를 위한 커스텀 필터를 만들기 위해 JwtFilter 클래스를 생성합니다.\n\n```java\npublic class JwtFilter extends GenericFilterBean {\n\n    private static final Logger logger = LoggerFactory.getLogger(JwtFilter.class);\n\n    public static final String AUTHORIZATION_HEADER = \"Authorization\";\n\n    private TokenProvider tokenProvider;\n\n    public JwtFilter(TokenProvider tokenProvider) {\n        this.tokenProvider = tokenProvider;\n    }\n\n    @Override\n    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain)\n            throws IOException, ServletException {\n        \n    }\n}\n```\n\n- doFilter : JWT 토큰의 인증정보를 현재 실행중인 SecurityContext 에 저장하는 역활\n\nGenericFilterBean을 상속받아 doFilter 메소드를 Override.\n\n실제 필터링 로직은 doFilter 내부에 작성합니다.\n\n### resolveToken 메소드\n\nRequest Header 에서 토큰정보를 가져오기 위한, resolveToken 메소드를 추가합니다.\n\n```java\nprivate String resolveToken(HttpServletRequest request) {\n      String bearerToken = request.getHeader(AUTHORIZATION_HEADER);\n      if (StringUtils.hasText(bearerToken) && bearerToken.startsWith(\"Bearer \")) {\n         return bearerToken.substring(7);\n      }\n      return null;\n   }\n```\n\n### doFilter 메소드 내부 로직\n\n doFilter의 내부 로직을 작성하겠습니다.\n\n```clike\nHttpServletRequest httpServletRequest = (HttpServletRequest) servletRequest;\n      String jwt = resolveToken(httpServletRequest);\n      String requestURI = httpServletRequest.getRequestURI();\n\n      if (StringUtils.hasText(jwt) && tokenProvider.validateToken(jwt)) {\n         Authentication authentication = tokenProvider.getAuthentication(jwt);\n         SecurityContextHolder.getContext().setAuthentication(authentication);\n         logger.debug(\"Security Context에 '{}' 인증 정보를 저장했습니다, uri: {}\", authentication.getName(), requestURI);\n      } else {\n         logger.debug(\"유효한 JWT 토큰이 없습니다, uri: {}\", requestURI);\n      }\n\n      filterChain.doFilter(servletRequest, servletResponse);\n```\n\nresolveToken 을 통해 토큰을 받아와서 유효성 검증을 하고 토큰이 정상적이면 Authenticaion 객체를 받아와서 \n\nSecurityContext 에 저장합니다.\n\n## JwtSecurityConfig 클래스\n\nTokenProvider, JwtFilter 를 SecurityConfig에 적용할때 사용할 JwtSecurityConfig 클래스를 생성합니다.\n\n```java\npublic class JwtSecurityConfig extends SecurityConfigurerAdapter<DefaultSecurityFilterChain, HttpSecurity> {\n\n    private TokenProvider tokenProvider;\n\n    public JwtSecurityConfig(TokenProvider tokenProvider) {\n        this.tokenProvider = tokenProvider;\n    }\n\n    @Override\n    public void configure(HttpSecurity http) {\n        JwtFilter customFilter = new JwtFilter(tokenProvider);\n        http.addFilterBefore(customFilter, UsernamePasswordAuthenticationFilter.class);\n    }\n}\n```\n\nSecurityConfigurerAdapter를 상속받고 TokenProvider를 주입받아서 configure 메소드를 Override 하여 JwtFilter를 통해 Security 로직에 필터를 등록합니다.\n\n## JwtAuthenticationEntryPoint 클래스\n\n유효한 자격증명을 제공하지 않고 접근하려 할때 401 Unauthorized 에러를 리턴할 JwtAuthenticationEntryPoint 클래스를 생성합니다.\n\n```java\n@Component\npublic class JwtAuthenticationEntryPoint implements AuthenticationEntryPoint {\n\n    @Override\n    public void commence(HttpServletRequest request,\n                         HttpServletResponse response,\n                         AuthenticationException authException) throws IOException {\n        // 유효한 자격증명을 제공하지 않고 접근하려 할때 401\n        response.sendError(HttpServletResponse.SC_UNAUTHORIZED);\n    }\n}\n```\n\nAuthneticaionEntryPoint 를 구현하고, commence 메소드를 Override 합니다\n\n이 클래스는 유효하지 않는 자격증명은 401 에러를 전송하는 클래스입니다.\n\n## JwtAccessDeniedHandler 클래스\n\n필요한 권한이 존재하지 않는 경우에 403 Forbidden 에러를 리턴하기 위해 JwtAccessDeniedHandler 클래스를 생성합니다.\n\n```java\n@Component\npublic class JwtAccessDeniedHandler implements AccessDeniedHandler {\n\n    @Override\n    public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException {\n        //필요한 권한이 없이 접근하려 할때 403\n        response.sendError(HttpServletResponse.SC_FORBIDDEN);\n    }\n}\n```\n\nAccessDeniedHandler를 구현하하고, handle 메소드를 Override합니다.\n\n필요한 권한이 없이 접근할때 403 에러를 리턴합니다.\n\n# 3. Security 설정 추가\n\n## SecurityConfig 에 추가\n\n이제 만들었던 5개의 클래스를 SecurityConfig 에 적용하겠습니다.\n\n```java\n@EnableWebSecurity\n@EnableGlobalMethodSecurity(prePostEnabled = true)\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    private final TokenProvider tokenProvider;\n    private final JwtAuthenticationEntryPoint jwtAuthenticationEntryPoint;\n    private final JwtAccessDeniedHandler jwtAccessDeniedHandler;\n\n    public SecurityConfig(\n            TokenProvider tokenProvider,\n            JwtAuthenticationEntryPoint jwtAuthenticationEntryPoint,\n            JwtAccessDeniedHandler jwtAccessDeniedHandler\n    ) {\n        this.tokenProvider = tokenProvider;\n        this.jwtAuthenticationEntryPoint = jwtAuthenticationEntryPoint;\n        this.jwtAccessDeniedHandler = jwtAccessDeniedHandler;\n    }\n\n    @Bean\n    public PasswordEncoder passwordEncoder() {\n        return new BCryptPasswordEncoder();\n    }\n\n    @Override\n    public void configure(WebSecurity web) {\n        web.ignoring()\n                .antMatchers(\n                        \"/h2-console/**\"\n                        ,\"/favicon.ico\"\n                );\n    }\n\n    @Override\n    protected void configure(HttpSecurity httpSecurity) throws Exception {\n        httpSecurity\n                // token을 사용하는 방식이기 때문에 csrf를 disable합니다.\n                .csrf().disable()\n\n                .exceptionHandling()\n                .authenticationEntryPoint(jwtAuthenticationEntryPoint)\n                .accessDeniedHandler(jwtAccessDeniedHandler)\n\n                // enable h2-console\n                .and()\n                .headers()\n                .frameOptions()\n                .sameOrigin()\n\n                // 세션을 사용하지 않기 때문에 STATELESS로 설정\n                .and()\n                .sessionManagement()\n                .sessionCreationPolicy(SessionCreationPolicy.STATELESS)\n\n                .and()\n                .authorizeRequests()\n                .antMatchers(\"/api/hello\").permitAll()\n                .antMatchers(\"/api/authenticate\").permitAll()\n                .antMatchers(\"/api/signup\").permitAll()\n\n                .anyRequest().authenticated()\n\n                .and()\n                .apply(new JwtSecurityConfig(tokenProvider));\n    }\n}\n```\n\n- `@EnableGlobalMethodSecurity` : @PreAuthorize 어노테이션을 메소드 단위로 추가한다\n\nSecurityConfig는 TokenProvider, JwtAuthenticaionEntryPoint, JwtAccessDeniedHandler 를 주입받습니다. \n\npasswordEncoder로 BCryptPasswordEncoder를 사용합니다.\n\nconfigure 메소드에서 많은 부분이 추가됬는데(HttpSecurity 매개인자) \n\n일단 토큰을 사용하기 때문에 csrf 는 disable 합니다 Exception을 핸들링할때 우리가 작성한 클래스를 추가합니다.\n\n그리고 h2-console 을 위한 설정들을 추가해줬고, 우리는 세션을 사용하지 않기 때문에 세션 설정을 STATELESS로 설정합니다.\n\n로그인 API, 회원가입 API 는 토큰이 없는 상태에서 요청이 들어오기 때문에 모두 permitAll 설정을 해줬습니다.\n\n마지막으로 JwtFilter를 addFilterBefore로 등록했던 JwtSecurityConfig 클래스도 적용해줍니다.\n\n### 서버 실행\n\n서버를 최종적으로 실행하면 아무 오류없이 잘 실행되는 것을 볼수있습니다.\n\n```java\n2022-01-10 20:36:56.570  INFO 44384 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''\n2022-01-10 20:36:56.575  INFO 44384 --- [           main] c.e.jwttutorial.JwtTutorialApplication   : Started JwtTutorialApplication in 2.078 seconds (JVM running for 2.671)\n```\n\n이제 JWT 설정 추가, JWT 관련 코드 개발, Security 설정 추가하는 작업이 완료되었습니다.\n\n다음편에서는 DB와 연결하는 Repository를 만들고 로그인 API 를 구현하겠습니다.","excerpt":"1. JWT 설정추가 application.yml 파일을 열고, jwt 설정을 추가하겠습니다. header : JWT를 검증하는데 필요한 정보 secret : HS512 알고리즘을 사용할 것이기 때문에 512bit, 즉 64byte 이상의 secre…","fields":{"slug":"/springboot-jwt-tutorial3/"},"frontmatter":{"date":"Jan 12, 2022","title":"SpringBoot JWT 튜토리얼 - 3장 JWT코드, Security 설정 추가","tags":["SpringBoot","JWT","튜토리얼"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"# 1. JWT (Json Web Token)란?\n\n---\n\n- JSON 객체를 사용해서 토큰 자체에 정보를 저장하는 Web Token\n- Header, Payload, Signature 3개 부분으로 구성됨.\n- 쿠키나 세션을 이용한 인증보다 안전하고 효율적임\n- 일반적으로는 `Authorization : <type> <credentials>` 형태로 Request Header 에 담겨져 오기 떄문에 Header 값을 확인해서 가져올 수 있음.\n\n## 1.1 장단점\n\n---\n\n- 장점\n    - 중앙 인증 서버, 저장소에 대한 의존성이 없어서 수평확장에 유리\n    - Base64 URL Safe Encoding 이라 URL, Cookie, Header 어떤 형태로 사용가능\n    - Stateless 한 서버 구현 가능\n    - 웹이 아닌 모바일에서도 사용 가능\n    - 인증 정보를 다른 곳에서도 사용 가능 (OAuth)\n- 단점\n    - Payload 의 정보가 많아지면 네트워크 사용량 증가\n    - 다른 사람이 토큰을 decode 하여 데이터 확인 가능\n    - 토큰을 탈취당한 경우 대처하기 어려움\n        - 기본적으로는 서버에서 관리하는게 아니다보니 탈취당한 경우 강제 로그아웃 처리가 불가능\n        - 토큰 유효시간이 만료되기 전까지는 탈취자는 자유롭게 인증 가능\n        - 그래서 유효시간을 짧게 가져가고 refresh Token 을 발급하는 방식으로 많이 사용\n\n## 1.2 Token 구성요소\n\n---\n\n- Header\n    - `alg` : Signature 를 해싱하기 위한 알고리즘 정보를 갖고 있음\n    - `typ` : 토큰의 타입을 나타내는데 없어도 됨(보통 JWT 를 사용)\n- Payload\n    - 서버와 클라이언트가 주고받는, 시스템에서 실제로 사용될 정보에 대한 내용을 담고 있음\n    - JWT가 [기본적으로 갖고 있는 키워드](https://datatracker.ietf.org/doc/html/rfc7519#section-4.1)가 존재\n    - 원한다면 추가 가능\n        - `iss` : 토큰 발급자\n        - `sub` : 토큰 제목\n        - `aud` : 토큰 대상\n        - `exp` : 토큰의 만료시간\n        - `nbf` : Not Before\n        - `iat` : 토큰이 발급된 시간\n        - `jti` : JWT의 고유 식별자\n- Signature\n    - 서버에서 토큰이 유효한지 검증하기 위한 문자열\n    - Header + Payload + Secret Key 로 값을 생성하므로 데이터 변조 여부를 판단 가능\n    - Secret Key 는 노출되지 않도록 서버에서 관리 필요\n\n## 1.3 토큰 인증 타입\n\n---\n\n`Authorization: <type> <credentials>` 형태에서 `<type>` 부분에 들어값 값.\n\n엄격한 규칙이 있는건 아니고, 일반적으로 많이 사용되는 형태\n\n- Basic\n    - 사용자 아이디와 암호를 Base64로 인코딩한 값을 토큰으로 사용\n- Bearer\n    - JWT 또는 OAuth 에 대한 토큰을 사용\n- Digest\n    - 서버에서 난수 데이터 문자열을 클라이언트에 보냄\n    - 클라이언트는 사용자 정보와 nonce 를 포함하는 해시값을 사용하여 응답\n- HOBA\n    - 전자 서명 기반 인증\n- Mutual\n    - 암호를 이용한 클라이언트-서버 상호 인증\n- AWS4-HMAC-SHA256\n    - AWS 전자 서명 기반 인증\n\n# 2. Refresh Token\n\n---\n\n**JWT 역시 탈취되면 누구나 API 를 호출할 수 있다는 [단점이](https://www.notion.so/JWT-6b901ef070744b6bb65fff7f5343fd35) 존재.**\n\n세션은 탈취된 경우 세션 저장소에서 탈취된 세션 ID를 삭제하면되지만, JWT 는 서버에서 관리하지 않기 때문에 속수무책으로 당할 수 밖에 없음.\n\n그래서 탈취되어도 피해가 최소한 되도록 유효시간을 짧게 가져감.\n\n하지만 만료 시간을 30분으로 설정하면 일반 사용자는 30분마다 새로 로그인하여 토큰을 발급받아야 함.\n\n**사용자가 매번 로그인 하는 과정을 생략하기 위해 필요한게 Refresh Token.**\n\n### 발급 과정\n\n1. Refresh Token 은 로그인 토큰(Access Token) 보다 긴 유효 시간을 가지며, Access Token 이 만료된 사용자가 재발급을 원할 경우 Refresh Toekn을 함께 전달함.\n2. 서버는 Access Token 에 담긴 사용자의 정보를 확인하고 Refresh Token 이 아직 만료되지 않았다면, 새로운 토큰을 발급해줌\n\n위와 같이 하면 매번 로그인해야하는 번거로움 없이 로그인을 지속적으로 유지 할 수 있음.\n\n### 주의\n\nRefresh Token 은 사용자가 로그인할 때 같이 발급되며, 클라이언트가 안전한 곳에 보관하고 있어야 함.\n\nAccess Token과 달리 매 요청마다 주고 받지 않기 때문에 탈취 당할 위험이 적으며, 요청 주기가 길기 때문에 별도의 저장소에 보관함. (정책마다 다르게 사용)\n\n## 2.1 Refresh Token 저장소\n\n---\n\nRefresh Token 은 서버에서 별도의 저장소에 보관하는 것이 좋다.\n\n- Refresh Token 은 사용자 정보가 없기 때문에 저장소에 값이 있으면 검증 시 어떤 사용자의 토큰인지 판단하기 용이\n- 탈취당했을 때 저장소에서 Refresh Token 정보를 삭제하면 Access Token 만료 후에 재발급이 안되게 강제 로그아웃 처리 가능\n- 일반적으로 Redis 많이 사용\n\n## 2.2 Refresh Token 으로 Access Token 재발급 시나리오\n\n---\n\n1. 클라이언트는 `access token` 으로 API 요청하며 서비스 제공\n2. `access token` 이 만료되면 서버에서 `access token` 만료 응답을 내려줌\n3. 클라이언트는 access token 만료응답을 받고 재발급을 위해 `access token + refresh token` 을 함께 보냄\n4. 서버는 `refresh token` 의 만료 여부를 확인\n5. `acces token` 으로 유저 정보(username 또는 userid) 를 획득하고 저장소에 해당 유저 정보를 key 값으로 한 value 가 `refresh token` 과 일치하는지 확인\n6.  4 - 5 번의 검증이 끝나면 새로운 토큰 세트 (access + refresh ) 발급\n7. 서버는 `refresh token` 저장소의 value 업데이트\n\n## 참고\n\n- [JWT Token 확인 가능한 사이트](https://jwt.io)\n- [참고한 블로그](https://bcp0109.tistory.com/321)","excerpt":"1. JWT (Json Web Token)란? JSON 객체를 사용해서 토큰 자체에 정보를 저장하는 Web Token Header, Payload, Signature 3개 부분으로 구성됨. 쿠키나 세션을 이용한 인증보다 안전하고 효율적임 일반적으로는…","fields":{"slug":"/json-web-token/"},"frontmatter":{"date":"Jan 10, 2022","title":"Json Web Token(JWT) 란?","tags":["보안","Token"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"## 1. 401 Unauthorized 해결을 위한 Security 설정\n\n### SecurityConfig 생성\n\n![Untitled](2-1.png)\n\nconfig 패키지를 생성한뒤, SecurityConfig 클래스를 작성합니다.\n\n- SecurityConfigurer 설정을 위한 두가지 방법\n    1. `WebSecurityConfigurer` 를 `implements` 하기\n    2. `WebSecurityConfigurerAdapter` 를 `extends` 하기\n    \n    위 코드에서는 2번째 방법으로 어댑터 클래스를 상속받아서 구현한다.\n    \n- `configure(HttpSecurity http)` 메소드 오바라이딩\n    \n    상속받은 클래스 내부를 보면, configure 함수가 오버로딩되어있는데, 이 코드에서는 HTTPSecurity 를 매개변수로 가지는 함수를 오버라이딩하여 작성한다.\n    \n- `authorizeRequests()`\n    - HttpServletRequest 를 사용한 요청들에 대한 접근제한\n    - HttpServletRequest?\n        \n        JSP 기본 내장 객체 중 **request 객체는 JSP에서 가장 많이 사용되는 객체**입니다.\n        \n        웹브라우저 사용자인 클라이언트로부터 서버로 요청이 들어오면 서버에서는 **HttpServletRequest**  를 생성하며, 요청정보에 있는 패스로 매핑된 서블릿에게 전달합니다.\n        \n        이렇게 전달받은 내용들을 파라미터로 Get과 Post 형식으로 클라이언트에게 전달합니다.\n        \n- `antMatchers(path).permitAll()`\n    - 해당 path 는 인증없이(permitAll) 접근허용한다.\n- `anyRequest().authenticated()`\n    - 그외 나머지 요청들은 인증되어야한다.\n\n### Postman으로 테스트\n- GET - localhost:8080/api/hello\n\n![Untitled](2-2.png)\n\n위와 같이 문자열 “hello” 가 반환이 된것을 볼수있습니다.\n\n## 2. Datasource, JPA 설정\n\n### properties → yml 로 변경\n\n기본적으로 스프링부트는 key - value 형식을 사용하는 [application.properties](http://application.properties) 파일이 있습니다.\n\n키에 동일한 접두사를 사용하여, 계층적 데이터를 표현합니다.\n\n해당 파일의 각 라인은 단일 구성이고, 모든 키는 spring.datasource에 속합니다.\n\n```\nspring.datasource.url=jdbc:h2:dev\nspring.datasource.username=SA\nspring.datasource.password=password\n```\n\nYAML 형식은 계층적 구성 데이터를 지정하기 편리한 형식입니다.\n\n```yaml\nspring:\n    datasource:\n        password: password\n        url: jdbc:h2:dev\n        username: SA\n```\n\n따라서 위 두가지 차이를 보면, YAML 형식은 가독성이 좋고, 하나의 파일로, 프로필을 구분할 수 있는 장점이있다.\n\n보기 좋은 것을 선호하면 YAML 형식을 사용하거나, 이전 형식대로 사용해도 상관없습니다.\n\n인텔리제이의 Refactor를 이용해 application.properties 의 확장자를 yml로 변경합니다.\n\n![Untitled](2-3.png)\n\nH2 데이터베이스를 사용할 것 이고, 메모리에 데이터를 저장합니다.\n\n- h2.console.enabled\n    - h2 콘솔 페이지 활성화\n- jpa.hibernate.ddl-auto\n    - Hibernate 초기화 전략, create-drop 은 인-메모리 DB 기본 전략입니다.\n    - SessionFactory가 시작될 때, Drop, Create, Alter 종료될때 Drop\n- jpa.properties.hibernate\n    - 콘솔창에서 sql 문을 보기좋게 출력\n- logging.level\n    - log4j 의 로그레벨은 ALL < DEBUG < INFO < WARN < ERROR < FATAL < OFF 순으로 지정.\n\n## 3. Entity 생성\n\nentity 패키지를 생성하고, User, Authority 를 생성합니다.\n\n```java\n@Entity\n@Table(name = \"user\")\n@Getter\n@Setter\n@Builder\n@AllArgsConstructor\n@NoArgsConstructor\npublic class User {\n\n    @Id\n    @Column(name = \"user_id\")\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long userId;\n\n    @Column(name = \"username\", length = 50, unique = true)\n    private String username;\n\n    @Column(name = \"password\", length = 100)\n    private String password;\n\n    @Column(name = \"nickname\", length = 50)\n    private String nickname;\n\n    @Column(name = \"activated\")\n    private boolean activated;\n\n    @ManyToMany\n    @JoinTable(\n            name = \"user_authority\",\n            joinColumns = {@JoinColumn(name = \"user_id\", referencedColumnName = \"user_id\")},\n            inverseJoinColumns = {@JoinColumn(name = \"authority_name\", referencedColumnName = \"authority_name\")})\n    private Set<Authority> authorities;\n}\n```\n\n```java\npackage com.example.jwttutorial.entity;\n\nimport lombok.*;\nimport javax.persistence.Column;\nimport javax.persistence.Entity;\nimport javax.persistence.Id;\nimport javax.persistence.Table;\n\n@Entity\n@Table(name = \"authority\")\n@Getter\n@Setter\n@Builder\n@AllArgsConstructor\n@NoArgsConstructor\npublic class Authority {\n\n    @Id\n    @Column(name = \"authority_name\", length = 50)\n    private String authorityName;\n}\n```\n\n![Untitled](2-4.png)\n\nUser 클래스를 보면 @ManyToMany, @JoinTable 은 유저와 권한 객체의 다대다 관계를 위 테이블 처럼 일대다, 다대일 관계의 조인 테이블로 정의했습니다. \n\n이 부분은 추후 강의자의 JPA 강의에서 자세히 설명합니다. \n\n### data.sql 생성\n\n편의를 위해, 서버를 시작할때마다 Data를 자동으로 DB에 넣어주는 기능을 활용하겠습니다.\n\n resource 폴더 밑에 data.sql 파일을 만들겠습니다.\n\n```sql\nINSERT INTO USER (USER_ID, USERNAME, PASSWORD, NICKNAME, ACTIVATED) VALUES (1, 'admin', '$2a$08$lDnHPz7eUkSi6ao14Twuau08mzhWrL4kyZGGU5xfiGALO/Vxd5DOi', 'admin', 1);\nINSERT INTO USER (USER_ID, USERNAME, PASSWORD, NICKNAME, ACTIVATED) VALUES (2, 'user', '$2a$08$UkVvwpULis18S19S5pZFn.YHPZt3oaqHZnDwqbCW9pft6uFtkXKDC', 'user', 1);\n\nINSERT INTO AUTHORITY (AUTHORITY_NAME) values ('ROLE_USER');\nINSERT INTO AUTHORITY (AUTHORITY_NAME) values ('ROLE_ADMIN');\n\nINSERT INTO USER_AUTHORITY (USER_ID, AUTHORITY_NAME) values (1, 'ROLE_USER');\nINSERT INTO USER_AUTHORITY (USER_ID, AUTHORITY_NAME) values (1, 'ROLE_ADMIN');\nINSERT INTO USER_AUTHORITY (USER_ID, AUTHORITY_NAME) values (2, 'ROLE_USER');  \n```\n\n## 4. H2 Console 결과 확인\n\n우리가 만들었던 엔티티들이 DB에 생성이 되는지 확인을 해봅니다. \n\n그 전에 Security 설정을 추가해줘야지 h2-console 접근을 원할하게 할 수 있습니다.\n\n![Untitled](2-5.png)\n\nh2-console 하위 모든 요청들과 파비콘 관련 요청은 Spring Security 로직을 수행하지 않고 접근할 수 있도록 \n\nconfigure(WebSecurity) 메소드를 오버라이딩 합니다.\n\n그 후 서버를 시작합니다.\n\n- DB 초기화 중 에러 발생\n    \n    ```java\n    2022-01-07 16:36:18.468  WARN 2873 --- [           main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSourceScriptDatabaseInitializer' defined in class path resource [org/springframework/boot/autoconfigure/sql/init/DataSourceInitializationConfiguration.class]: Invocation of init method failed; nested exception is org.springframework.jdbc.datasource.init.ScriptStatementFailedException: Failed to execute SQL script statement #1 of URL [file:/Users/seonghun/Desktop/dev/projects/jwt-tutorial/build/resources/main/data.sql]: INSERT INTO USER (USER_ID, USERNAME, PASSWORD, NICKNAME, ACTIVATED) VALUES (1, 'admin', '$2a$08$lDnHPz7eUkSi6ao14Twuau08mzhWrL4kyZGGU5xfiGALO/Vxd5DOi', 'admin', 1); \n    nested exception is org.h2.jdbc.JdbcSQLSyntaxErrorException: Table \"USER\" not found; SQL statement:\n    \n    INSERT INTO USER (USER_ID, USERNAME, PASSWORD, NICKNAME, ACTIVATED) VALUES (1, 'admin', '$2a$08$lDnHPz7eUkSi6ao14Twuau08mzhWrL4kyZGGU5xfiGALO/Vxd5DOi', 'admin', 1) [42102-200]\n    ```\n    <br/>\n    hibernate 초기화 과정에 에러가 발생했습니다.\n    \n    Spring Boot Application 구동하는 과정 중에 `data.sql`을 실행하는 도중, User 테이블을 찾을 수 없어 Insert 구문에서 오류가 발생하는 것인데. \n    \n    강의에서 스프링부트의 버전은 2.4이고 현재 2.6 인데 버전이 업데이트 되면서 이러한 오류가 발생하는 듯 합니다.(대부분의 오류는 버전업데이트 관련을 많이겪음)\n    <br/>\n    - Hibernate and data.sql 공식 노트 내용 ([릴리즈 노트 링크)](https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-2.5-Release-Notes)\n    \n    > By default, data.sql scripts are now run before Hibernate is initialized. This aligns the behavior of basic script-based initialization with that of Flyway and Liquibase. If you want to use data.sql to populate a schema created by Hibernate, set spring.jpa.defer-datasource-initialization to true. While mixing database initialization technologies is not recommended, this will also allow you to use a schema.sql script to build upon a Hibernate-created schema before it’s populated via data.sql.\n    > \n    \n    Spring Boot 2.5버전 부터 스크립트 기반 초기화의 동작과정을 Flyway, Liquibase와 일치시키기 위해서 `data.sql` 은 Hibernate 초기화되기 전에 실행된다는 내용인것 같습니다.\n    \n    따라서 Hibernate 초기화를 통해 생성된 스키마에다가 데이터를 채우기를 위해서 `data.sql`가 실행되기를 원한다면 **application.yml**(또는 properties)에 **`spring.jpa.defer-datasource-initialization`** 옵션 값을 **true**로 추가해주어야 합니다. \n    \n    또는 `schema.sql`을 추가해서 hibernate 가 스키마를 생성하는 과정보다 먼저 실행되도록하여 해당 스키마에 data.sql을 채우도록하는 방법도 있다고 합니다. 그러나 DB 초기화 기술을 혼합하여 사용하는 것은 권장하지 않는 방법이라고 합니다.\n    \n    따라서 application.yml 에 `defer-datasource-initialization: true` 옵션을 권장하지 않지만 추가합니다.\n    \n\n```sql\n2022-01-07 16:43:40.706  INFO 2951 --- [           main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.H2Dialect\nHibernate: \n    \n    drop table if exists authority CASCADE \nHibernate: \n    \n    drop table if exists user CASCADE \nHibernate: \n    \n    drop table if exists user_authority CASCADE \nHibernate: \n    \n    create table authority (\n       authority_name varchar(50) not null,\n        primary key (authority_name)\n    )\nHibernate: \n    \n    create table user (\n       user_id bigint generated by default as identity,\n        activated boolean,\n        nickname varchar(50),\n        password varchar(100),\n        username varchar(50),\n        primary key (user_id)\n    )\nHibernate: \n    \n    create table user_authority (\n       user_id bigint not null,\n        authority_name varchar(50) not null,\n        primary key (user_id, authority_name)\n    )\nHibernate: \n    \n    alter table user \n       add constraint UK_sb8bbouer5wak8vyiiy4pf2bx unique (username)\nHibernate: \n    \n    alter table user_authority \n       add constraint FK6ktglpl5mjosa283rvken2py5 \n       foreign key (authority_name) \n       references authority\nHibernate: \n    \n    alter table user_authority \n       add constraint FKpqlsjpkybgos9w2svcri7j8xy \n       foreign key (user_id) \n       references user\n```\n\nHibernate DB 초기화 오류를 해결하고 실행을 하니, 로그에 SQL 문을 볼수있습니다. \n\n이 로그들을 보면, 우리가 만들어둔 Entity 내용들을 기반으로 DB 관련 정보들을 생성하는 쿼리들이 잘 수행 된것을 볼수있습니다.\n\n### 실제 DB 반영 확인\n\n[localhost:8080/h2-console](http://localhost:8080/h2-console) 에 접속합니다. (인증을 무시하도록 설정했으므로,접속이 잘 되야합니다)\n\n![Untitled](2-6.png)\n\n우리가 만들었던 Entity 정보들과 data.sql 파일의 쿼리내용들이 잘 들어와있는것을 볼수있습니다.\n\n다음 강의에는 JWT 관련 코드들을 작성하겠습니다.\n\n### Reference\n\n[HttpServletRequest 개념](https://chobopark.tistory.com/43)\n\n[properties → YAML](https://devgoat.tistory.com/15)\n\n[log4j loggin level](https://myblog.opendocs.co.kr/archives/950)\n\n[hibernate ddl-auto 초기화전략](https://pravusid.kr/java/2018/10/10/spring-database-initialization.html)\n\n[스프링부트 2.5 hibernate data.sql](https://velog.io/@khsb2012/스프링-부트-2.5-업데이트-hibernate-data.sql-관련-변동사항)","excerpt":"1. 401 Unauthorized 해결을 위한 Security 설정 SecurityConfig 생성  config 패키지를 생성한뒤, SecurityConfig 클래스를 작성합니다. SecurityConfigurer 설정을 위한 두가지 방법  를 …","fields":{"slug":"/springboot-jwt-tutorial2/"},"frontmatter":{"date":"Jan 08, 2022","title":"SpringBoot JWT 튜토리얼 - 2장 Security 설정, Data 설정","tags":["SpringBoot","JWT","튜토리얼"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n인프런 강의(Spring Boot JWT Tutorial)를 수강하며, 내용들을 기록한 페이지입니다.\n\n- 배우는 것\n    - Spring Boot를 이용한 JWT 인증, 인가 구현\n    - Spring Security 기초\n    - 회원가입, 로그인, 권한로직\n\n# JWT 소개 ([JWT.io](http://JWT.io) [홈페이지](https://jwt.io))\n\n---\n\n![Untitled](1-1.png)\n\nJWT 는 Json 객체를 사용하여 토큰 자체에 정보들을 저장하고 있는 Web Token 이라 할 수 있다.\n\n특히, JWT를 이용하는 방식은 헤비하지 않고 아주 간편하고 쉽게 적응할 수 있다.\n\n- JWT 는 Header, Payload, Signature  3개의 부분으로 구성되어 있다.\n    - Header : Signature 를 해싱하기 위한 알고리즘 정보들이 담김\n    - Payload :  서버와 클라이언트가 주고받는, 시스템에서 실제로 사용될 정보에 대한 내용들을 담고있다.\n    - Signature : 토큰의 유효성 검증을 위한 문자열\n- 장점\n    - 중앙의 인증서버, 데이터 스토어에 대한 의존성 없음, 수평확장에 유리\n    - Base64 URL Safe Encoding  > URL, Cookie, Header 모두 사용 가능\n- 단점\n    - Payload 의 정보가 많아지면 네트워크 사용량 증가, 데이터 설계 고려 필요\n    - 토큰이 클라이언트에 저장, 서버에서 클라이언트의 토큰을 조작할 수 없음\n\n## 프로젝트 생성\n\n---\n\n### 1. 스프링 이니셜라이저를 통한 프로젝트 생성\n\n![Untitled](1-2.png)\n\n- 프로젝트 메타데이터를 입력한다\n- 자바 버전은 8\n- 빌드 도구는 Gradle\n\n![Untitled](1-3.png)\n\n- 스프링 부트 버전은 2.6.2 (강좌는 2.4.1임)\n- 추가한 의존성\n    - Lombok (편의성)\n    - Spring Web\n    - Spring Security\n    - h2 Database\n    - Spring Data JPA\n    - Validation\n    \n\n![Untitled](1-5.png)\n\n- 프로젝트가 생성된 모습\n\n![Untitled](1-4.png)\n\n- Lombok을 사용하므로 Enable annotaion processing 을 체크하자.\n\n### 2. 간단한 Rest API 테스트\n\n![Untitled](1-6.png)\n\n간단한 문자열(hello)을 리턴해주는 api를 만들고 테스트해보겠습니다.\n\n- `RestController` : 컨트롤러를 JSON을 반환하는 컨트롤러로 만들어 줍니다.\n- `RequestMapping` : 요청에 대해 어떤 Controller가 처리할지를 맵핑하기 위한 어노테이션.\n- `GetMapping` : HTTP Method인 Get인 요청을 받을 수 있는 API를 만들어 준다.\n- `ResponseEntity<>` : 사용자의 HttpRequest에 대한 응답 데이터를 포함하는 클래스.\n- `ResponseEntity.ok()`: 정상적인 요청이면 메소드의 파라미터 내용을 반환한다.\n\n위 코드를 작성하고 애플리케이션을 실행하고 Postman을 통해서 해당 url로 요청을 보내겠습니다.\n\n![Untitled](1-7.png)\n\n요청을 보내면 401 HTTP 상태 코드가 반환된 것을 볼 수 있습니다.\n\n이를 해결하기 위한 Security 설정과, 기본적인 Data 설정을 하겠습니다.\n\n### Reference\n\n- [ResponseEntity 스프링 공식 문서](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/http/ResponseEntity.html)","excerpt":"인프런 강의(Spring Boot JWT Tutorial)를 수강하며, 내용들을 기록한 페이지입니다. 배우는 것 Spring Boot를 이용한 JWT 인증, 인가 구현 Spring Security 기초 회원가입, 로그인, 권한로직 JWT 소개 (JW…","fields":{"slug":"/springboot-jwt-tutorial1/"},"frontmatter":{"date":"Jan 07, 2022","title":"SpringBoot JWT 튜토리얼 - 1장 JWT소개,프로젝트생성","tags":["SpringBoot","JWT","튜토리얼"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"# asdf란? ([asdf 설치 하기](https://subicura.com/mac/dev/terminal-apps.html#asdf))\n\nasdf-vm은 mac OS의 각종 프로그램의 버전을 손쉽게 관리해주는 **성의 없어 보이는 이름**의 도구입니다.<br/>\n기존에 nvm, rbenv등 언어, 프로그램별로 달랐던 관리 도구를 하나로 통합해서 사용할 수 있습니다. <br/>\nhomebrew도 일부 버전 관리 기능을 제공하지만 asdf만큼 강력하지 않습니다.<br/>\nasdf를 이용하면 버전 별로 설치할 수 있는 장점이 있습니다.<br/>\n그래서 이번에는 Java 8 JDK와, Java 11 JDK 를 둘다 설치하는 것을 해보겠습니다.<br/>\n\n\n## 시작\n\n```json\n❯ java --version\nopenjdk 11.0.13 2021-10-19 LTS\nOpenJDK Runtime Environment Zulu11.52+13-CA (build 11.0.13+8-LTS)\nOpenJDK 64-Bit Server VM Zulu11.52+13-CA (build 11.0.13+8-LTS, mixed mode)\n```\n\n현재 저의 자바 jdk 버전은 11입니다. 저는 jdk 8 버전의 자바 환경도 만들고 싶습니다. \n<br/>그럴려면 환경변수도 매번 지정해줘야하는 번거로움이 있습니다. \n<br/>asdf 를 이용해서 8버전과 11버전을 유연하게 돌아가며 사용할 수 있는 환경을 만들어 보겠습니다.\n\n### 이전에 이미 설치한 JAVA JDK 는 어떡합니까?\n\n만약 brew를 통해서 java를 설치하신 분이라면 brew uninstall 을 통해 jdk를 삭제하면 되고.\n\n아니면 아래 명령어를 통해 삭제하시면 됩니다.\n\n```json\n❯ sudo rm -fr /Library/Internet\\ Plug-Ins/JavaAppletPlugin.plugin\n❯ sudo rm -fr /Library/PreferencesPanes/JavaControlPanel.prefPane\n❯ sudo rm -fr ~/Library/Application\\ Support/Java\n\n❯ cd /Library/Java/JavaVirtualMachines/ \n❯ ls \n❯ sudo -rm -rf jdk-x.x.x.jdk\n```\n\n### JAVA Plugin 추가\n\n[asdf-java plugin 깃허브 링크](https://github.com/halcyon/asdf-java#java_home)\n\n- 먼저 자바 플러그인을 추가합니다\n\n```json\n❯ asdf plugin-add java https://github.com/halcyon/asdf-java.git\n```\n\n### 자바 플러그인 업데이트\n\n플러그인 목록을 최신화합니다.\n\n```json\n❯ asdf plugin update java\n```\n\n### 자바 버전 별 플러그인 보기\n\n아래 명령어를 이용하면 설치할 수 있는 자바의 버전들이 나타납니다.\n\n```json\n❯ asdf list-all java\n...\nsapmachine-jre-18-internal.0\ntemurin-17.0.0+35\ntemurin-17.0.1+12\ntemurin-jre-17.0.1+12\nzulu-8.52.0.23\nzulu-8.54.0.21\nzulu-8.56.0.23\nzulu-8.58.0.13\nzulu-11.43.1017\nzulu-11.43.1021\nzulu-11.45.27\nzulu-11.48.21\nzulu-11.50.19\nzulu-11.52.13\nzulu-13.35.1019\nzulu-13.35.1025\nzulu-13.37.21\nzulu-13.40.15\nzulu-13.42.17\nzulu-13.44.13\nzulu-15.28.1013\nzulu-15.29.15\nzulu-15.32.15\nzulu-15.34.17\nzulu-15.36.13\nzulu-16.28.11\nzulu-16.30.15\nzulu-16.30.19\nzulu-16.32.15\nzulu-17.28.13\nzulu-17.30.15\n...\n```\n\n(라이선스 문제없는 jdk를 설치하시면 됩니다). [[JDK 라이선스 유료화]](https://zdnet.co.kr/view/?no=20181102140004)\n\n### JAVA 8, 11 버전 설치\n\n자바 8버전과 11버전의 openjdk를 설치하겠습니다.\n\n```json\n❯ asdf install java zulu-8.58.0.13\n❯ asdf install java zulu-11.52.13\n```\n\n### asdf 설치한 자바 버전 확인하기\n\n아래 명령어를 통해, 설치된 자바 버전들을 볼수있습니다.\n\n```json\n❯ asdf list java\n  zulu-11.52.13\n  zulu-8.58.0.13\n```\n\n### Global 버전으로 지정하기\n\n설치한 버전을 전역 버전으로 지정합니다. 즉 내 컴퓨터의 자바 버전을 지정한 버전으로 설정합니다.\n\n저는 8버전을 지정했습니다.\n\n```json\n❯ asdf global java zulu-8.58.0.13\n```\n\n### JAVA_HOME 설정하기\n\n[sadf java-plugin JAVA_HOME 설정](https://github.com/halcyon/asdf-java#java_home)\n\n아래 명령어를 실행하면, 자바 위치를 지정합니다. (처음 한번만 실행하면 됩니다)\n\n```json\n. ~/.asdf/plugins/java/set-java-home.zsh\n```\n\n### 자바 버전 확인하기\n\n아래 명령어를 통해 정상적으로 설치되었는지 확인합니다.\n\n```json\n❯ java -version\nopenjdk version \"1.8.0_312\"\nOpenJDK Runtime Environment (Zulu 8.58.0.13-CA-macos-aarch64) (build 1.8.0_312-b07)\nOpenJDK 64-Bit Server VM (Zulu 8.58.0.13-CA-macos-aarch64) (build 25.312-b07, mixed mode)\n```\n\n정상적으로 8버전의 jdk가 나오는 것을 볼 수 있습니다.\n\n또한 자바 환경 변수 위치까지 jdk 8로 변경된 것 을 볼 수 있습니다.\n\n```json\n❯ echo $JAVA_HOME\n/Users/seonghun/.asdf/installs/java/zulu-8.58.0.13/zulu-8.jdk/Contents/Home\n```\n\n### 현재 전역으로 설정된 버전들 보기\n\n자바 뿐만 아니라 다른 프로그램들의 버전 현황을 볼 수 있습니다. (global version)\n\n```json\n❯ asdf current\njava            zulu-8.58.0.13  /Users/seonghun/.tool-versions\nnodejs          lts-fermium     Not installed. Run \"asdf install nodejs lts-fermium\"\nyarn            1.22.17         /Users/seonghun/.tool-versions\n```\n\n### 자바 버전 변경하기\n\n아래 명령어를 통해 11버전의 자바 jdk 로 변경하겠습니다.\n\n```json\n❯ asdf global java zulu-11.52.13\n```\n\n그 후 정상적으로 버전이 변경됬는지 확인하겠습니다.\n\n```json\n❯ java --version\nopenjdk 11.0.13 2021-10-19 LTS\nOpenJDK Runtime Environment Zulu11.52+13-CA (build 11.0.13+8-LTS)\nOpenJDK 64-Bit Server VM Zulu11.52+13-CA (build 11.0.13+8-LTS, mixed mode)\n```\n\n8버전에서 11버전으로 변경된 것 을 확인할 수 있습니다.\n\n아래 명령어로 자바 환경변수 경로까지 자동으로 변경된 것 을 볼수있습니다.\n\n```json\n❯ echo $JAVA_HOME\n/Users/seonghun/.asdf/installs/java/zulu-11.52.13/zulu-11.jdk/Contents/Home\n```\n\n### 결론\n\n`asdf globale java <version>` 명령어 한 줄 만으로 자바 버전을 쉽게 변경할 수 있었습니다.\n\n(원래라면 자바 버전을 버전마다 변수로 추가해줘야함)\n\n자바 뿐만 아니라 npm, yarn 같은 패키지 매니저 또한 지원하니 검색해서 유용하게 쓰시면 되겠습니다.\n\n---\n\n[참고](https://www.wiserfirst.com/blog/install-java-with-asdf/)\n\n[subicura 님 mac asdf 설치](https://subicura.com/mac/dev/terminal-apps.html#asdf/)\n\n[맥에서 Brew로 자바 설치하기(자바 버전 바꾸기)](https://llighter.github.io/install-java-on-mac/)","excerpt":"asdf란? (asdf 설치 하기) asdf-vm은 mac OS의 각종 프로그램의 버전을 손쉽게 관리해주는 성의 없어 보이는 이름의 도구입니다.\n기존에 nvm, rbenv등 언어, 프로그램별로 달랐던 관리 도구를 하나로 통합해서 사용할 수 있습니다.…","fields":{"slug":"/asdf-java/"},"frontmatter":{"date":"Jan 05, 2022","title":"asdf 를 이용한 JAVA 버전 별 설치","tags":["JAVA","자바","asdf"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"## Spring Security란?\n\n- Spring 기반의 애플리케이션의 보안(인증과 권한, 인가 등)을 담당하는 스프링 하위 프레임워크\n- **인증**과 **권한**에 대한 부분을 **Filter** 흐름에 따라 처리\n    - Filter는 Dispatcher Servlet 으로 가기전에 적용\n    - 따라서 가장 먼저 URL 요청을 받는다.\n    - 하지만, Interceptor는 Dispatcher와 Contoller 사이에 위치한다는 점에서 적용 시기의 차이가 있다.\n\n### 인증(Authentication)과 인가(Authorization)\n\n- 인증(Authentiacation) : 해당 사용자가 본인이 맞는지를 **확인**하는 절차\n- 인가(Authorization) : 인증된 사용자가 요청한 자원에 접근 가능한지를 결정하는 절차\n\n> Authentiacation → (인증 성공 후) → Authorization\n> \n\n- Spring Security는 기본적으로 인증 절차를 거친 후, 인가 절차를 진행\n- 인가 과정에서 해당 리소스에 대한 접근 권한이 있는지를 확인하게 된다.\n- Spring Security에서는 이러한 인증과 인가를 위해 Principal을 아이디로, Credential을 비밀번호로 사용하는 **Credential 기반의 인증 방식을** 사용한다.\n    - Principal(접근 주체) : 보호받는 리소스에 접근하는 대상\n    - Credential(비밀전호) : 리소스에 접근하는 대상의 비밀번호","excerpt":"Spring Security란? Spring 기반의 애플리케이션의 보안(인증과 권한, 인가 등)을 담당하는 스프링 하위 프레임워크 인증과 권한에 대한 부분을 Filter 흐름에 따라 처리 Filter는 Dispatcher Servlet 으로 가기전에…","fields":{"slug":"/spring-security-1/"},"frontmatter":{"date":"Jan 04, 2022","title":"SpringSecurity 란?","tags":["Spring Security"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n개인적으로 참고할려고 기록하는 글입니다.\n\n## MSA 구성요소 및 패턴의 유형\n\n- 인프라 구성요소 : 마이크로서비스를 지탱하는 하부구조 인프라를 구축하는데 필요한 구성요소\n- 플랫폼 패턴 : 인프라 위에서 마이크로서비스의 운영과 관리를 지원하는 플랫폼 차원의 패턴\n- 애플리케이션 패턴 : 마이크로서비스 애플리케이션을 구성하는데 필요한 패턴\n\n## 서비스 유형별 대표적인 클라우드 서비스\n\n- `Iaas(Infrastructure as a Service)` :\n  가상 머신, 스토리지, 네트워크 같은 인프라를 필요한 만큼 적시에 제공하는 서비스\n  (예시 : AWS EC2, GCP Compute Engine, Azure VM)\n\n- `CaaS(Container as a Service)` :\n  컨테이너 기반 가상화를 사용해 컨테이너를 업로드, 구성, 실행, 확장, 중지할 수 있는 서비스\n  (예시 : Google Kubernetes Engine, AWS ECS)\n\n- `Paas(Platform as a Service)` : 애플리케이션을 즉시 개발, 실행, 관리할 수 있는 플랫폼 환경 서비스\n  (예시 : Azure Web App, Google App Engine, Heroku, AWS Elastic Beanstalk)\n\n## 개발 지원 환경 DevOps\n\n- `DevOps` : 마이크로서비스를 빌드하고 테스트한 뒤 배포할 수 있게 도와주는 개발 지원 환경\n\n- `CI/CD` - 자동화된 빌드나 배포작업,\n\n  - `CI`는 `지속적 통합(Continuous Integration)` 자동으로 통합 및 테스트하고 그 결과를 기록하는 활동\n  - `CD`는 `지속적 제공(Continuous Delivery)` 및 `지속적 배포(Continouss Deployment)` 실행환경에 내보내는 활동\n  - `지속적 제공`은 빌드된 소스코드의 실행 파일을 실행환경에 반영하기 위해 승인 및 배포 담당자의 허가를 받아야하고\n    배포도 수동으로 처리한다.\n  - `지속적 배포`은 소스코드 저장소(Github)에서 빌드한 소스코드의 실행 파일을 실행 환경 까지 자동으로 배포하는 방식\n    모든 영역을 자동화하는 것에 해당함.\n\n- `Infrastructure as a Code` - 인프라 구성을 마치 프로그래밍하는 것 처럼 처리하고 소수의 인원으로 컨테이너 배포 처리하는 과정\n  (배포 파이프라인 절차를 코드로 완벽히 자동화)\n\n## MSA 주요 아키텍처 패턴\n\n- Spring Cloud + DevOps\n  - Spring Cloud : Spring Boot + Netflix OSS\n\n## 참고한 자료\n\n- [도메인 주도 설계로 시작하는 마이크로서비스 개발](http://www.yes24.com/Product/Goods/98880996)","excerpt":"개인적으로 참고할려고 기록하는 글입니다. MSA 구성요소 및 패턴의 유형 인프라 구성요소 : 마이크로서비스를 지탱하는 하부구조 인프라를 구축하는데 필요한 구성요소 플랫폼 패턴 : 인프라 위에서 마이크로서비스의 운영과 관리를 지원하는 플랫폼 차원의 패…","fields":{"slug":"/msa-related-term/"},"frontmatter":{"date":"Sep 28, 2021","title":"마이크로서비스 아키텍처(MSA) 관련 용어 정리","tags":["MSA","마이크로서비스 아키텍쳐","정리"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n처음에는 Jekyll로 블로그를 만들었는데 생각보다 마음에 안들어서, 검색하다보니 Gatsby를 발견했다.\nGatsby는 `React` 프레임워크를 기반으로 만들었는데 React를 전에 한번 입문해봐서 이걸로 선택했다.\n<br>\n<br>\n처음에는 `npm`으로 node module를 설치해서 환경을 구성했는데. 후반에 가니깐 한번 꼬이니깐 계속 꼬여서\nnpm을 재설치하고 시간을 많이 잡아 먹었다. 그래서 `yarn`으로 다시 패키지 설치하고 하니 잘되더라.\n<br>\n<br>\n# 1. Gatsby 설치\n\n## Gatsby-cli 설치\n패키지 매니저를 통해서 `gatsby-cli`를 설치한다.\n``` sh\n# npm\nnpm install -g gatsby-cli\n```\n```sh\n# yarn\nyarn add gatsby-cli\n```\n\n## 테마 설치\n```sh\ngatsby new [디렉터리 이름] [테마 깃허브 주소]\n```\n디렉터리에 다운받은 테마가 위치된다.\n```sh\ncd [디렉터리 이름]\nyarn start\n```\n\n그후 [localhost:8000](localhost:8000) 를 접속해서 설치한 테마를 맛본다.\n\n# 2. 나만의 블로그로 꾸미기\n## 포스트 위치\n다음 위치에서 블로그 포스팅을 추가할 수 있다.\n\n- `content/blog` : 포스트 파일 위치\n- `content/__about` : 프로필 파일 위치\n\n<br>\n\n포스트 파일은 `.markdown` 또는 `.md`을 사용한다.\n<br>\n\n## 메타데이터\n`gatsby-config.js` 파일이나 `gatsby-meta-config.js`파일에서 \n<br>\n블로그를 설정하는\n여러 요소를 수정할 수 있다.\n원하는 설정으로 수정하면된다.\n\n그 외의 설정은 \n`gatsby-browser.js`, `gatsby-node.js`을 참고\n\n## CSS 파일\n`src/styles` 위치에서 CSS 속성들을 수정할 수 있다.\n\n<br>\n직접 설정을 다하면 글을 한번 작성해봐서 깃허브 저장소나 자신만의 서버에서 배포하면된다.\n\n# 3. SEO 적용\nSEO는 `search engine optimization`로 검색 엔진 최적화, 구글이나 네이버에서 우리 블로그를 찾기 쉽도록 사이트를 개선하는 프로세스이다.\n\n## sitemap.xml 생성\n검색엔진에 검색이 잘 되게 할려면 웹 크롤러가 우리 사이트를 찾아와 크롤링을 하는데, 우리는 이정표를 만들어줘야한다.\n`sitemap.xml`이 이정표 역활을 한다.\n<br>\ngatsby는 `sitemap.xml`을 자동 생성해주는 플러그인이 있다. 추가하자\n<br>\n<br>\n`gastby-config.js`\n```js\n    plugins: [\n        ...\n        'gatsby-plugin-sitemap',\n    ]\n```\nplugins에 추가하면 build 될 때 마다 파일을 생성해준다.\n\n<br>\n그 후 플러그인을 설치하고, gatsby를 실행 한다.\n\n```sh\nyarn add gatsby-plugin-sitemap\ngatsby develop\n```\n\n[http://localhost:8000/sitemap.xml](http://localhost:8000/sitemap.xml)에 접속\n\n```xml\n<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" xmlns:news=\"http://www.google.com/schemas/sitemap-news/0.9\" xmlns:xhtml=\"http://www.w3.org/1999/xhtml\" xmlns:mobile=\"http://www.google.com/schemas/sitemap-mobile/1.0\" xmlns:image=\"http://www.google.com/schemas/sitemap-image/1.1\" xmlns:video=\"http://www.google.com/schemas/sitemap-video/1.1\">\n    <url>\n    ...\n    </url>\n</urlset>\n```\n위와 같은 xml 형식의 문서가 나오면 성공.\n\n## rss.xml 생성\nrss는 사이트를 방문하지 않아도 그 사이트의 새로운 글이 올라오면 알람을 준다고 생각하면된다.\n그리고 rss를 등록하는것도 검색엔진최적화 작업에 해당된다.\n\n```sh\nyarn add gatsby-plugin-feed\n```\n`sitemap`과 마찬가지로 build 할때마다 새로운 파일을 생성해야 하니 plugins에 추가하자.\n\n`gastby-config.js`\n```js\n    plugins: [\n        ...\n        'gatsby-plugin-feed',\n    ]\n```\n`rss.xml` 이 제대로 생성됬는지 확인하자\n```sh\ngatsby develop\n```\n그 후 [http://localhost:8000/rss.xml](http://localhost:8000/rss.xml)에 접속\n<br>\n`rss.xml` 페이지가 제대로 나온다면 성공.\n\n## robots.txt 생성\n`robots.txt`도 웹 크롤러가 사이트에 접속하면 찾는 파일이므로 만들어준다.\n\n```sh\nyarn add gatsby-plugin-robots-txt\n```\n`gastby-config.js`\n\n```js\nplugins: [\n\t...\n\t{\n      resolve: 'gatsby-plugin-robots-txt',\n      options: {\n        host: 웹사이트경로,\n        sitemap: 웹사이트경로/sitemap.xml',\n        policy: [{\n          userAgent: '*',\n          allow: '/'\n        }]\n      }\n    },\n\t...\n]\n```\n그리고 빌드해서 확인.\n\n```sh\ngatsby develop\n```\n그 후 [http://localhost:8000/robots.txt](http://localhost:8000/robots.txt)에 접속해\n`robots.txt`가 생성됬는지 확인한다.\n\n## 구글 서치 콘솔(GSC) 등록\n[구글등록](https://search.google.com/search-console/about)에서 시작하기를 통해 등록한다.\n우측에 URL 접두어를 선택하고 인증용 html 파일을 다운로드한다.\n다운받은 html 파일은 프로젝트 경로에 복사하고 `package.json`에서 build 스크립트를 작성한다.\n<br>\n`package.json`\n\n```json\n  \"scripts\": {\n        ...\n        \"copy\" : \"cp content/google인증용파일.html public/\",\n        \"build\": \"gatsby build && npm run copy\",\n        ...\n  }\n```\n빌드시 `npm run copy`를 통해 인증 html 파일을 public 경로로 복사해 줄 것이다.\n\n```\nyarn build\ngatsby serve\n```\n를 통해 \"http://localhost:9000/google인증파일.html\" 접속해서 잘 뜨는지 확인한다.\n그리고 sitemaps 메뉴내에 빈칸에 `sitemap.xml` 입력하고 제출한다.\n\n그러면 구글검색엔진에 등록되기까진 몇시간정도 걸리므로 기다리고 검색창에 `site: 블로그주소` 를 입력해서 확인하자.\n\n\n## 네이버 검색 노출\n\n네이버 검색도 구글에 하던것처럼 하면된다.\nhttps://searchadvisor.naver.com/console/board 접속해서 사이트를 등록한다.\n- 좌측 사이드바 메뉴에서 요청 - 사이트맵 제출에서 sitemap.xml의 경로를 입력한다.\n- 요청 - RSS 제출에서도 마찬가지로 경로를 입력한다.\n- 검증 - robots.txt에서 robots.txt 검증 및 수집요청을 한다.\n- 설정 - 수집 주기 설정을 빠르게를 체크한다.\n모든 등록이 끝났으면 몇시간뒤에 검색창에서 `site: 블로그주소`를 입력해서 등록됬는지 확인한다.\n\n## 다음 검색 노출\n다음은 다른 검색엔진보다 매우 간단해서.\nhttps://register.search.daum.net/index.daum에 접속해서 블로그를 등록만하면 끝이다.\n\n\n# 끝으로\n이렇게 간단하게 겟츠비를 통해서 블로그를 만들고 SEO 적용까지 해봤다.\n생략된 부분도 많지만 충분히 참고할 수 있을 것이다.\nReact를 잘 사용하거나 앞으로 사용해야하는 개발자가 블로그를 만들게 된다면\nGatsby로 만들어보는 것을 추천한다. 테마로 만들어도 되지만 자신이 직접 react로 만들어도 좋을것이다.\n<br>\n만약에 블로그를 수정하다가 `npm` 관련 오류가 발생한다면, yarn으로 전환해서 구축하거나,\nnpm 패키지를 재설치 해보자.\n\n\n","excerpt":"처음에는 Jekyll로 블로그를 만들었는데 생각보다 마음에 안들어서, 검색하다보니 Gatsby를 발견했다.\nGatsby는  프레임워크를 기반으로 만들었는데 React를 전에 한번 입문해봐서 이걸로 선택했다.\n\n\n처음에는 으로 node module를 …","fields":{"slug":"/gatsby-blog-start/"},"frontmatter":{"date":"Sep 28, 2021","title":"Gatsby로 블로그를 만들기","tags":["Gatsby","Blog"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n#application.properties\n\n스프링 애플리케이션은 다음 리소스가 주어진 순서대로 고려된다.\n\n1. 명령행 인수\n2. 패키징된 애플리케이션 외부의 `application.properties`\n3. 패키징된 애플리케이션 내부의 `application.properties`\n\napplication-{profile}.properties는 프로필에 관련되지 않은 파일 보다 우선된다.\n\n1. 명령행 인수\n2. 패키징된 애플리케이션 외부의 `application-{profile}.properties`\n3. 패키징된 애플리케이션 외부의 `application.properties`\n4. 패키징된 애플리케이션 내부의 `application-{profile}.properties`\n5. 패키징된 애플리케이션 내부의 `application.properties`\n\n##application.properties 에서 속성 값 사용하기\n속성 외부화를 위해 우리가 만든 application.properties를 사용할려면 `@Value` 어노테이션을 사용해야한다.\n`@Value` 어노테이션은 스프링이 속성을 찾고 해당 속성의 값을 사용하도록 지시한다.\n\n```java\npublic 리턴타입 메소드(@Value(\"${hi}\") int hi) {\n  ...\n}\n```\n\n스프링은 hi라는 이름을 가진 속성을 감지하고 그 값을 사용한다.\n\n또한 `:`을 사용해 기본값을 지정할 수 있다.\n\n```java\npublic 리턴타입 메소드(@Value(\"${hi:10}\") int hi) {\n  ...\n}\n```\n\n만약 `:` 기본값을 지정하면 값을 찾지 못했을 때 10을 기본값으로 사용한다.\n기본값을 정의하지 않고, 해당 속성이 없을 때 `IllegalArgumentException`이 발생한다.\n\n##프로필을 사용한 속성 재정의\n스프링 부트는 프로필을 사용해 추가 구성 파일을 불러와 기존의 application.properties를 전부 대체 또는 일부를 재정의할 수 있다.\n`application-{profile}.properties`를 만들면 된다.\n만약에 `application.properties`에 `hi` 값이 있고, `application-hi.properties`에 `hi`라는 값이 있으면\n`application-hi.properties`의 속성 우선순위가 높기 때문에 대체된다.\n\n##다른 속성 파일로부터 속성 불러오기\n내가 사용하고 싶은 속성 파일을 불러오고자 하면은, `@SpringBootApplication` 어노테이션이 붙은 클래스에\n`@PropertySource` 어노테이션을 추가해 사용할 수 있다.\n\n```java\n@PropertySource(\"classpath:임의의속성파일.properties\")\n@SpringBootApplication\npublic class MySpringApp {\n...\n}\n```\n\n`@PropertySource` 어노테이션은 스프링부트가 시작할 때 추가 속성 파일을 불러와준다.\n해당 어노테이션 대신 밑에 표의 매개변수를 사용하면 스프링 부트가 추가 속성 파일을 불러온다.\n\n| 매개변수                          |                         설명 |\n| :-------------------------------- | ---------------------------: |\n| spring.config.name                |             불러올 파일 목록 |\n| spring.config.location            |             속성 파일의 위치 |\n| spring.config.additional-location | 속성 파일을 불러올 추가 위치 |\n\n위 매개변수를 사용하면, application.properties는 불러오지 않는다.\n모두 검색하는 방법으로는 `--spring.config.name=application,불러올속성파일`을 사용한다.","excerpt":"application.properties 스프링 애플리케이션은 다음 리소스가 주어진 순서대로 고려된다. 명령행 인수 패키징된 애플리케이션 외부의  패키징된 애플리케이션 내부의  application-{profile}.properties는 프로필에 관…","fields":{"slug":"/springboot-application-properties-extern/"},"frontmatter":{"date":"Sep 27, 2021","title":"[SpringBoot] 속성 외부화","tags":["SpringBoot","속성","Properties"],"update":"Jan 01, 0001"}}}]}},"pageContext":{}},"staticQueryHashes":["2027115977","694178885"]}